{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 15:29:19.429702: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"2conv_only_2\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(48, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Conv2D(48, kernel_size=(21,1),\n",
    "                activation='relu',\n",
    "                padding='same')(x)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 192))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 15:30:03.583745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2259\n",
      "Epoch 1: val_loss improved from inf to 0.08524, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.2259 - val_loss: 0.0852\n",
      "Epoch 2/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0973\n",
      "Epoch 2: val_loss improved from 0.08524 to 0.07468, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0972 - val_loss: 0.0747\n",
      "Epoch 3/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0882\n",
      "Epoch 3: val_loss improved from 0.07468 to 0.07126, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0883 - val_loss: 0.0713\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0837\n",
      "Epoch 4: val_loss improved from 0.07126 to 0.06543, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0837 - val_loss: 0.0654\n",
      "Epoch 5/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0799\n",
      "Epoch 5: val_loss did not improve from 0.06543\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.0799 - val_loss: 0.0661\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0777\n",
      "Epoch 6: val_loss improved from 0.06543 to 0.06380, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0778 - val_loss: 0.0638\n",
      "Epoch 7/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0761\n",
      "Epoch 7: val_loss did not improve from 0.06380\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0762 - val_loss: 0.0654\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0744\n",
      "Epoch 8: val_loss improved from 0.06380 to 0.05775, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0744 - val_loss: 0.0577\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0732\n",
      "Epoch 9: val_loss did not improve from 0.05775\n",
      "2317/2317 [==============================] - 23s 10ms/step - loss: 0.0732 - val_loss: 0.0609\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0724\n",
      "Epoch 10: val_loss did not improve from 0.05775\n",
      "2317/2317 [==============================] - 25s 11ms/step - loss: 0.0725 - val_loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 8s 4ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2249\n",
      "Epoch 1: val_loss improved from inf to 0.09237, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 18s 7ms/step - loss: 0.2249 - val_loss: 0.0924\n",
      "Epoch 2/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0961\n",
      "Epoch 2: val_loss improved from 0.09237 to 0.07848, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0961 - val_loss: 0.0785\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0870\n",
      "Epoch 3: val_loss improved from 0.07848 to 0.07660, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0870 - val_loss: 0.0766\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0820\n",
      "Epoch 4: val_loss improved from 0.07660 to 0.06638, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0820 - val_loss: 0.0664\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0795\n",
      "Epoch 5: val_loss improved from 0.06638 to 0.06551, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0795 - val_loss: 0.0655\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0773\n",
      "Epoch 6: val_loss improved from 0.06551 to 0.06462, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 15s 7ms/step - loss: 0.0773 - val_loss: 0.0646\n",
      "Epoch 7/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0760\n",
      "Epoch 7: val_loss improved from 0.06462 to 0.06385, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 15s 7ms/step - loss: 0.0760 - val_loss: 0.0638\n",
      "Epoch 8/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0748\n",
      "Epoch 8: val_loss improved from 0.06385 to 0.06247, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0748 - val_loss: 0.0625\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0737\n",
      "Epoch 9: val_loss did not improve from 0.06247\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0737 - val_loss: 0.0664\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0728\n",
      "Epoch 10: val_loss did not improve from 0.06247\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0728 - val_loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 3ms/step\n",
      "2317/2317 [==============================] - 6s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2225\n",
      "Epoch 1: val_loss improved from inf to 0.08765, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.2222 - val_loss: 0.0876\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0966\n",
      "Epoch 2: val_loss improved from 0.08765 to 0.07477, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0966 - val_loss: 0.0748\n",
      "Epoch 3/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0883\n",
      "Epoch 3: val_loss improved from 0.07477 to 0.06977, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0883 - val_loss: 0.0698\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0836\n",
      "Epoch 4: val_loss improved from 0.06977 to 0.06755, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0836 - val_loss: 0.0675\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0800\n",
      "Epoch 5: val_loss improved from 0.06755 to 0.06408, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.0800 - val_loss: 0.0641\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0779\n",
      "Epoch 6: val_loss did not improve from 0.06408\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0779 - val_loss: 0.0659\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0759\n",
      "Epoch 7: val_loss improved from 0.06408 to 0.06199, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0759 - val_loss: 0.0620\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0749\n",
      "Epoch 8: val_loss improved from 0.06199 to 0.06191, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0749 - val_loss: 0.0619\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0740\n",
      "Epoch 9: val_loss did not improve from 0.06191\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0740 - val_loss: 0.0640\n",
      "Epoch 10/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0731\n",
      "Epoch 10: val_loss did not improve from 0.06191\n",
      "2317/2317 [==============================] - 17s 8ms/step - loss: 0.0731 - val_loss: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2227\n",
      "Epoch 1: val_loss improved from inf to 0.08876, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.2225 - val_loss: 0.0888\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0958\n",
      "Epoch 2: val_loss improved from 0.08876 to 0.07896, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 24s 10ms/step - loss: 0.0959 - val_loss: 0.0790\n",
      "Epoch 3/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0865\n",
      "Epoch 3: val_loss improved from 0.07896 to 0.07761, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0864 - val_loss: 0.0776\n",
      "Epoch 4/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0813\n",
      "Epoch 4: val_loss improved from 0.07761 to 0.06600, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0813 - val_loss: 0.0660\n",
      "Epoch 5/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0783\n",
      "Epoch 5: val_loss improved from 0.06600 to 0.06552, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0783 - val_loss: 0.0655\n",
      "Epoch 6/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.0757\n",
      "Epoch 6: val_loss improved from 0.06552 to 0.06338, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0758 - val_loss: 0.0634\n",
      "Epoch 7/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0739\n",
      "Epoch 7: val_loss improved from 0.06338 to 0.06301, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0739 - val_loss: 0.0630\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0731\n",
      "Epoch 8: val_loss did not improve from 0.06301\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0731 - val_loss: 0.0633\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0720\n",
      "Epoch 9: val_loss improved from 0.06301 to 0.06100, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0720 - val_loss: 0.0610\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0710\n",
      "Epoch 10: val_loss did not improve from 0.06100\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0711 - val_loss: 0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2304\n",
      "Epoch 1: val_loss improved from inf to 0.08591, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.2303 - val_loss: 0.0859\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0952\n",
      "Epoch 2: val_loss improved from 0.08591 to 0.07298, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0952 - val_loss: 0.0730\n",
      "Epoch 3/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0853\n",
      "Epoch 3: val_loss improved from 0.07298 to 0.07210, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.0853 - val_loss: 0.0721\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0812\n",
      "Epoch 4: val_loss improved from 0.07210 to 0.06415, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 29s 13ms/step - loss: 0.0812 - val_loss: 0.0641\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0785\n",
      "Epoch 5: val_loss did not improve from 0.06415\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0785 - val_loss: 0.0678\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0760\n",
      "Epoch 6: val_loss improved from 0.06415 to 0.06391, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 29s 13ms/step - loss: 0.0760 - val_loss: 0.0639\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0754\n",
      "Epoch 7: val_loss improved from 0.06391 to 0.06192, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 27s 12ms/step - loss: 0.0754 - val_loss: 0.0619\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0741\n",
      "Epoch 8: val_loss did not improve from 0.06192\n",
      "2317/2317 [==============================] - 32s 14ms/step - loss: 0.0741 - val_loss: 0.0633\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0727\n",
      "Epoch 9: val_loss improved from 0.06192 to 0.06067, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0728 - val_loss: 0.0607\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0725\n",
      "Epoch 10: val_loss did not improve from 0.06067\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.0726 - val_loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 6s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2341\n",
      "Epoch 1: val_loss improved from inf to 0.08111, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.2341 - val_loss: 0.0811\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0969\n",
      "Epoch 2: val_loss improved from 0.08111 to 0.07675, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 22s 10ms/step - loss: 0.0969 - val_loss: 0.0767\n",
      "Epoch 3/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0875\n",
      "Epoch 3: val_loss improved from 0.07675 to 0.06914, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 22s 9ms/step - loss: 0.0875 - val_loss: 0.0691\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0834\n",
      "Epoch 4: val_loss improved from 0.06914 to 0.06343, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0833 - val_loss: 0.0634\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0802\n",
      "Epoch 5: val_loss improved from 0.06343 to 0.06086, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0802 - val_loss: 0.0609\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0777\n",
      "Epoch 6: val_loss did not improve from 0.06086\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0777 - val_loss: 0.0626\n",
      "Epoch 7/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0757\n",
      "Epoch 7: val_loss did not improve from 0.06086\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0757 - val_loss: 0.0621\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0746\n",
      "Epoch 8: val_loss improved from 0.06086 to 0.05870, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0746 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0735\n",
      "Epoch 9: val_loss did not improve from 0.05870\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0736 - val_loss: 0.0610\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0725\n",
      "Epoch 10: val_loss did not improve from 0.05870\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.0725 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "2576/2576 [==============================] - 10s 4ms/step\n",
      "2576/2576 [==============================] - 13s 5ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2330\n",
      "Epoch 1: val_loss improved from inf to 0.08872, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.2330 - val_loss: 0.0887\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0975\n",
      "Epoch 2: val_loss improved from 0.08872 to 0.07565, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.0975 - val_loss: 0.0756\n",
      "Epoch 3/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0873\n",
      "Epoch 3: val_loss improved from 0.07565 to 0.06882, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.0873 - val_loss: 0.0688\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0820\n",
      "Epoch 4: val_loss improved from 0.06882 to 0.06388, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 32s 14ms/step - loss: 0.0820 - val_loss: 0.0639\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0790\n",
      "Epoch 5: val_loss did not improve from 0.06388\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.0790 - val_loss: 0.0689\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0778\n",
      "Epoch 6: val_loss did not improve from 0.06388\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.0778 - val_loss: 0.0746\n",
      "Epoch 7/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0759\n",
      "Epoch 7: val_loss improved from 0.06388 to 0.06091, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 29s 12ms/step - loss: 0.0760 - val_loss: 0.0609\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0739\n",
      "Epoch 8: val_loss did not improve from 0.06091\n",
      "2317/2317 [==============================] - 45s 19ms/step - loss: 0.0739 - val_loss: 0.0612\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0734\n",
      "Epoch 9: val_loss improved from 0.06091 to 0.05930, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 22s 10ms/step - loss: 0.0734 - val_loss: 0.0593\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0730\n",
      "Epoch 10: val_loss did not improve from 0.05930\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.0730 - val_loss: 0.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 13s 6ms/step\n",
      "2317/2317 [==============================] - 12s 5ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 25s 10ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2368\n",
      "Epoch 1: val_loss improved from inf to 0.08561, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.2365 - val_loss: 0.0856\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0982\n",
      "Epoch 2: val_loss improved from 0.08561 to 0.07258, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.0982 - val_loss: 0.0726\n",
      "Epoch 3/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.0882\n",
      "Epoch 3: val_loss improved from 0.07258 to 0.06890, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0882 - val_loss: 0.0689\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0834\n",
      "Epoch 4: val_loss improved from 0.06890 to 0.06683, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0834 - val_loss: 0.0668\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0796\n",
      "Epoch 5: val_loss improved from 0.06683 to 0.06523, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0796 - val_loss: 0.0652\n",
      "Epoch 6/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0773\n",
      "Epoch 6: val_loss improved from 0.06523 to 0.06213, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0773 - val_loss: 0.0621\n",
      "Epoch 7/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.0759\n",
      "Epoch 7: val_loss did not improve from 0.06213\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0758 - val_loss: 0.0641\n",
      "Epoch 8/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0744\n",
      "Epoch 8: val_loss improved from 0.06213 to 0.06060, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.0744 - val_loss: 0.0606\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0731\n",
      "Epoch 9: val_loss improved from 0.06060 to 0.05989, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0731 - val_loss: 0.0599\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0724\n",
      "Epoch 10: val_loss did not improve from 0.05989\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0724 - val_loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "623/623 [==============================] - 2s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2286\n",
      "Epoch 1: val_loss improved from inf to 0.08520, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.2285 - val_loss: 0.0852\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.0958\n",
      "Epoch 2: val_loss improved from 0.08520 to 0.07776, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0960 - val_loss: 0.0778\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0868\n",
      "Epoch 3: val_loss improved from 0.07776 to 0.07246, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0868 - val_loss: 0.0725\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0818\n",
      "Epoch 4: val_loss improved from 0.07246 to 0.06992, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0818 - val_loss: 0.0699\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0785\n",
      "Epoch 5: val_loss improved from 0.06992 to 0.06453, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0785 - val_loss: 0.0645\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0770\n",
      "Epoch 6: val_loss did not improve from 0.06453\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0770 - val_loss: 0.0689\n",
      "Epoch 7/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0755\n",
      "Epoch 7: val_loss did not improve from 0.06453\n",
      "2317/2317 [==============================] - 15s 7ms/step - loss: 0.0755 - val_loss: 0.0691\n",
      "Epoch 8/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0742\n",
      "Epoch 8: val_loss improved from 0.06453 to 0.06273, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0742 - val_loss: 0.0627\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0731\n",
      "Epoch 9: val_loss improved from 0.06273 to 0.06170, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.0731 - val_loss: 0.0617\n",
      "Epoch 10/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0725\n",
      "Epoch 10: val_loss improved from 0.06170 to 0.06159, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0724 - val_loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "623/623 [==============================] - 2s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2295\n",
      "Epoch 1: val_loss improved from inf to 0.08814, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 7ms/step - loss: 0.2295 - val_loss: 0.0881\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0964\n",
      "Epoch 2: val_loss improved from 0.08814 to 0.07745, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0964 - val_loss: 0.0775\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0868\n",
      "Epoch 3: val_loss improved from 0.07745 to 0.07092, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.0868 - val_loss: 0.0709\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0819\n",
      "Epoch 4: val_loss did not improve from 0.07092\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0819 - val_loss: 0.0725\n",
      "Epoch 5/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0797\n",
      "Epoch 5: val_loss improved from 0.07092 to 0.06785, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0796 - val_loss: 0.0679\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0768\n",
      "Epoch 6: val_loss improved from 0.06785 to 0.06758, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0768 - val_loss: 0.0676\n",
      "Epoch 7/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0753\n",
      "Epoch 7: val_loss improved from 0.06758 to 0.06643, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0753 - val_loss: 0.0664\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.0742\n",
      "Epoch 8: val_loss improved from 0.06643 to 0.06500, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.0742 - val_loss: 0.0650\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0731\n",
      "Epoch 9: val_loss improved from 0.06500 to 0.06258, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 22s 9ms/step - loss: 0.0731 - val_loss: 0.0626\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0721\n",
      "Epoch 10: val_loss did not improve from 0.06258\n",
      "2317/2317 [==============================] - 25s 11ms/step - loss: 0.0721 - val_loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_2_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 9s 3ms/step\n",
      "2576/2576 [==============================] - 10s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.8591028584477268 \n",
      "Average MSE on tiling: 0.06342161164762114 \n",
      "Average correlation on random: 0.8580967521958952 \n",
      "Average MSE on random: 0.03841844253925453 \n",
      "Average correlation on ChrV: 0.7238504451973244 \n",
      "Average MSE on ChrV: 0.13873573399336006 \n",
      "Average correlation on CN: 0.8147196669481815 \n",
      "Average MSE on CN: 0.0740896845728389\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 2s 896us/step\n",
      "390/390 [==============================] - 0s 667us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 4s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "second_conv_model = Model(inputs = model.input, outputs = model.layers[5].output)\n",
    "second_conv_output = second_conv_model.predict(X5)\n",
    "pd.DataFrame(second_conv_output.reshape(second_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_second_conv_output\")\n",
    "second_conv_output_random = second_conv_model.predict(X3)\n",
    "pd.DataFrame(second_conv_output_random.reshape(second_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_second_conv_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
