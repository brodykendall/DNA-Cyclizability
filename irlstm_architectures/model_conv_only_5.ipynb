{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"conv_only_5\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(8, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 24*48))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    # print(outputs.shape)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:29:32.655962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2884\n",
      "Epoch 1: val_loss improved from inf to 0.21427, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.2882 - val_loss: 0.2143\n",
      "Epoch 2/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2243\n",
      "Epoch 2: val_loss improved from 0.21427 to 0.20901, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2242 - val_loss: 0.2090\n",
      "Epoch 3/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 3: val_loss improved from 0.20901 to 0.20759, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2218 - val_loss: 0.2076\n",
      "Epoch 4/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2209\n",
      "Epoch 4: val_loss improved from 0.20759 to 0.20746, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2209 - val_loss: 0.2075\n",
      "Epoch 5/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2206\n",
      "Epoch 5: val_loss did not improve from 0.20746\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2206 - val_loss: 0.2076\n",
      "Epoch 6/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2205\n",
      "Epoch 6: val_loss improved from 0.20746 to 0.20719, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2204 - val_loss: 0.2072\n",
      "Epoch 7/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2205\n",
      "Epoch 7: val_loss did not improve from 0.20719\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2205 - val_loss: 0.2105\n",
      "Epoch 8/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2202\n",
      "Epoch 8: val_loss improved from 0.20719 to 0.20685, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2201 - val_loss: 0.2069\n",
      "Epoch 9/10\n",
      "2285/2317 [============================>.] - ETA: 0s - loss: 0.2200\n",
      "Epoch 9: val_loss did not improve from 0.20685\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2202 - val_loss: 0.2069\n",
      "Epoch 10/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2197\n",
      "Epoch 10: val_loss did not improve from 0.20685\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2197 - val_loss: 0.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 794us/step\n",
      "2317/2317 [==============================] - 2s 836us/step\n",
      "623/623 [==============================] - 1s 835us/step\n",
      "623/623 [==============================] - 1s 827us/step\n",
      "390/390 [==============================] - 0s 806us/step\n",
      "390/390 [==============================] - 0s 817us/step\n",
      "258/258 [==============================] - 0s 822us/step\n",
      "258/258 [==============================] - 0s 825us/step\n",
      "2576/2576 [==============================] - 2s 821us/step\n",
      "2576/2576 [==============================] - 2s 878us/step\n",
      "Epoch 1/10\n",
      "2283/2317 [============================>.] - ETA: 0s - loss: 0.3188\n",
      "Epoch 1: val_loss improved from inf to 0.21881, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.3173 - val_loss: 0.2188\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2196\n",
      "Epoch 2: val_loss did not improve from 0.21881\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2197 - val_loss: 0.2193\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2176\n",
      "Epoch 3: val_loss improved from 0.21881 to 0.21665, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2177 - val_loss: 0.2167\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2173\n",
      "Epoch 4: val_loss improved from 0.21665 to 0.21528, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2174 - val_loss: 0.2153\n",
      "Epoch 5/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2179\n",
      "Epoch 5: val_loss did not improve from 0.21528\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2178 - val_loss: 0.2158\n",
      "Epoch 6/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2175\n",
      "Epoch 6: val_loss did not improve from 0.21528\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2175 - val_loss: 0.2165\n",
      "Epoch 7/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2169\n",
      "Epoch 7: val_loss did not improve from 0.21528\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2169 - val_loss: 0.2165\n",
      "Epoch 8/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 8: val_loss improved from 0.21528 to 0.21464, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2170 - val_loss: 0.2146\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2165\n",
      "Epoch 9: val_loss did not improve from 0.21464\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2165 - val_loss: 0.2152\n",
      "Epoch 10/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 10: val_loss did not improve from 0.21464\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2167 - val_loss: 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 924us/step\n",
      "2317/2317 [==============================] - 2s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 0s 831us/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 2ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.3084\n",
      "Epoch 1: val_loss improved from inf to 0.22106, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.3077 - val_loss: 0.2211\n",
      "Epoch 2/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2185\n",
      "Epoch 2: val_loss improved from 0.22106 to 0.22067, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 8s 3ms/step - loss: 0.2184 - val_loss: 0.2207\n",
      "Epoch 3/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2165\n",
      "Epoch 3: val_loss improved from 0.22067 to 0.21917, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2165 - val_loss: 0.2192\n",
      "Epoch 4/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.2163\n",
      "Epoch 4: val_loss improved from 0.21917 to 0.21754, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2160 - val_loss: 0.2175\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 5: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2157 - val_loss: 0.2203\n",
      "Epoch 6/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 6: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2155 - val_loss: 0.2176\n",
      "Epoch 7/10\n",
      "2285/2317 [============================>.] - ETA: 0s - loss: 0.2154\n",
      "Epoch 7: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2154 - val_loss: 0.2207\n",
      "Epoch 8/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2153\n",
      "Epoch 8: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2153 - val_loss: 0.2199\n",
      "Epoch 9/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2152\n",
      "Epoch 9: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2153 - val_loss: 0.2179\n",
      "Epoch 10/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2154\n",
      "Epoch 10: val_loss did not improve from 0.21754\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2154 - val_loss: 0.2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 805us/step\n",
      "2317/2317 [==============================] - 2s 734us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 964us/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 950us/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 2s 806us/step\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.3013\n",
      "Epoch 1: val_loss improved from inf to 0.22191, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3013 - val_loss: 0.2219\n",
      "Epoch 2/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2183\n",
      "Epoch 2: val_loss improved from 0.22191 to 0.22087, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2181 - val_loss: 0.2209\n",
      "Epoch 3/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 3: val_loss did not improve from 0.22087\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2175 - val_loss: 0.2219\n",
      "Epoch 4/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.2165\n",
      "Epoch 4: val_loss improved from 0.22087 to 0.21922, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2167 - val_loss: 0.2192\n",
      "Epoch 5/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2168\n",
      "Epoch 5: val_loss did not improve from 0.21922\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2168 - val_loss: 0.2225\n",
      "Epoch 6/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2166\n",
      "Epoch 6: val_loss improved from 0.21922 to 0.21914, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2165 - val_loss: 0.2191\n",
      "Epoch 7/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2164\n",
      "Epoch 7: val_loss did not improve from 0.21914\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2162 - val_loss: 0.2201\n",
      "Epoch 8/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2164\n",
      "Epoch 8: val_loss improved from 0.21914 to 0.21858, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2163 - val_loss: 0.2186\n",
      "Epoch 9/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2161\n",
      "Epoch 9: val_loss improved from 0.21858 to 0.21790, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2159 - val_loss: 0.2179\n",
      "Epoch 10/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.2161\n",
      "Epoch 10: val_loss did not improve from 0.21790\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2161 - val_loss: 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 2s 786us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 983us/step\n",
      "390/390 [==============================] - 0s 902us/step\n",
      "258/258 [==============================] - 0s 867us/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 2s 954us/step\n",
      "Epoch 1/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.3094\n",
      "Epoch 1: val_loss improved from inf to 0.21976, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.3089 - val_loss: 0.2198\n",
      "Epoch 2/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2194\n",
      "Epoch 2: val_loss improved from 0.21976 to 0.21632, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2194 - val_loss: 0.2163\n",
      "Epoch 3/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2179\n",
      "Epoch 3: val_loss did not improve from 0.21632\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2179 - val_loss: 0.2182\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2169\n",
      "Epoch 4: val_loss improved from 0.21632 to 0.21529, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2169 - val_loss: 0.2153\n",
      "Epoch 5/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2162\n",
      "Epoch 5: val_loss improved from 0.21529 to 0.21446, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2164 - val_loss: 0.2145\n",
      "Epoch 6/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 6: val_loss improved from 0.21446 to 0.21437, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2166 - val_loss: 0.2144\n",
      "Epoch 7/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2160\n",
      "Epoch 7: val_loss did not improve from 0.21437\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2160 - val_loss: 0.2192\n",
      "Epoch 8/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 8: val_loss did not improve from 0.21437\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2154 - val_loss: 0.2182\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2162\n",
      "Epoch 9: val_loss did not improve from 0.21437\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2161 - val_loss: 0.2147\n",
      "Epoch 10/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2159\n",
      "Epoch 10: val_loss improved from 0.21437 to 0.21419, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2158 - val_loss: 0.2142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 1ms/step\n",
      "2317/2317 [==============================] - 2s 990us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 4s 2ms/step\n",
      "2576/2576 [==============================] - 4s 2ms/step\n",
      "Epoch 1/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.3009\n",
      "Epoch 1: val_loss improved from inf to 0.21341, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.3005 - val_loss: 0.2134\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2213\n",
      "Epoch 2: val_loss improved from 0.21341 to 0.21042, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2213 - val_loss: 0.2104\n",
      "Epoch 3/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2196\n",
      "Epoch 3: val_loss improved from 0.21042 to 0.21022, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2196 - val_loss: 0.2102\n",
      "Epoch 4/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2196\n",
      "Epoch 4: val_loss improved from 0.21022 to 0.21020, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2198 - val_loss: 0.2102\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2199\n",
      "Epoch 5: val_loss did not improve from 0.21020\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2199 - val_loss: 0.2113\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2196\n",
      "Epoch 6: val_loss improved from 0.21020 to 0.20890, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2196 - val_loss: 0.2089\n",
      "Epoch 7/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2187\n",
      "Epoch 7: val_loss did not improve from 0.20890\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2185 - val_loss: 0.2096\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2183\n",
      "Epoch 8: val_loss did not improve from 0.20890\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2184 - val_loss: 0.2089\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2185\n",
      "Epoch 9: val_loss did not improve from 0.20890\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2185 - val_loss: 0.2097\n",
      "Epoch 10/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 10: val_loss did not improve from 0.20890\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2190 - val_loss: 0.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.3032\n",
      "Epoch 1: val_loss improved from inf to 0.21897, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.3022 - val_loss: 0.2190\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2190\n",
      "Epoch 2: val_loss improved from 0.21897 to 0.21246, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2190 - val_loss: 0.2125\n",
      "Epoch 3/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2180\n",
      "Epoch 3: val_loss improved from 0.21246 to 0.21209, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2178 - val_loss: 0.2121\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2170\n",
      "Epoch 4: val_loss did not improve from 0.21209\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2170 - val_loss: 0.2148\n",
      "Epoch 5/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 5: val_loss did not improve from 0.21209\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2167 - val_loss: 0.2135\n",
      "Epoch 6/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2163\n",
      "Epoch 6: val_loss did not improve from 0.21209\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2163 - val_loss: 0.2132\n",
      "Epoch 7/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2170\n",
      "Epoch 7: val_loss improved from 0.21209 to 0.21068, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2168 - val_loss: 0.2107\n",
      "Epoch 8/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2165\n",
      "Epoch 8: val_loss did not improve from 0.21068\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2165 - val_loss: 0.2112\n",
      "Epoch 9/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2164\n",
      "Epoch 9: val_loss improved from 0.21068 to 0.21068, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2164 - val_loss: 0.2107\n",
      "Epoch 10/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2159\n",
      "Epoch 10: val_loss did not improve from 0.21068\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2160 - val_loss: 0.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 1ms/step\n",
      "2317/2317 [==============================] - 2s 963us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "390/390 [==============================] - 0s 901us/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 896us/step\n",
      "2576/2576 [==============================] - 3s 991us/step\n",
      "2576/2576 [==============================] - 3s 988us/step\n",
      "Epoch 1/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.3190\n",
      "Epoch 1: val_loss improved from inf to 0.22323, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.3187 - val_loss: 0.2232\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2205\n",
      "Epoch 2: val_loss improved from 0.22323 to 0.21663, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2205 - val_loss: 0.2166\n",
      "Epoch 3/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2192\n",
      "Epoch 3: val_loss did not improve from 0.21663\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2191 - val_loss: 0.2168\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2187\n",
      "Epoch 4: val_loss improved from 0.21663 to 0.21539, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2187 - val_loss: 0.2154\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2179\n",
      "Epoch 5: val_loss did not improve from 0.21539\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2179 - val_loss: 0.2167\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2177\n",
      "Epoch 6: val_loss improved from 0.21539 to 0.21511, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2177 - val_loss: 0.2151\n",
      "Epoch 7/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2178\n",
      "Epoch 7: val_loss did not improve from 0.21511\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2177 - val_loss: 0.2160\n",
      "Epoch 8/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2176\n",
      "Epoch 8: val_loss did not improve from 0.21511\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2176 - val_loss: 0.2171\n",
      "Epoch 9/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2175\n",
      "Epoch 9: val_loss improved from 0.21511 to 0.21461, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2171 - val_loss: 0.2146\n",
      "Epoch 10/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 10: val_loss did not improve from 0.21461\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2172 - val_loss: 0.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 2s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.3085\n",
      "Epoch 1: val_loss improved from inf to 0.20974, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.3076 - val_loss: 0.2097\n",
      "Epoch 2/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2194\n",
      "Epoch 2: val_loss improved from 0.20974 to 0.20527, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2195 - val_loss: 0.2053\n",
      "Epoch 3/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2185\n",
      "Epoch 3: val_loss improved from 0.20527 to 0.20390, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2184 - val_loss: 0.2039\n",
      "Epoch 4/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2178\n",
      "Epoch 4: val_loss did not improve from 0.20390\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2177 - val_loss: 0.2049\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2175\n",
      "Epoch 5: val_loss did not improve from 0.20390\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2176 - val_loss: 0.2056\n",
      "Epoch 6/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 6: val_loss improved from 0.20390 to 0.20317, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2169 - val_loss: 0.2032\n",
      "Epoch 7/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2170\n",
      "Epoch 7: val_loss did not improve from 0.20317\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2169 - val_loss: 0.2037\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2164\n",
      "Epoch 8: val_loss did not improve from 0.20317\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2165 - val_loss: 0.2037\n",
      "Epoch 9/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2171\n",
      "Epoch 9: val_loss improved from 0.20317 to 0.20310, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2171 - val_loss: 0.2031\n",
      "Epoch 10/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2166\n",
      "Epoch 10: val_loss did not improve from 0.20310\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2165 - val_loss: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 722us/step\n",
      "2317/2317 [==============================] - 2s 717us/step\n",
      "623/623 [==============================] - 0s 741us/step\n",
      "623/623 [==============================] - 0s 721us/step\n",
      "390/390 [==============================] - 0s 722us/step\n",
      "390/390 [==============================] - 0s 750us/step\n",
      "258/258 [==============================] - 0s 760us/step\n",
      "258/258 [==============================] - 0s 746us/step\n",
      "2576/2576 [==============================] - 2s 728us/step\n",
      "2576/2576 [==============================] - 2s 731us/step\n",
      "Epoch 1/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.3141\n",
      "Epoch 1: val_loss improved from inf to 0.21564, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3132 - val_loss: 0.2156\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2204\n",
      "Epoch 2: val_loss did not improve from 0.21564\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2204 - val_loss: 0.2177\n",
      "Epoch 3/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2197\n",
      "Epoch 3: val_loss did not improve from 0.21564\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2197 - val_loss: 0.2170\n",
      "Epoch 4/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2192\n",
      "Epoch 4: val_loss did not improve from 0.21564\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2191 - val_loss: 0.2189\n",
      "Epoch 5/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2186\n",
      "Epoch 5: val_loss improved from 0.21564 to 0.21524, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2187 - val_loss: 0.2152\n",
      "Epoch 6/10\n",
      "2286/2317 [============================>.] - ETA: 0s - loss: 0.2183\n",
      "Epoch 6: val_loss improved from 0.21524 to 0.21504, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2185 - val_loss: 0.2150\n",
      "Epoch 7/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.2170\n",
      "Epoch 7: val_loss improved from 0.21504 to 0.21134, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2170 - val_loss: 0.2113\n",
      "Epoch 8/10\n",
      "2285/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 8: val_loss did not improve from 0.21134\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2169 - val_loss: 0.2152\n",
      "Epoch 9/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2168\n",
      "Epoch 9: val_loss did not improve from 0.21134\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2168 - val_loss: 0.2125\n",
      "Epoch 10/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.2166\n",
      "Epoch 10: val_loss improved from 0.21134 to 0.21087, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2167 - val_loss: 0.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_5_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 708us/step\n",
      "2317/2317 [==============================] - 2s 728us/step\n",
      "623/623 [==============================] - 0s 742us/step\n",
      "623/623 [==============================] - 0s 724us/step\n",
      "390/390 [==============================] - 0s 715us/step\n",
      "390/390 [==============================] - 0s 750us/step\n",
      "258/258 [==============================] - 0s 732us/step\n",
      "258/258 [==============================] - 0s 738us/step\n",
      "2576/2576 [==============================] - 2s 717us/step\n",
      "2576/2576 [==============================] - 2s 717us/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.34968205939295266 \n",
      "Average MSE on tiling: 0.2126284461927145 \n",
      "Average correlation on random: 0.37962935267120634 \n",
      "Average MSE on random: 0.12319482575942367 \n",
      "Average correlation on ChrV: 0.277817324164291 \n",
      "Average MSE on ChrV: 0.2685321505857016 \n",
      "Average correlation on CN: 0.2946417553273579 \n",
      "Average MSE on CN: 0.19873594917836232\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 2s 619us/step\n",
      "390/390 [==============================] - 0s 610us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = model.layers[1].weights[0]\n",
    "first_conv_biases = model.layers[1].weights[1]\n",
    "# Format: [Position 0: A, C, G, T, Position 1: A, C, G, T, Position 2: A, C, G, T]\n",
    "pd.DataFrame(array(first_conv_weights).transpose((3,2,0,1)).reshape(first_conv_weights.shape[-1], -1)).to_csv(save_path + model_name+\"_tiling_first_conv_kernels\")\n",
    "pd.DataFrame(first_conv_biases).to_csv(save_path + model_name+\"_tiling_first_conv_biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
