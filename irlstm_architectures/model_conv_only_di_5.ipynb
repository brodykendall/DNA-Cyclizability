{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:37:06.080948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"conv_only_di_5\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(49, 16, 1))\n",
    "        \n",
    "    x = Conv2D(8, kernel_size=(21,16),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 24*48))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    # print(outputs.shape)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diOneHot(sequence):\n",
    "    code = {\"AA\": [0], \"AC\": [1], \"AG\": [2], \"AT\": [3],\n",
    "            \"CA\": [4], \"CC\": [5], \"CG\": [6], \"CT\": [7], \n",
    "            \"GA\": [8], \"GC\": [9], \"GG\": [10], \"GT\": [11], \n",
    "            \"TA\": [12], \"TC\": [13], \"TG\": [14], \"TT\": [15],  \"N\": [16]}\n",
    "    onehot_encoded_seq = []\n",
    "    for i, _ in enumerate(sequence[:(len(sequence)-1)]):\n",
    "        onehot_encoded = np.zeros(17)\n",
    "        onehot_encoded[code[sequence[i:i+2]]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:16])\n",
    "    return onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(diOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],49,16,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(diOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],49,16,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(diOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],49,16,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(diOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],49,16,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:38:19.328891: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2537\n",
      "Epoch 1: val_loss improved from inf to 0.16909, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2535 - val_loss: 0.1691\n",
      "Epoch 2/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1623\n",
      "Epoch 2: val_loss improved from 0.16909 to 0.15312, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1622 - val_loss: 0.1531\n",
      "Epoch 3/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.1573\n",
      "Epoch 3: val_loss improved from 0.15312 to 0.14858, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1572 - val_loss: 0.1486\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1552\n",
      "Epoch 4: val_loss improved from 0.14858 to 0.14828, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1551 - val_loss: 0.1483\n",
      "Epoch 5/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.1522\n",
      "Epoch 5: val_loss improved from 0.14828 to 0.14158, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1524 - val_loss: 0.1416\n",
      "Epoch 6/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.1485\n",
      "Epoch 6: val_loss improved from 0.14158 to 0.14059, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1486 - val_loss: 0.1406\n",
      "Epoch 7/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.1473\n",
      "Epoch 7: val_loss improved from 0.14059 to 0.13744, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1471 - val_loss: 0.1374\n",
      "Epoch 8/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.1467\n",
      "Epoch 8: val_loss did not improve from 0.13744\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1468 - val_loss: 0.1378\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1446\n",
      "Epoch 9: val_loss did not improve from 0.13744\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1446 - val_loss: 0.1376\n",
      "Epoch 10/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.1455\n",
      "Epoch 10: val_loss did not improve from 0.13744\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1455 - val_loss: 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 697us/step\n",
      "2317/2317 [==============================] - 2s 708us/step\n",
      "623/623 [==============================] - 0s 696us/step\n",
      "623/623 [==============================] - 0s 682us/step\n",
      "390/390 [==============================] - 0s 683us/step\n",
      "390/390 [==============================] - 0s 690us/step\n",
      "258/258 [==============================] - 0s 689us/step\n",
      "258/258 [==============================] - 0s 685us/step\n",
      "2576/2576 [==============================] - 2s 826us/step\n",
      "2576/2576 [==============================] - 2s 736us/step\n",
      "Epoch 1/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1: val_loss improved from inf to 0.16477, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2450 - val_loss: 0.1648\n",
      "Epoch 2/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.1639\n",
      "Epoch 2: val_loss improved from 0.16477 to 0.14849, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1639 - val_loss: 0.1485\n",
      "Epoch 3/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.1586\n",
      "Epoch 3: val_loss improved from 0.14849 to 0.14525, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1586 - val_loss: 0.1452\n",
      "Epoch 4/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.1546\n",
      "Epoch 4: val_loss improved from 0.14525 to 0.14155, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1549 - val_loss: 0.1415\n",
      "Epoch 5/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.1517\n",
      "Epoch 5: val_loss improved from 0.14155 to 0.13976, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1517 - val_loss: 0.1398\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1507\n",
      "Epoch 6: val_loss improved from 0.13976 to 0.13766, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1506 - val_loss: 0.1377\n",
      "Epoch 7/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1493\n",
      "Epoch 7: val_loss improved from 0.13766 to 0.13619, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1492 - val_loss: 0.1362\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1477\n",
      "Epoch 8: val_loss improved from 0.13619 to 0.13529, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1477 - val_loss: 0.1353\n",
      "Epoch 9/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.1473\n",
      "Epoch 9: val_loss improved from 0.13529 to 0.13503, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1472 - val_loss: 0.1350\n",
      "Epoch 10/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.1463\n",
      "Epoch 10: val_loss improved from 0.13503 to 0.13477, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1463 - val_loss: 0.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 726us/step\n",
      "2317/2317 [==============================] - 2s 736us/step\n",
      "623/623 [==============================] - 0s 732us/step\n",
      "623/623 [==============================] - 0s 687us/step\n",
      "390/390 [==============================] - 0s 701us/step\n",
      "390/390 [==============================] - 0s 691us/step\n",
      "258/258 [==============================] - 0s 693us/step\n",
      "258/258 [==============================] - 0s 744us/step\n",
      "2576/2576 [==============================] - 2s 697us/step\n",
      "2576/2576 [==============================] - 2s 693us/step\n",
      "Epoch 1/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2618\n",
      "Epoch 1: val_loss improved from inf to 0.15064, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2610 - val_loss: 0.1506\n",
      "Epoch 2/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1549\n",
      "Epoch 2: val_loss improved from 0.15064 to 0.13657, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1550 - val_loss: 0.1366\n",
      "Epoch 3/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.1466\n",
      "Epoch 3: val_loss improved from 0.13657 to 0.13098, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1464 - val_loss: 0.1310\n",
      "Epoch 4/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.1432\n",
      "Epoch 4: val_loss improved from 0.13098 to 0.12674, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1432 - val_loss: 0.1267\n",
      "Epoch 5/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1410\n",
      "Epoch 5: val_loss improved from 0.12674 to 0.12426, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1410 - val_loss: 0.1243\n",
      "Epoch 6/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.1405\n",
      "Epoch 6: val_loss did not improve from 0.12426\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1404 - val_loss: 0.1248\n",
      "Epoch 7/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.1388\n",
      "Epoch 7: val_loss improved from 0.12426 to 0.12384, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.1388 - val_loss: 0.1238\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 8: val_loss did not improve from 0.12384\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1384 - val_loss: 0.1239\n",
      "Epoch 9/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.1382\n",
      "Epoch 9: val_loss improved from 0.12384 to 0.12361, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1382 - val_loss: 0.1236\n",
      "Epoch 10/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.1370\n",
      "Epoch 10: val_loss improved from 0.12361 to 0.12162, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1369 - val_loss: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 696us/step\n",
      "2317/2317 [==============================] - 2s 687us/step\n",
      "623/623 [==============================] - 0s 688us/step\n",
      "623/623 [==============================] - 0s 687us/step\n",
      "390/390 [==============================] - 0s 685us/step\n",
      "390/390 [==============================] - 0s 687us/step\n",
      "258/258 [==============================] - 0s 683us/step\n",
      "258/258 [==============================] - 0s 692us/step\n",
      "2576/2576 [==============================] - 2s 686us/step\n",
      "2576/2576 [==============================] - 2s 690us/step\n",
      "Epoch 1/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.2532\n",
      "Epoch 1: val_loss improved from inf to 0.15741, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2527 - val_loss: 0.1574\n",
      "Epoch 2/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1609\n",
      "Epoch 2: val_loss improved from 0.15741 to 0.15050, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1609 - val_loss: 0.1505\n",
      "Epoch 3/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.1584\n",
      "Epoch 3: val_loss improved from 0.15050 to 0.15048, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1583 - val_loss: 0.1505\n",
      "Epoch 4/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1561\n",
      "Epoch 4: val_loss improved from 0.15048 to 0.14579, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1560 - val_loss: 0.1458\n",
      "Epoch 5/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1544\n",
      "Epoch 5: val_loss did not improve from 0.14579\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1544 - val_loss: 0.1460\n",
      "Epoch 6/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.1544\n",
      "Epoch 6: val_loss improved from 0.14579 to 0.14526, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1543 - val_loss: 0.1453\n",
      "Epoch 7/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 7: val_loss improved from 0.14526 to 0.14484, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1534 - val_loss: 0.1448\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1529\n",
      "Epoch 8: val_loss did not improve from 0.14484\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1529 - val_loss: 0.1455\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1524\n",
      "Epoch 9: val_loss did not improve from 0.14484\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1524 - val_loss: 0.1459\n",
      "Epoch 10/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.1527\n",
      "Epoch 10: val_loss did not improve from 0.14484\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1526 - val_loss: 0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 678us/step\n",
      "2317/2317 [==============================] - 2s 769us/step\n",
      "623/623 [==============================] - 0s 687us/step\n",
      "623/623 [==============================] - 0s 685us/step\n",
      "390/390 [==============================] - 0s 681us/step\n",
      "390/390 [==============================] - 0s 736us/step\n",
      "258/258 [==============================] - 0s 697us/step\n",
      "258/258 [==============================] - 0s 730us/step\n",
      "2576/2576 [==============================] - 2s 710us/step\n",
      "2576/2576 [==============================] - 2s 703us/step\n",
      "Epoch 1/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1: val_loss improved from inf to 0.15677, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2449 - val_loss: 0.1568\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1607\n",
      "Epoch 2: val_loss improved from 0.15677 to 0.15184, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1607 - val_loss: 0.1518\n",
      "Epoch 3/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.1567\n",
      "Epoch 3: val_loss improved from 0.15184 to 0.14049, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1567 - val_loss: 0.1405\n",
      "Epoch 4/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.1543\n",
      "Epoch 4: val_loss did not improve from 0.14049\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1542 - val_loss: 0.1410\n",
      "Epoch 5/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.1526\n",
      "Epoch 5: val_loss did not improve from 0.14049\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1527 - val_loss: 0.1409\n",
      "Epoch 6/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.1522\n",
      "Epoch 6: val_loss did not improve from 0.14049\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1523 - val_loss: 0.1415\n",
      "Epoch 7/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1512\n",
      "Epoch 7: val_loss improved from 0.14049 to 0.13456, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1512 - val_loss: 0.1346\n",
      "Epoch 8/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.1501\n",
      "Epoch 8: val_loss did not improve from 0.13456\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1502 - val_loss: 0.1364\n",
      "Epoch 9/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.1489\n",
      "Epoch 9: val_loss did not improve from 0.13456\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1489 - val_loss: 0.1382\n",
      "Epoch 10/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1483\n",
      "Epoch 10: val_loss improved from 0.13456 to 0.13341, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1483 - val_loss: 0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 714us/step\n",
      "2317/2317 [==============================] - 2s 693us/step\n",
      "623/623 [==============================] - 0s 698us/step\n",
      "623/623 [==============================] - 0s 687us/step\n",
      "390/390 [==============================] - 0s 686us/step\n",
      "390/390 [==============================] - 0s 683us/step\n",
      "258/258 [==============================] - 0s 691us/step\n",
      "258/258 [==============================] - 0s 691us/step\n",
      "2576/2576 [==============================] - 2s 708us/step\n",
      "2576/2576 [==============================] - 2s 765us/step\n",
      "Epoch 1/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2599\n",
      "Epoch 1: val_loss improved from inf to 0.14539, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2596 - val_loss: 0.1454\n",
      "Epoch 2/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.1511\n",
      "Epoch 2: val_loss improved from 0.14539 to 0.13589, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1511 - val_loss: 0.1359\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1462\n",
      "Epoch 3: val_loss improved from 0.13589 to 0.13339, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1462 - val_loss: 0.1334\n",
      "Epoch 4/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1440\n",
      "Epoch 4: val_loss improved from 0.13339 to 0.13164, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1440 - val_loss: 0.1316\n",
      "Epoch 5/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1423\n",
      "Epoch 5: val_loss did not improve from 0.13164\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1423 - val_loss: 0.1376\n",
      "Epoch 6/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1417\n",
      "Epoch 6: val_loss improved from 0.13164 to 0.13075, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1417 - val_loss: 0.1307\n",
      "Epoch 7/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.1409\n",
      "Epoch 7: val_loss improved from 0.13075 to 0.12877, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1411 - val_loss: 0.1288\n",
      "Epoch 8/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.1401\n",
      "Epoch 8: val_loss did not improve from 0.12877\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1400 - val_loss: 0.1304\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1399\n",
      "Epoch 9: val_loss improved from 0.12877 to 0.12791, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1399 - val_loss: 0.1279\n",
      "Epoch 10/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.1394\n",
      "Epoch 10: val_loss improved from 0.12791 to 0.12735, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.1394 - val_loss: 0.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 696us/step\n",
      "2317/2317 [==============================] - 2s 685us/step\n",
      "623/623 [==============================] - 0s 691us/step\n",
      "623/623 [==============================] - 0s 687us/step\n",
      "390/390 [==============================] - 0s 687us/step\n",
      "390/390 [==============================] - 0s 684us/step\n",
      "258/258 [==============================] - 0s 691us/step\n",
      "258/258 [==============================] - 0s 693us/step\n",
      "2576/2576 [==============================] - 2s 692us/step\n",
      "2576/2576 [==============================] - 2s 828us/step\n",
      "Epoch 1/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2259\n",
      "Epoch 1: val_loss improved from inf to 0.14276, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2255 - val_loss: 0.1428\n",
      "Epoch 2/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.1545\n",
      "Epoch 2: val_loss improved from 0.14276 to 0.13442, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.1545 - val_loss: 0.1344\n",
      "Epoch 3/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1479\n",
      "Epoch 3: val_loss did not improve from 0.13442\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1479 - val_loss: 0.1393\n",
      "Epoch 4/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.1469\n",
      "Epoch 4: val_loss did not improve from 0.13442\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1469 - val_loss: 0.1375\n",
      "Epoch 5/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.1452\n",
      "Epoch 5: val_loss improved from 0.13442 to 0.13022, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1451 - val_loss: 0.1302\n",
      "Epoch 6/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.1441\n",
      "Epoch 6: val_loss improved from 0.13022 to 0.12886, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1442 - val_loss: 0.1289\n",
      "Epoch 7/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1436\n",
      "Epoch 7: val_loss did not improve from 0.12886\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1436 - val_loss: 0.1289\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1425\n",
      "Epoch 8: val_loss improved from 0.12886 to 0.12837, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1426 - val_loss: 0.1284\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1431\n",
      "Epoch 9: val_loss did not improve from 0.12837\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.1431 - val_loss: 0.1294\n",
      "Epoch 10/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.1426\n",
      "Epoch 10: val_loss improved from 0.12837 to 0.12754, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1425 - val_loss: 0.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 737us/step\n",
      "2317/2317 [==============================] - 2s 831us/step\n",
      "623/623 [==============================] - 0s 727us/step\n",
      "623/623 [==============================] - 0s 713us/step\n",
      "390/390 [==============================] - 0s 717us/step\n",
      "390/390 [==============================] - 0s 721us/step\n",
      "258/258 [==============================] - 0s 721us/step\n",
      "258/258 [==============================] - 0s 714us/step\n",
      "2576/2576 [==============================] - 2s 824us/step\n",
      "2576/2576 [==============================] - 2s 712us/step\n",
      "Epoch 1/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2565\n",
      "Epoch 1: val_loss improved from inf to 0.15025, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2556 - val_loss: 0.1503\n",
      "Epoch 2/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1551\n",
      "Epoch 2: val_loss improved from 0.15025 to 0.14096, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1551 - val_loss: 0.1410\n",
      "Epoch 3/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.1490\n",
      "Epoch 3: val_loss improved from 0.14096 to 0.14044, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1492 - val_loss: 0.1404\n",
      "Epoch 4/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.1458\n",
      "Epoch 4: val_loss improved from 0.14044 to 0.13582, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1460 - val_loss: 0.1358\n",
      "Epoch 5/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.1452\n",
      "Epoch 5: val_loss did not improve from 0.13582\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.1452 - val_loss: 0.1372\n",
      "Epoch 6/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.1435\n",
      "Epoch 6: val_loss did not improve from 0.13582\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.1435 - val_loss: 0.1369\n",
      "Epoch 7/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.1432\n",
      "Epoch 7: val_loss improved from 0.13582 to 0.13498, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.1431 - val_loss: 0.1350\n",
      "Epoch 8/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1417\n",
      "Epoch 8: val_loss improved from 0.13498 to 0.13268, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8.h5\n",
      "2317/2317 [==============================] - 8s 3ms/step - loss: 0.1417 - val_loss: 0.1327\n",
      "Epoch 9/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.1414\n",
      "Epoch 9: val_loss did not improve from 0.13268\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.1415 - val_loss: 0.1345\n",
      "Epoch 10/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.1414\n",
      "Epoch 10: val_loss did not improve from 0.13268\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.1414 - val_loss: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 937us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 955us/step\n",
      "258/258 [==============================] - 0s 946us/step\n",
      "2576/2576 [==============================] - 4s 2ms/step\n",
      "2576/2576 [==============================] - 5s 2ms/step\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2378\n",
      "Epoch 1: val_loss improved from inf to 0.15508, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.2378 - val_loss: 0.1551\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1575\n",
      "Epoch 2: val_loss improved from 0.15508 to 0.15164, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1575 - val_loss: 0.1516\n",
      "Epoch 3/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1559\n",
      "Epoch 3: val_loss improved from 0.15164 to 0.14810, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1559 - val_loss: 0.1481\n",
      "Epoch 4/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1530\n",
      "Epoch 4: val_loss improved from 0.14810 to 0.14428, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1530 - val_loss: 0.1443\n",
      "Epoch 5/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.1497\n",
      "Epoch 5: val_loss improved from 0.14428 to 0.14275, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1497 - val_loss: 0.1428\n",
      "Epoch 6/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1493\n",
      "Epoch 6: val_loss improved from 0.14275 to 0.14065, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1492 - val_loss: 0.1407\n",
      "Epoch 7/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.1484\n",
      "Epoch 7: val_loss did not improve from 0.14065\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1484 - val_loss: 0.1413\n",
      "Epoch 8/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1472\n",
      "Epoch 8: val_loss improved from 0.14065 to 0.14009, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1472 - val_loss: 0.1401\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1467\n",
      "Epoch 9: val_loss did not improve from 0.14009\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1468 - val_loss: 0.1420\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1470\n",
      "Epoch 10: val_loss improved from 0.14009 to 0.13984, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1469 - val_loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 4s 2ms/step\n",
      "2317/2317 [==============================] - 4s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 0s 2ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2597\n",
      "Epoch 1: val_loss improved from inf to 0.15708, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2591 - val_loss: 0.1571\n",
      "Epoch 2/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.1544\n",
      "Epoch 2: val_loss improved from 0.15708 to 0.14025, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.1544 - val_loss: 0.1402\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1489\n",
      "Epoch 3: val_loss improved from 0.14025 to 0.13951, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.1489 - val_loss: 0.1395\n",
      "Epoch 4/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.1468\n",
      "Epoch 4: val_loss improved from 0.13951 to 0.13828, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 8s 4ms/step - loss: 0.1467 - val_loss: 0.1383\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1447\n",
      "Epoch 5: val_loss improved from 0.13828 to 0.13507, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1447 - val_loss: 0.1351\n",
      "Epoch 6/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1422\n",
      "Epoch 6: val_loss improved from 0.13507 to 0.13244, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1422 - val_loss: 0.1324\n",
      "Epoch 7/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1407\n",
      "Epoch 7: val_loss improved from 0.13244 to 0.13128, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1407 - val_loss: 0.1313\n",
      "Epoch 8/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1390\n",
      "Epoch 8: val_loss improved from 0.13128 to 0.12732, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1391 - val_loss: 0.1273\n",
      "Epoch 9/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.1370\n",
      "Epoch 9: val_loss improved from 0.12732 to 0.12729, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10.h5\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1370 - val_loss: 0.1273\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1370\n",
      "Epoch 10: val_loss did not improve from 0.12729\n",
      "2317/2317 [==============================] - 9s 4ms/step - loss: 0.1370 - val_loss: 0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_di_5_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 4s 2ms/step\n",
      "2317/2317 [==============================] - 4s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 0s 2ms/step\n",
      "258/258 [==============================] - 0s 2ms/step\n",
      "2576/2576 [==============================] - 5s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.6303708606728119 \n",
      "Average MSE on tiling: 0.1459739835228377 \n",
      "Average correlation on random: 0.5858507718665155 \n",
      "Average MSE on random: 0.09467333298419112 \n",
      "Average correlation on ChrV: 0.5139940164406387 \n",
      "Average MSE on ChrV: 0.21412225490617015 \n",
      "Average correlation on CN: 0.5747654744415812 \n",
      "Average MSE on CN: 0.1482757141945698\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 4s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = model.layers[1].weights[0]\n",
    "first_conv_biases = model.layers[1].weights[1]\n",
    "# Format: [Position 0: AAA, AAC, ..., CAA, CAC, ..., TTG, TTT  Position 1: AAA, AAC, ..., CAA, CAC, ..., TTG, TTT,\n",
    "# ..., Position 20: AAA, AAC, ..., CAA, CAC, ..., TTG, TTT]\n",
    "pd.DataFrame(array(first_conv_weights).transpose((3,2,0,1)).reshape(first_conv_weights.shape[-1], -1)).to_csv(save_path + model_name+\"_tiling_first_conv_kernels\")\n",
    "pd.DataFrame(first_conv_biases).to_csv(save_path + model_name+\"_tiling_first_conv_biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
