{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"conv_only_2\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(16, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 24*48))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2800\n",
      "Epoch 1: val_loss improved from inf to 0.22880, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.2797 - val_loss: 0.2288\n",
      "Epoch 2/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2186\n",
      "Epoch 2: val_loss improved from 0.22880 to 0.22421, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2185 - val_loss: 0.2242\n",
      "Epoch 3/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 3: val_loss improved from 0.22421 to 0.22268, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2167 - val_loss: 0.2227\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2161\n",
      "Epoch 4: val_loss did not improve from 0.22268\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2161 - val_loss: 0.2324\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2158\n",
      "Epoch 5: val_loss improved from 0.22268 to 0.22165, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2158 - val_loss: 0.2217\n",
      "Epoch 6/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 6: val_loss improved from 0.22165 to 0.22043, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2154 - val_loss: 0.2204\n",
      "Epoch 7/10\n",
      "2283/2317 [============================>.] - ETA: 0s - loss: 0.2153\n",
      "Epoch 7: val_loss did not improve from 0.22043\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2154 - val_loss: 0.2211\n",
      "Epoch 8/10\n",
      "2279/2317 [============================>.] - ETA: 0s - loss: 0.2151\n",
      "Epoch 8: val_loss did not improve from 0.22043\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2151 - val_loss: 0.2230\n",
      "Epoch 9/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2148\n",
      "Epoch 9: val_loss did not improve from 0.22043\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2150 - val_loss: 0.2222\n",
      "Epoch 10/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2154\n",
      "Epoch 10: val_loss did not improve from 0.22043\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2153 - val_loss: 0.2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 1s 575us/step\n",
      "2317/2317 [==============================] - 1s 580us/step\n",
      "623/623 [==============================] - 0s 603us/step\n",
      "623/623 [==============================] - 0s 651us/step\n",
      "390/390 [==============================] - 0s 593us/step\n",
      "390/390 [==============================] - 0s 604us/step\n",
      "258/258 [==============================] - 0s 602us/step\n",
      "258/258 [==============================] - 0s 612us/step\n",
      "2576/2576 [==============================] - 2s 625us/step\n",
      "2576/2576 [==============================] - 2s 588us/step\n",
      "Epoch 1/10\n",
      "2286/2317 [============================>.] - ETA: 0s - loss: 0.2905\n",
      "Epoch 1: val_loss improved from inf to 0.22503, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2894 - val_loss: 0.2250\n",
      "Epoch 2/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2192\n",
      "Epoch 2: val_loss improved from 0.22503 to 0.21561, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2193 - val_loss: 0.2156\n",
      "Epoch 3/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2174\n",
      "Epoch 3: val_loss did not improve from 0.21561\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2172 - val_loss: 0.2166\n",
      "Epoch 4/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.2163\n",
      "Epoch 4: val_loss improved from 0.21561 to 0.21219, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2161 - val_loss: 0.2122\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 5: val_loss did not improve from 0.21219\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2154 - val_loss: 0.2125\n",
      "Epoch 6/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2154\n",
      "Epoch 6: val_loss did not improve from 0.21219\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2153 - val_loss: 0.2131\n",
      "Epoch 7/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2146\n",
      "Epoch 7: val_loss improved from 0.21219 to 0.21070, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2145 - val_loss: 0.2107\n",
      "Epoch 8/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2150\n",
      "Epoch 8: val_loss did not improve from 0.21070\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2150 - val_loss: 0.2117\n",
      "Epoch 9/10\n",
      "2275/2317 [============================>.] - ETA: 0s - loss: 0.2149\n",
      "Epoch 9: val_loss did not improve from 0.21070\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2150 - val_loss: 0.2145\n",
      "Epoch 10/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2144\n",
      "Epoch 10: val_loss did not improve from 0.21070\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2146 - val_loss: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 1s 616us/step\n",
      "2317/2317 [==============================] - 1s 580us/step\n",
      "623/623 [==============================] - 0s 701us/step\n",
      "623/623 [==============================] - 0s 568us/step\n",
      "390/390 [==============================] - 0s 573us/step\n",
      "390/390 [==============================] - 0s 564us/step\n",
      "258/258 [==============================] - 0s 578us/step\n",
      "258/258 [==============================] - 0s 561us/step\n",
      "2576/2576 [==============================] - 1s 551us/step\n",
      "2576/2576 [==============================] - 1s 556us/step\n",
      "Epoch 1/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2804\n",
      "Epoch 1: val_loss improved from inf to 0.21953, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2800 - val_loss: 0.2195\n",
      "Epoch 2/10\n",
      "2272/2317 [============================>.] - ETA: 0s - loss: 0.2190\n",
      "Epoch 2: val_loss improved from 0.21953 to 0.21686, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2190 - val_loss: 0.2169\n",
      "Epoch 3/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2173\n",
      "Epoch 3: val_loss did not improve from 0.21686\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2174 - val_loss: 0.2275\n",
      "Epoch 4/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2167\n",
      "Epoch 4: val_loss improved from 0.21686 to 0.21463, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2167 - val_loss: 0.2146\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2162\n",
      "Epoch 5: val_loss did not improve from 0.21463\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2162 - val_loss: 0.2186\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2154\n",
      "Epoch 6: val_loss improved from 0.21463 to 0.21444, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2154 - val_loss: 0.2144\n",
      "Epoch 7/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 7: val_loss improved from 0.21444 to 0.21394, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2156 - val_loss: 0.2139\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 8: val_loss did not improve from 0.21394\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2153 - val_loss: 0.2149\n",
      "Epoch 9/10\n",
      "2273/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 9: val_loss improved from 0.21394 to 0.21392, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2157 - val_loss: 0.2139\n",
      "Epoch 10/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2147\n",
      "Epoch 10: val_loss improved from 0.21392 to 0.21372, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2148 - val_loss: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 1s 593us/step\n",
      "2317/2317 [==============================] - 1s 619us/step\n",
      "623/623 [==============================] - 0s 670us/step\n",
      "623/623 [==============================] - 0s 583us/step\n",
      "390/390 [==============================] - 0s 590us/step\n",
      "390/390 [==============================] - 0s 596us/step\n",
      "258/258 [==============================] - 0s 594us/step\n",
      "258/258 [==============================] - 0s 601us/step\n",
      "2576/2576 [==============================] - 2s 594us/step\n",
      "2576/2576 [==============================] - 2s 587us/step\n",
      "Epoch 1/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2868\n",
      "Epoch 1: val_loss improved from inf to 0.21340, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2866 - val_loss: 0.2134\n",
      "Epoch 2/10\n",
      "2286/2317 [============================>.] - ETA: 0s - loss: 0.2206\n",
      "Epoch 2: val_loss improved from 0.21340 to 0.21061, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2203 - val_loss: 0.2106\n",
      "Epoch 3/10\n",
      "2276/2317 [============================>.] - ETA: 0s - loss: 0.2184\n",
      "Epoch 3: val_loss did not improve from 0.21061\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2184 - val_loss: 0.2120\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2174\n",
      "Epoch 4: val_loss did not improve from 0.21061\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2175 - val_loss: 0.2198\n",
      "Epoch 5/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2169\n",
      "Epoch 5: val_loss improved from 0.21061 to 0.20758, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2172 - val_loss: 0.2076\n",
      "Epoch 6/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2166\n",
      "Epoch 6: val_loss did not improve from 0.20758\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2167 - val_loss: 0.2088\n",
      "Epoch 7/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2165\n",
      "Epoch 7: val_loss did not improve from 0.20758\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2165 - val_loss: 0.2132\n",
      "Epoch 8/10\n",
      "2280/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 8: val_loss did not improve from 0.20758\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2155 - val_loss: 0.2100\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2150\n",
      "Epoch 9: val_loss improved from 0.20758 to 0.20650, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2150 - val_loss: 0.2065\n",
      "Epoch 10/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2147\n",
      "Epoch 10: val_loss improved from 0.20650 to 0.20602, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2147 - val_loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 728us/step\n",
      "2317/2317 [==============================] - 2s 709us/step\n",
      "623/623 [==============================] - 0s 632us/step\n",
      "623/623 [==============================] - 0s 666us/step\n",
      "390/390 [==============================] - 0s 626us/step\n",
      "390/390 [==============================] - 0s 569us/step\n",
      "258/258 [==============================] - 0s 567us/step\n",
      "258/258 [==============================] - 0s 582us/step\n",
      "2576/2576 [==============================] - 2s 871us/step\n",
      "2576/2576 [==============================] - 2s 648us/step\n",
      "Epoch 1/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2912\n",
      "Epoch 1: val_loss improved from inf to 0.21372, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2909 - val_loss: 0.2137\n",
      "Epoch 2/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2180\n",
      "Epoch 2: val_loss improved from 0.21372 to 0.21140, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2178 - val_loss: 0.2114\n",
      "Epoch 3/10\n",
      "2276/2317 [============================>.] - ETA: 0s - loss: 0.2161\n",
      "Epoch 3: val_loss did not improve from 0.21140\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2160 - val_loss: 0.2116\n",
      "Epoch 4/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2153\n",
      "Epoch 4: val_loss improved from 0.21140 to 0.20988, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2153 - val_loss: 0.2099\n",
      "Epoch 5/10\n",
      "2281/2317 [============================>.] - ETA: 0s - loss: 0.2151\n",
      "Epoch 5: val_loss improved from 0.20988 to 0.20687, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2149 - val_loss: 0.2069\n",
      "Epoch 6/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2148\n",
      "Epoch 6: val_loss did not improve from 0.20687\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2148 - val_loss: 0.2088\n",
      "Epoch 7/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2148\n",
      "Epoch 7: val_loss did not improve from 0.20687\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2148 - val_loss: 0.2108\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2141\n",
      "Epoch 8: val_loss did not improve from 0.20687\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2141 - val_loss: 0.2077\n",
      "Epoch 9/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2137\n",
      "Epoch 9: val_loss did not improve from 0.20687\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2137 - val_loss: 0.2076\n",
      "Epoch 10/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2136\n",
      "Epoch 10: val_loss did not improve from 0.20687\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2135 - val_loss: 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 842us/step\n",
      "2317/2317 [==============================] - 2s 709us/step\n",
      "623/623 [==============================] - 0s 682us/step\n",
      "623/623 [==============================] - 0s 621us/step\n",
      "390/390 [==============================] - 0s 565us/step\n",
      "390/390 [==============================] - 0s 685us/step\n",
      "258/258 [==============================] - 0s 565us/step\n",
      "258/258 [==============================] - 0s 620us/step\n",
      "2576/2576 [==============================] - 1s 546us/step\n",
      "2576/2576 [==============================] - 2s 583us/step\n",
      "Epoch 1/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2815\n",
      "Epoch 1: val_loss improved from inf to 0.21821, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.2811 - val_loss: 0.2182\n",
      "Epoch 2/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2189\n",
      "Epoch 2: val_loss improved from 0.21821 to 0.21529, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2188 - val_loss: 0.2153\n",
      "Epoch 3/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2170\n",
      "Epoch 3: val_loss did not improve from 0.21529\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2170 - val_loss: 0.2154\n",
      "Epoch 4/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2163\n",
      "Epoch 4: val_loss did not improve from 0.21529\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2163 - val_loss: 0.2199\n",
      "Epoch 5/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 5: val_loss improved from 0.21529 to 0.21475, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2157 - val_loss: 0.2148\n",
      "Epoch 6/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 6: val_loss improved from 0.21475 to 0.21376, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2156 - val_loss: 0.2138\n",
      "Epoch 7/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 7: val_loss improved from 0.21376 to 0.21301, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2154 - val_loss: 0.2130\n",
      "Epoch 8/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 8: val_loss did not improve from 0.21301\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2158 - val_loss: 0.2142\n",
      "Epoch 9/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2162\n",
      "Epoch 9: val_loss did not improve from 0.21301\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2159 - val_loss: 0.2134\n",
      "Epoch 10/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 10: val_loss did not improve from 0.21301\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2157 - val_loss: 0.2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 671us/step\n",
      "2317/2317 [==============================] - 1s 557us/step\n",
      "623/623 [==============================] - 0s 572us/step\n",
      "623/623 [==============================] - 0s 555us/step\n",
      "390/390 [==============================] - 0s 560us/step\n",
      "390/390 [==============================] - 0s 561us/step\n",
      "258/258 [==============================] - 0s 561us/step\n",
      "258/258 [==============================] - 0s 559us/step\n",
      "2576/2576 [==============================] - 1s 557us/step\n",
      "2576/2576 [==============================] - 1s 556us/step\n",
      "Epoch 1/10\n",
      "2272/2317 [============================>.] - ETA: 0s - loss: 0.3060\n",
      "Epoch 1: val_loss improved from inf to 0.21256, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.3043 - val_loss: 0.2126\n",
      "Epoch 2/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2186\n",
      "Epoch 2: val_loss improved from 0.21256 to 0.20850, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2187 - val_loss: 0.2085\n",
      "Epoch 3/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 3: val_loss improved from 0.20850 to 0.20744, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2172 - val_loss: 0.2074\n",
      "Epoch 4/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2161\n",
      "Epoch 4: val_loss improved from 0.20744 to 0.20545, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2162 - val_loss: 0.2055\n",
      "Epoch 5/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2162\n",
      "Epoch 5: val_loss did not improve from 0.20545\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2162 - val_loss: 0.2071\n",
      "Epoch 6/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2159\n",
      "Epoch 6: val_loss did not improve from 0.20545\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2160 - val_loss: 0.2063\n",
      "Epoch 7/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 7: val_loss improved from 0.20545 to 0.20504, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2158 - val_loss: 0.2050\n",
      "Epoch 8/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2152\n",
      "Epoch 8: val_loss did not improve from 0.20504\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2153 - val_loss: 0.2058\n",
      "Epoch 9/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2153\n",
      "Epoch 9: val_loss improved from 0.20504 to 0.20378, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2153 - val_loss: 0.2038\n",
      "Epoch 10/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 10: val_loss did not improve from 0.20378\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2155 - val_loss: 0.2046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 649us/step\n",
      "2317/2317 [==============================] - 1s 614us/step\n",
      "623/623 [==============================] - 0s 606us/step\n",
      "623/623 [==============================] - 0s 587us/step\n",
      "390/390 [==============================] - 0s 591us/step\n",
      "390/390 [==============================] - 0s 594us/step\n",
      "258/258 [==============================] - 0s 598us/step\n",
      "258/258 [==============================] - 0s 622us/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 2s 590us/step\n",
      "Epoch 1/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.3008\n",
      "Epoch 1: val_loss improved from inf to 0.21375, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.3003 - val_loss: 0.2138\n",
      "Epoch 2/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2193\n",
      "Epoch 2: val_loss did not improve from 0.21375\n",
      "2317/2317 [==============================] - 8s 4ms/step - loss: 0.2195 - val_loss: 0.2155\n",
      "Epoch 3/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2176\n",
      "Epoch 3: val_loss improved from 0.21375 to 0.21100, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2175 - val_loss: 0.2110\n",
      "Epoch 4/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2173\n",
      "Epoch 4: val_loss improved from 0.21100 to 0.20997, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2173 - val_loss: 0.2100\n",
      "Epoch 5/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 5: val_loss improved from 0.20997 to 0.20813, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2171 - val_loss: 0.2081\n",
      "Epoch 6/10\n",
      "2281/2317 [============================>.] - ETA: 0s - loss: 0.2162\n",
      "Epoch 6: val_loss did not improve from 0.20813\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2160 - val_loss: 0.2095\n",
      "Epoch 7/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2164\n",
      "Epoch 7: val_loss did not improve from 0.20813\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2163 - val_loss: 0.2091\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2159\n",
      "Epoch 8: val_loss did not improve from 0.20813\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2160 - val_loss: 0.2083\n",
      "Epoch 9/10\n",
      "2280/2317 [============================>.] - ETA: 0s - loss: 0.2159\n",
      "Epoch 9: val_loss did not improve from 0.20813\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2157 - val_loss: 0.2105\n",
      "Epoch 10/10\n",
      "2283/2317 [============================>.] - ETA: 0s - loss: 0.2156\n",
      "Epoch 10: val_loss improved from 0.20813 to 0.20768, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2159 - val_loss: 0.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 1s 570us/step\n",
      "2317/2317 [==============================] - 1s 555us/step\n",
      "623/623 [==============================] - 0s 625us/step\n",
      "623/623 [==============================] - 0s 561us/step\n",
      "390/390 [==============================] - 0s 757us/step\n",
      "390/390 [==============================] - 0s 566us/step\n",
      "258/258 [==============================] - 0s 681us/step\n",
      "258/258 [==============================] - 0s 595us/step\n",
      "2576/2576 [==============================] - 1s 571us/step\n",
      "2576/2576 [==============================] - 1s 558us/step\n",
      "Epoch 1/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.3042\n",
      "Epoch 1: val_loss improved from inf to 0.21672, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.3030 - val_loss: 0.2167\n",
      "Epoch 2/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2199\n",
      "Epoch 2: val_loss improved from 0.21672 to 0.21095, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2200 - val_loss: 0.2109\n",
      "Epoch 3/10\n",
      "2286/2317 [============================>.] - ETA: 0s - loss: 0.2163\n",
      "Epoch 3: val_loss did not improve from 0.21095\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2164 - val_loss: 0.2112\n",
      "Epoch 4/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 4: val_loss did not improve from 0.21095\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2155 - val_loss: 0.2118\n",
      "Epoch 5/10\n",
      "2277/2317 [============================>.] - ETA: 0s - loss: 0.2150\n",
      "Epoch 5: val_loss improved from 0.21095 to 0.21069, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2149 - val_loss: 0.2107\n",
      "Epoch 6/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2149\n",
      "Epoch 6: val_loss improved from 0.21069 to 0.20790, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2150 - val_loss: 0.2079\n",
      "Epoch 7/10\n",
      "2284/2317 [============================>.] - ETA: 0s - loss: 0.2145\n",
      "Epoch 7: val_loss improved from 0.20790 to 0.20786, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2143 - val_loss: 0.2079\n",
      "Epoch 8/10\n",
      "2280/2317 [============================>.] - ETA: 0s - loss: 0.2140\n",
      "Epoch 8: val_loss did not improve from 0.20786\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2139 - val_loss: 0.2097\n",
      "Epoch 9/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2140\n",
      "Epoch 9: val_loss did not improve from 0.20786\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2139 - val_loss: 0.2082\n",
      "Epoch 10/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2136\n",
      "Epoch 10: val_loss did not improve from 0.20786\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2136 - val_loss: 0.2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 705us/step\n",
      "2317/2317 [==============================] - 2s 674us/step\n",
      "623/623 [==============================] - 0s 689us/step\n",
      "623/623 [==============================] - 0s 682us/step\n",
      "390/390 [==============================] - 0s 667us/step\n",
      "390/390 [==============================] - 0s 747us/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 798us/step\n",
      "2576/2576 [==============================] - 2s 759us/step\n",
      "2576/2576 [==============================] - 2s 802us/step\n",
      "Epoch 1/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2902\n",
      "Epoch 1: val_loss improved from inf to 0.21624, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.2899 - val_loss: 0.2162\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2190\n",
      "Epoch 2: val_loss improved from 0.21624 to 0.21362, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2191 - val_loss: 0.2136\n",
      "Epoch 3/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2172\n",
      "Epoch 3: val_loss did not improve from 0.21362\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2171 - val_loss: 0.2167\n",
      "Epoch 4/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2160\n",
      "Epoch 4: val_loss improved from 0.21362 to 0.21272, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2162 - val_loss: 0.2127\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 5: val_loss improved from 0.21272 to 0.20940, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2157 - val_loss: 0.2094\n",
      "Epoch 6/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2158\n",
      "Epoch 6: val_loss did not improve from 0.20940\n",
      "2317/2317 [==============================] - 11s 5ms/step - loss: 0.2157 - val_loss: 0.2109\n",
      "Epoch 7/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2155\n",
      "Epoch 7: val_loss did not improve from 0.20940\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2155 - val_loss: 0.2112\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2157\n",
      "Epoch 8: val_loss improved from 0.20940 to 0.20933, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2156 - val_loss: 0.2093\n",
      "Epoch 9/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2144\n",
      "Epoch 9: val_loss did not improve from 0.20933\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2146 - val_loss: 0.2103\n",
      "Epoch 10/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2146\n",
      "Epoch 10: val_loss did not improve from 0.20933\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2146 - val_loss: 0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_2_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 990us/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.35712626771155376 \n",
      "Average MSE on tiling: 0.21134105378493992 \n",
      "Average correlation on random: 0.3991318826118988 \n",
      "Average MSE on random: 0.12096292862541491 \n",
      "Average correlation on ChrV: 0.28475106054751326 \n",
      "Average MSE on ChrV: 0.26743536756809705 \n",
      "Average correlation on CN: 0.30013080321240515 \n",
      "Average MSE on CN: 0.1994015223530362\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(save_path + model_name + \"_tiling_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 5s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 13s 5ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "max_pool_model = Model(inputs = model.input, outputs = model.layers[2].output)\n",
    "max_pool_output = max_pool_model.predict(X5)\n",
    "pd.DataFrame(max_pool_output.reshape(max_pool_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_max_pool_output\")\n",
    "max_pool_output_random = max_pool_model.predict(X3)\n",
    "pd.DataFrame(max_pool_output_random.reshape(max_pool_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_max_pool_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 6s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_norm_model = Model(inputs = model.input, outputs = model.layers[3].output)\n",
    "batch_norm_output = batch_norm_model.predict(X5)\n",
    "pd.DataFrame(batch_norm_output.reshape(batch_norm_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_batch_norm_output\")\n",
    "batch_norm_output_random = batch_norm_model.predict(X3)\n",
    "pd.DataFrame(batch_norm_output_random.reshape(batch_norm_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_batch_norm_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 9s 3ms/step\n",
      "390/390 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "dense_model = Model(inputs = model.input, outputs = model.layers[6].output)\n",
    "dense_output = dense_model.predict(X5)\n",
    "pd.DataFrame(dense_output.reshape(dense_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_dense_output\")\n",
    "dense_output_random = dense_model.predict(X3)\n",
    "pd.DataFrame(dense_output_random.reshape(dense_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_dense_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = model.layers[1].weights[0]\n",
    "first_conv_biases = model.layers[1].weights[1]\n",
    "# Format: [Position 0: A, C, G, T, Position 1: A, C, G, T, Position 2: A, C, G, T]\n",
    "pd.DataFrame(array(first_conv_weights).transpose((3,2,0,1)).reshape(first_conv_weights.shape[-1], -1)).to_csv(save_path + model_name+\"_tiling_first_conv_kernels\")\n",
    "pd.DataFrame(first_conv_biases).to_csv(save_path + model_name+\"_tiling_first_conv_biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
