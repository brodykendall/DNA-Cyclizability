{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 09:19:15.531833: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"2conv_only\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(48, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Conv2D(48, kernel_size=(11,1),\n",
    "                activation='relu',\n",
    "                padding='same')(x)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 192))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 16:17:01.684602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2624\n",
      "Epoch 1: val_loss improved from inf to 0.12370, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.2622 - val_loss: 0.1237\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 2: val_loss improved from 0.12370 to 0.10963, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1355 - val_loss: 0.1096\n",
      "Epoch 3/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1243\n",
      "Epoch 3: val_loss improved from 0.10963 to 0.10674, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1243 - val_loss: 0.1067\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1206\n",
      "Epoch 4: val_loss improved from 0.10674 to 0.10067, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1206 - val_loss: 0.1007\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1167\n",
      "Epoch 5: val_loss improved from 0.10067 to 0.09957, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1166 - val_loss: 0.0996\n",
      "Epoch 6/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1149\n",
      "Epoch 6: val_loss improved from 0.09957 to 0.09771, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.1150 - val_loss: 0.0977\n",
      "Epoch 7/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1131\n",
      "Epoch 7: val_loss did not improve from 0.09771\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1131 - val_loss: 0.0978\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1126\n",
      "Epoch 8: val_loss improved from 0.09771 to 0.09563, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1126 - val_loss: 0.0956\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1119\n",
      "Epoch 9: val_loss did not improve from 0.09563\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.1119 - val_loss: 0.0958\n",
      "Epoch 10/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1102\n",
      "Epoch 10: val_loss did not improve from 0.09563\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1102 - val_loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2619\n",
      "Epoch 1: val_loss improved from inf to 0.12570, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.2617 - val_loss: 0.1257\n",
      "Epoch 2/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1346\n",
      "Epoch 2: val_loss improved from 0.12570 to 0.12079, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1346 - val_loss: 0.1208\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1252\n",
      "Epoch 3: val_loss improved from 0.12079 to 0.11016, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2.h5\n",
      "2317/2317 [==============================] - 23s 10ms/step - loss: 0.1253 - val_loss: 0.1102\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1194\n",
      "Epoch 4: val_loss did not improve from 0.11016\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1194 - val_loss: 0.1102\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1163\n",
      "Epoch 5: val_loss improved from 0.11016 to 0.10555, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1163 - val_loss: 0.1056\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1140\n",
      "Epoch 6: val_loss did not improve from 0.10555\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.1140 - val_loss: 0.1063\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1118\n",
      "Epoch 7: val_loss improved from 0.10555 to 0.10153, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2.h5\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1117 - val_loss: 0.1015\n",
      "Epoch 8/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1107\n",
      "Epoch 8: val_loss did not improve from 0.10153\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1106 - val_loss: 0.1047\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1101\n",
      "Epoch 9: val_loss did not improve from 0.10153\n",
      "2317/2317 [==============================] - 22s 9ms/step - loss: 0.1101 - val_loss: 0.1034\n",
      "Epoch 10/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1086\n",
      "Epoch 10: val_loss did not improve from 0.10153\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.1086 - val_loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "2576/2576 [==============================] - 9s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2516\n",
      "Epoch 1: val_loss improved from inf to 0.12627, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.2516 - val_loss: 0.1263\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1337\n",
      "Epoch 2: val_loss improved from 0.12627 to 0.11439, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.1337 - val_loss: 0.1144\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1243\n",
      "Epoch 3: val_loss improved from 0.11439 to 0.10926, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1243 - val_loss: 0.1093\n",
      "Epoch 4/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1196\n",
      "Epoch 4: val_loss improved from 0.10926 to 0.10314, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1196 - val_loss: 0.1031\n",
      "Epoch 5/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1168\n",
      "Epoch 5: val_loss improved from 0.10314 to 0.10094, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1168 - val_loss: 0.1009\n",
      "Epoch 6/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1143\n",
      "Epoch 6: val_loss improved from 0.10094 to 0.10015, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1144 - val_loss: 0.1002\n",
      "Epoch 7/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1138\n",
      "Epoch 7: val_loss did not improve from 0.10015\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.1139 - val_loss: 0.1106\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1117\n",
      "Epoch 8: val_loss did not improve from 0.10015\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1117 - val_loss: 0.1006\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1108\n",
      "Epoch 9: val_loss did not improve from 0.10015\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1108 - val_loss: 0.1025\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1102\n",
      "Epoch 10: val_loss did not improve from 0.10015\n",
      "2317/2317 [==============================] - 19s 8ms/step - loss: 0.1102 - val_loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 9s 4ms/step\n",
      "2576/2576 [==============================] - 9s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2644\n",
      "Epoch 1: val_loss improved from inf to 0.13026, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.2643 - val_loss: 0.1303\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1343\n",
      "Epoch 2: val_loss improved from 0.13026 to 0.10890, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1343 - val_loss: 0.1089\n",
      "Epoch 3/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1245\n",
      "Epoch 3: val_loss improved from 0.10890 to 0.10277, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 21s 9ms/step - loss: 0.1245 - val_loss: 0.1028\n",
      "Epoch 4/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1198\n",
      "Epoch 4: val_loss improved from 0.10277 to 0.10010, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 23s 10ms/step - loss: 0.1198 - val_loss: 0.1001\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1162\n",
      "Epoch 5: val_loss improved from 0.10010 to 0.09818, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 22s 9ms/step - loss: 0.1162 - val_loss: 0.0982\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1146\n",
      "Epoch 6: val_loss did not improve from 0.09818\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.1147 - val_loss: 0.1034\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1126\n",
      "Epoch 7: val_loss improved from 0.09818 to 0.09757, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1126 - val_loss: 0.0976\n",
      "Epoch 8/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1122\n",
      "Epoch 8: val_loss improved from 0.09757 to 0.09752, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 27s 11ms/step - loss: 0.1122 - val_loss: 0.0975\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1103\n",
      "Epoch 9: val_loss did not improve from 0.09752\n",
      "2317/2317 [==============================] - 20s 9ms/step - loss: 0.1103 - val_loss: 0.1024\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1096\n",
      "Epoch 10: val_loss improved from 0.09752 to 0.09510, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4.h5\n",
      "2317/2317 [==============================] - 20s 8ms/step - loss: 0.1096 - val_loss: 0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "2576/2576 [==============================] - 8s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2596\n",
      "Epoch 1: val_loss improved from inf to 0.12774, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.2595 - val_loss: 0.1277\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1331\n",
      "Epoch 2: val_loss improved from 0.12774 to 0.11252, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1331 - val_loss: 0.1125\n",
      "Epoch 3/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1244\n",
      "Epoch 3: val_loss improved from 0.11252 to 0.11068, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.1244 - val_loss: 0.1107\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1187\n",
      "Epoch 4: val_loss improved from 0.11068 to 0.10447, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1187 - val_loss: 0.1045\n",
      "Epoch 5/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1171\n",
      "Epoch 5: val_loss did not improve from 0.10447\n",
      "2317/2317 [==============================] - 15s 6ms/step - loss: 0.1171 - val_loss: 0.1099\n",
      "Epoch 6/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1148\n",
      "Epoch 6: val_loss did not improve from 0.10447\n",
      "2317/2317 [==============================] - 15s 6ms/step - loss: 0.1149 - val_loss: 0.1128\n",
      "Epoch 7/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1138\n",
      "Epoch 7: val_loss improved from 0.10447 to 0.10105, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 15s 6ms/step - loss: 0.1138 - val_loss: 0.1011\n",
      "Epoch 8/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1121\n",
      "Epoch 8: val_loss improved from 0.10105 to 0.10069, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 15s 6ms/step - loss: 0.1121 - val_loss: 0.1007\n",
      "Epoch 9/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1109\n",
      "Epoch 9: val_loss improved from 0.10069 to 0.10003, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5.h5\n",
      "2317/2317 [==============================] - 14s 6ms/step - loss: 0.1111 - val_loss: 0.1000\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1099\n",
      "Epoch 10: val_loss did not improve from 0.10003\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1099 - val_loss: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "2317/2317 [==============================] - 6s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "2576/2576 [==============================] - 7s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2625\n",
      "Epoch 1: val_loss improved from inf to 0.15355, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.2625 - val_loss: 0.1536\n",
      "Epoch 2/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1359\n",
      "Epoch 2: val_loss improved from 0.15355 to 0.12075, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.1358 - val_loss: 0.1208\n",
      "Epoch 3/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1250\n",
      "Epoch 3: val_loss improved from 0.12075 to 0.11077, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1250 - val_loss: 0.1108\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1200\n",
      "Epoch 4: val_loss improved from 0.11077 to 0.10558, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1200 - val_loss: 0.1056\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1172\n",
      "Epoch 5: val_loss did not improve from 0.10558\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1172 - val_loss: 0.1058\n",
      "Epoch 6/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1149\n",
      "Epoch 6: val_loss improved from 0.10558 to 0.10318, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1149 - val_loss: 0.1032\n",
      "Epoch 7/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1129\n",
      "Epoch 7: val_loss improved from 0.10318 to 0.10281, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1129 - val_loss: 0.1028\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1115\n",
      "Epoch 8: val_loss did not improve from 0.10281\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1115 - val_loss: 0.1052\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1108\n",
      "Epoch 9: val_loss did not improve from 0.10281\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1108 - val_loss: 0.1038\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1103\n",
      "Epoch 10: val_loss did not improve from 0.10281\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1102 - val_loss: 0.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 6s 2ms/step\n",
      "2317/2317 [==============================] - 6s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "258/258 [==============================] - 1s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 6s 3ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2624\n",
      "Epoch 1: val_loss improved from inf to 0.12562, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 17s 7ms/step - loss: 0.2621 - val_loss: 0.1256\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1332\n",
      "Epoch 2: val_loss improved from 0.12562 to 0.10949, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1331 - val_loss: 0.1095\n",
      "Epoch 3/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1243\n",
      "Epoch 3: val_loss improved from 0.10949 to 0.10426, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1243 - val_loss: 0.1043\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1197\n",
      "Epoch 4: val_loss did not improve from 0.10426\n",
      "2317/2317 [==============================] - 16s 7ms/step - loss: 0.1197 - val_loss: 0.1063\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1169\n",
      "Epoch 5: val_loss improved from 0.10426 to 0.10225, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 15s 7ms/step - loss: 0.1169 - val_loss: 0.1023\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1150\n",
      "Epoch 6: val_loss improved from 0.10225 to 0.10007, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 15s 6ms/step - loss: 0.1150 - val_loss: 0.1001\n",
      "Epoch 7/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1129\n",
      "Epoch 7: val_loss improved from 0.10007 to 0.09914, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 13s 6ms/step - loss: 0.1129 - val_loss: 0.0991\n",
      "Epoch 8/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1126\n",
      "Epoch 8: val_loss improved from 0.09914 to 0.09702, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7.h5\n",
      "2317/2317 [==============================] - 18s 8ms/step - loss: 0.1126 - val_loss: 0.0970\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1109\n",
      "Epoch 9: val_loss did not improve from 0.09702\n",
      "2317/2317 [==============================] - 15s 7ms/step - loss: 0.1109 - val_loss: 0.0978\n",
      "Epoch 10/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.1100\n",
      "Epoch 10: val_loss did not improve from 0.09702\n",
      "2317/2317 [==============================] - 14s 6ms/step - loss: 0.1101 - val_loss: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 4s 2ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 2ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2615\n",
      "Epoch 1: val_loss improved from inf to 0.12704, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.2609 - val_loss: 0.1270\n",
      "Epoch 2/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1337\n",
      "Epoch 2: val_loss improved from 0.12704 to 0.11334, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1337 - val_loss: 0.1133\n",
      "Epoch 3/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.1238\n",
      "Epoch 3: val_loss improved from 0.11334 to 0.11295, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1238 - val_loss: 0.1130\n",
      "Epoch 4/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1192\n",
      "Epoch 4: val_loss improved from 0.11295 to 0.10638, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1192 - val_loss: 0.1064\n",
      "Epoch 5/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1154\n",
      "Epoch 5: val_loss did not improve from 0.10638\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1154 - val_loss: 0.1113\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1138\n",
      "Epoch 6: val_loss improved from 0.10638 to 0.10327, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1138 - val_loss: 0.1033\n",
      "Epoch 7/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.1124\n",
      "Epoch 7: val_loss did not improve from 0.10327\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1124 - val_loss: 0.1060\n",
      "Epoch 8/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1109\n",
      "Epoch 8: val_loss improved from 0.10327 to 0.10120, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1109 - val_loss: 0.1012\n",
      "Epoch 9/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.1095\n",
      "Epoch 9: val_loss did not improve from 0.10120\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1095 - val_loss: 0.1049\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1089\n",
      "Epoch 10: val_loss did not improve from 0.10120\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1089 - val_loss: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2643\n",
      "Epoch 1: val_loss improved from inf to 0.12307, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.2641 - val_loss: 0.1231\n",
      "Epoch 2/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1333\n",
      "Epoch 2: val_loss improved from 0.12307 to 0.11603, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1332 - val_loss: 0.1160\n",
      "Epoch 3/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1244\n",
      "Epoch 3: val_loss improved from 0.11603 to 0.10368, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1244 - val_loss: 0.1037\n",
      "Epoch 4/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1202\n",
      "Epoch 4: val_loss did not improve from 0.10368\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1202 - val_loss: 0.1062\n",
      "Epoch 5/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1167\n",
      "Epoch 5: val_loss improved from 0.10368 to 0.10253, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1168 - val_loss: 0.1025\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1144\n",
      "Epoch 6: val_loss improved from 0.10253 to 0.10094, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1144 - val_loss: 0.1009\n",
      "Epoch 7/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1130\n",
      "Epoch 7: val_loss improved from 0.10094 to 0.09802, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1129 - val_loss: 0.0980\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1119\n",
      "Epoch 8: val_loss did not improve from 0.09802\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1119 - val_loss: 0.0983\n",
      "Epoch 9/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.1106\n",
      "Epoch 9: val_loss improved from 0.09802 to 0.09684, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1106 - val_loss: 0.0968\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1093\n",
      "Epoch 10: val_loss did not improve from 0.09684\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1094 - val_loss: 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2575\n",
      "Epoch 1: val_loss improved from inf to 0.12429, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.2572 - val_loss: 0.1243\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1335\n",
      "Epoch 2: val_loss improved from 0.12429 to 0.11127, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1336 - val_loss: 0.1113\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1244\n",
      "Epoch 3: val_loss improved from 0.11127 to 0.10741, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1244 - val_loss: 0.1074\n",
      "Epoch 4/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.1185\n",
      "Epoch 4: val_loss did not improve from 0.10741\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1184 - val_loss: 0.1076\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1164\n",
      "Epoch 5: val_loss improved from 0.10741 to 0.10725, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1165 - val_loss: 0.1073\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1140\n",
      "Epoch 6: val_loss improved from 0.10725 to 0.10237, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1140 - val_loss: 0.1024\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1119\n",
      "Epoch 7: val_loss improved from 0.10237 to 0.10095, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10.h5\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1118 - val_loss: 0.1010\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.1107\n",
      "Epoch 8: val_loss did not improve from 0.10095\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1107 - val_loss: 0.1029\n",
      "Epoch 9/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.1104\n",
      "Epoch 9: val_loss did not improve from 0.10095\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1104 - val_loss: 0.1017\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1086\n",
      "Epoch 10: val_loss did not improve from 0.10095\n",
      "2317/2317 [==============================] - 10s 4ms/step - loss: 0.1086 - val_loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/2conv_only_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n",
      "2576/2576 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.7655984648294503 \n",
      "Average MSE on tiling: 0.10025435606876432 \n",
      "Average correlation on random: 0.7634555753091923 \n",
      "Average MSE on random: 0.060645906004313355 \n",
      "Average correlation on ChrV: 0.6369222322568756 \n",
      "Average MSE on ChrV: 0.17308379378491784 \n",
      "Average correlation on CN: 0.7211809263448375 \n",
      "Average MSE on CN: 0.10468038195278415\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 2s 717us/step\n",
      "390/390 [==============================] - 0s 629us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 3s 1ms/step\n",
      "390/390 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "second_conv_model = Model(inputs = model.input, outputs = model.layers[5].output)\n",
    "second_conv_output = second_conv_model.predict(X5)\n",
    "pd.DataFrame(second_conv_output.reshape(second_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_second_conv_output\")\n",
    "second_conv_output_random = second_conv_model.predict(X3)\n",
    "pd.DataFrame(second_conv_output_random.reshape(second_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_second_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
