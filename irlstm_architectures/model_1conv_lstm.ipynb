{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 09:41:24.636765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"1conv_lstm\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(48, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    x = LSTM(20, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 15:29:14.309178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2253\n",
      "Epoch 1: val_loss improved from inf to 0.19881, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 34s 14ms/step - loss: 0.2253 - val_loss: 0.1988\n",
      "Epoch 2/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2011\n",
      "Epoch 2: val_loss improved from 0.19881 to 0.19272, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.2011 - val_loss: 0.1927\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1944\n",
      "Epoch 3: val_loss improved from 0.19272 to 0.18144, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.1943 - val_loss: 0.1814\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1774\n",
      "Epoch 4: val_loss improved from 0.18144 to 0.10605, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 36s 15ms/step - loss: 0.1774 - val_loss: 0.1060\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1077\n",
      "Epoch 5: val_loss improved from 0.10605 to 0.08521, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 51s 22ms/step - loss: 0.1077 - val_loss: 0.0852\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0922\n",
      "Epoch 6: val_loss improved from 0.08521 to 0.07141, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 52s 22ms/step - loss: 0.0922 - val_loss: 0.0714\n",
      "Epoch 7/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0844\n",
      "Epoch 7: val_loss improved from 0.07141 to 0.06242, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 44s 19ms/step - loss: 0.0844 - val_loss: 0.0624\n",
      "Epoch 8/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0794\n",
      "Epoch 8: val_loss improved from 0.06242 to 0.06095, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0794 - val_loss: 0.0610\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0771\n",
      "Epoch 9: val_loss improved from 0.06095 to 0.05748, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1.h5\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.0771 - val_loss: 0.0575\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0743\n",
      "Epoch 10: val_loss did not improve from 0.05748\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0743 - val_loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 9s 4ms/step\n",
      "2317/2317 [==============================] - 8s 4ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 1s 4ms/step\n",
      "390/390 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "2576/2576 [==============================] - 9s 3ms/step\n",
      "2576/2576 [==============================] - 9s 4ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 1: val_loss improved from inf to 0.22312, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 33s 13ms/step - loss: 0.2219 - val_loss: 0.2231\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2012\n",
      "Epoch 2: val_loss improved from 0.22312 to 0.20260, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.2012 - val_loss: 0.2026\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1960\n",
      "Epoch 3: val_loss improved from 0.20260 to 0.19073, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 25s 11ms/step - loss: 0.1960 - val_loss: 0.1907\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1906\n",
      "Epoch 4: val_loss improved from 0.19073 to 0.18160, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 29s 12ms/step - loss: 0.1906 - val_loss: 0.1816\n",
      "Epoch 5/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1523\n",
      "Epoch 5: val_loss improved from 0.18160 to 0.09892, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.1522 - val_loss: 0.0989\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1018\n",
      "Epoch 6: val_loss improved from 0.09892 to 0.08147, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 36s 16ms/step - loss: 0.1018 - val_loss: 0.0815\n",
      "Epoch 7/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0911\n",
      "Epoch 7: val_loss improved from 0.08147 to 0.07175, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.0911 - val_loss: 0.0717\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0846\n",
      "Epoch 8: val_loss did not improve from 0.07175\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.0846 - val_loss: 0.0726\n",
      "Epoch 9/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0807\n",
      "Epoch 9: val_loss improved from 0.07175 to 0.06364, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.0807 - val_loss: 0.0636\n",
      "Epoch 10/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0782\n",
      "Epoch 10: val_loss improved from 0.06364 to 0.06214, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2.h5\n",
      "2317/2317 [==============================] - 27s 12ms/step - loss: 0.0782 - val_loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 10s 4ms/step\n",
      "2317/2317 [==============================] - 14s 6ms/step\n",
      "623/623 [==============================] - 4s 6ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "2576/2576 [==============================] - 10s 4ms/step\n",
      "2576/2576 [==============================] - 10s 4ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 1: val_loss improved from inf to 0.20508, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 37s 15ms/step - loss: 0.2234 - val_loss: 0.2051\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2012\n",
      "Epoch 2: val_loss improved from 0.20508 to 0.19461, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.2012 - val_loss: 0.1946\n",
      "Epoch 3/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 3: val_loss improved from 0.19461 to 0.19298, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.1946 - val_loss: 0.1930\n",
      "Epoch 4/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1890\n",
      "Epoch 4: val_loss improved from 0.19298 to 0.18807, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.1890 - val_loss: 0.1881\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1813\n",
      "Epoch 5: val_loss improved from 0.18807 to 0.17555, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 32s 14ms/step - loss: 0.1812 - val_loss: 0.1755\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1303\n",
      "Epoch 6: val_loss improved from 0.17555 to 0.08188, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 42s 18ms/step - loss: 0.1303 - val_loss: 0.0819\n",
      "Epoch 7/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0955\n",
      "Epoch 7: val_loss improved from 0.08188 to 0.07458, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 57s 24ms/step - loss: 0.0955 - val_loss: 0.0746\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0871\n",
      "Epoch 8: val_loss improved from 0.07458 to 0.06815, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 56s 24ms/step - loss: 0.0871 - val_loss: 0.0682\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0816\n",
      "Epoch 9: val_loss improved from 0.06815 to 0.06474, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 55s 24ms/step - loss: 0.0817 - val_loss: 0.0647\n",
      "Epoch 10/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0788\n",
      "Epoch 10: val_loss improved from 0.06474 to 0.06147, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3.h5\n",
      "2317/2317 [==============================] - 38s 16ms/step - loss: 0.0789 - val_loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 9s 4ms/step\n",
      "2317/2317 [==============================] - 9s 4ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "2576/2576 [==============================] - 14s 6ms/step\n",
      "2576/2576 [==============================] - 15s 6ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2222\n",
      "Epoch 1: val_loss improved from inf to 0.20202, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 48s 19ms/step - loss: 0.2222 - val_loss: 0.2020\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2003\n",
      "Epoch 2: val_loss improved from 0.20202 to 0.18997, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.2003 - val_loss: 0.1900\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1940\n",
      "Epoch 3: val_loss improved from 0.18997 to 0.18815, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.1940 - val_loss: 0.1881\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1880\n",
      "Epoch 4: val_loss improved from 0.18815 to 0.18451, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.1880 - val_loss: 0.1845\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1537\n",
      "Epoch 5: val_loss improved from 0.18451 to 0.08821, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 39s 17ms/step - loss: 0.1537 - val_loss: 0.0882\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1004\n",
      "Epoch 6: val_loss improved from 0.08821 to 0.07467, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 50s 21ms/step - loss: 0.1004 - val_loss: 0.0747\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0897\n",
      "Epoch 7: val_loss did not improve from 0.07467\n",
      "2317/2317 [==============================] - 53s 23ms/step - loss: 0.0897 - val_loss: 0.0830\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0842\n",
      "Epoch 8: val_loss improved from 0.07467 to 0.06374, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 64s 28ms/step - loss: 0.0842 - val_loss: 0.0637\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0805\n",
      "Epoch 9: val_loss did not improve from 0.06374\n",
      "2317/2317 [==============================] - 55s 24ms/step - loss: 0.0805 - val_loss: 0.0775\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0774\n",
      "Epoch 10: val_loss improved from 0.06374 to 0.05793, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4.h5\n",
      "2317/2317 [==============================] - 71s 31ms/step - loss: 0.0774 - val_loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 12s 5ms/step\n",
      "2317/2317 [==============================] - 17s 7ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "2576/2576 [==============================] - 20s 7ms/step\n",
      "2576/2576 [==============================] - 16s 6ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2217\n",
      "Epoch 1: val_loss improved from inf to 0.19583, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 48s 20ms/step - loss: 0.2217 - val_loss: 0.1958\n",
      "Epoch 2/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2006\n",
      "Epoch 2: val_loss improved from 0.19583 to 0.18850, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.2006 - val_loss: 0.1885\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1946\n",
      "Epoch 3: val_loss improved from 0.18850 to 0.18236, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 41s 18ms/step - loss: 0.1946 - val_loss: 0.1824\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1880\n",
      "Epoch 4: val_loss did not improve from 0.18236\n",
      "2317/2317 [==============================] - 35s 15ms/step - loss: 0.1880 - val_loss: 0.1874\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1522\n",
      "Epoch 5: val_loss improved from 0.18236 to 0.08786, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 36s 15ms/step - loss: 0.1521 - val_loss: 0.0879\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.0987\n",
      "Epoch 6: val_loss improved from 0.08786 to 0.07524, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 28s 12ms/step - loss: 0.0987 - val_loss: 0.0752\n",
      "Epoch 7/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0883\n",
      "Epoch 7: val_loss improved from 0.07524 to 0.07032, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.0883 - val_loss: 0.0703\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0832\n",
      "Epoch 8: val_loss improved from 0.07032 to 0.06293, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 29s 13ms/step - loss: 0.0832 - val_loss: 0.0629\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0800\n",
      "Epoch 9: val_loss did not improve from 0.06293\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.0800 - val_loss: 0.0658\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0780\n",
      "Epoch 10: val_loss improved from 0.06293 to 0.06005, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5.h5\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0780 - val_loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 9s 4ms/step\n",
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "2576/2576 [==============================] - 11s 4ms/step\n",
      "2576/2576 [==============================] - 9s 4ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2260\n",
      "Epoch 1: val_loss improved from inf to 0.20670, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 33s 13ms/step - loss: 0.2260 - val_loss: 0.2067\n",
      "Epoch 2/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2014\n",
      "Epoch 2: val_loss improved from 0.20670 to 0.19576, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 27s 12ms/step - loss: 0.2014 - val_loss: 0.1958\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1946\n",
      "Epoch 3: val_loss improved from 0.19576 to 0.19344, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.1947 - val_loss: 0.1934\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1721\n",
      "Epoch 4: val_loss improved from 0.19344 to 0.12128, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.1721 - val_loss: 0.1213\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1029\n",
      "Epoch 5: val_loss improved from 0.12128 to 0.08018, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.1029 - val_loss: 0.0802\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0888\n",
      "Epoch 6: val_loss improved from 0.08018 to 0.07205, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.0888 - val_loss: 0.0721\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0828\n",
      "Epoch 7: val_loss improved from 0.07205 to 0.06662, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 42s 18ms/step - loss: 0.0828 - val_loss: 0.0666\n",
      "Epoch 8/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0791\n",
      "Epoch 8: val_loss improved from 0.06662 to 0.05995, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6.h5\n",
      "2317/2317 [==============================] - 40s 17ms/step - loss: 0.0791 - val_loss: 0.0599\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0766\n",
      "Epoch 9: val_loss did not improve from 0.05995\n",
      "2317/2317 [==============================] - 33s 14ms/step - loss: 0.0765 - val_loss: 0.0629\n",
      "Epoch 10/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0745\n",
      "Epoch 10: val_loss did not improve from 0.05995\n",
      "2317/2317 [==============================] - 27s 12ms/step - loss: 0.0745 - val_loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 8s 3ms/step\n",
      "2317/2317 [==============================] - 7s 3ms/step\n",
      "623/623 [==============================] - 2s 3ms/step\n",
      "623/623 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "390/390 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "258/258 [==============================] - 1s 3ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "2576/2576 [==============================] - 6s 2ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2204\n",
      "Epoch 1: val_loss improved from inf to 0.19114, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 32s 13ms/step - loss: 0.2204 - val_loss: 0.1911\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1994\n",
      "Epoch 2: val_loss improved from 0.19114 to 0.18402, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.1994 - val_loss: 0.1840\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1920\n",
      "Epoch 3: val_loss improved from 0.18402 to 0.17537, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 24s 11ms/step - loss: 0.1919 - val_loss: 0.1754\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.1433\n",
      "Epoch 4: val_loss improved from 0.17537 to 0.08976, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 26s 11ms/step - loss: 0.1432 - val_loss: 0.0898\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0965\n",
      "Epoch 5: val_loss improved from 0.08976 to 0.06891, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 27s 12ms/step - loss: 0.0964 - val_loss: 0.0689\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0870\n",
      "Epoch 6: val_loss improved from 0.06891 to 0.06731, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 30s 13ms/step - loss: 0.0870 - val_loss: 0.0673\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0831\n",
      "Epoch 7: val_loss improved from 0.06731 to 0.05903, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 29s 12ms/step - loss: 0.0831 - val_loss: 0.0590\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0795\n",
      "Epoch 8: val_loss improved from 0.05903 to 0.05871, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 41s 18ms/step - loss: 0.0795 - val_loss: 0.0587\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0765\n",
      "Epoch 9: val_loss improved from 0.05871 to 0.05525, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 40s 17ms/step - loss: 0.0765 - val_loss: 0.0552\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0751\n",
      "Epoch 10: val_loss improved from 0.05525 to 0.05456, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7.h5\n",
      "2317/2317 [==============================] - 46s 20ms/step - loss: 0.0751 - val_loss: 0.0546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 13s 5ms/step\n",
      "2317/2317 [==============================] - 12s 5ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "258/258 [==============================] - 2s 6ms/step\n",
      "2576/2576 [==============================] - 15s 6ms/step\n",
      "2576/2576 [==============================] - 14s 5ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2277\n",
      "Epoch 1: val_loss improved from inf to 0.20416, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 51s 21ms/step - loss: 0.2277 - val_loss: 0.2042\n",
      "Epoch 2/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2005\n",
      "Epoch 2: val_loss improved from 0.20416 to 0.20210, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 41s 17ms/step - loss: 0.2005 - val_loss: 0.2021\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.1938\n",
      "Epoch 3: val_loss improved from 0.20210 to 0.19424, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 45s 20ms/step - loss: 0.1938 - val_loss: 0.1942\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1870\n",
      "Epoch 4: val_loss improved from 0.19424 to 0.17360, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 50s 22ms/step - loss: 0.1870 - val_loss: 0.1736\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1207\n",
      "Epoch 5: val_loss improved from 0.17360 to 0.08999, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 49s 21ms/step - loss: 0.1207 - val_loss: 0.0900\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0918\n",
      "Epoch 6: val_loss improved from 0.08999 to 0.07550, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 49s 21ms/step - loss: 0.0918 - val_loss: 0.0755\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0836\n",
      "Epoch 7: val_loss improved from 0.07550 to 0.07047, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 39s 17ms/step - loss: 0.0836 - val_loss: 0.0705\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0795\n",
      "Epoch 8: val_loss improved from 0.07047 to 0.06604, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 32s 14ms/step - loss: 0.0795 - val_loss: 0.0660\n",
      "Epoch 9/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0764\n",
      "Epoch 9: val_loss did not improve from 0.06604\n",
      "2317/2317 [==============================] - 42s 18ms/step - loss: 0.0764 - val_loss: 0.0679\n",
      "Epoch 10/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0747\n",
      "Epoch 10: val_loss improved from 0.06604 to 0.06248, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8.h5\n",
      "2317/2317 [==============================] - 46s 20ms/step - loss: 0.0747 - val_loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 13s 5ms/step\n",
      "2317/2317 [==============================] - 13s 6ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "623/623 [==============================] - 3s 6ms/step\n",
      "390/390 [==============================] - 2s 6ms/step\n",
      "390/390 [==============================] - 2s 5ms/step\n",
      "258/258 [==============================] - 1s 6ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "2576/2576 [==============================] - 14s 6ms/step\n",
      "2576/2576 [==============================] - 15s 6ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2235\n",
      "Epoch 1: val_loss improved from inf to 0.19869, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 44s 18ms/step - loss: 0.2235 - val_loss: 0.1987\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 2: val_loss improved from 0.19869 to 0.18932, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 44s 19ms/step - loss: 0.2019 - val_loss: 0.1893\n",
      "Epoch 3/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1953\n",
      "Epoch 3: val_loss did not improve from 0.18932\n",
      "2317/2317 [==============================] - 43s 19ms/step - loss: 0.1953 - val_loss: 0.1894\n",
      "Epoch 4/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1902\n",
      "Epoch 4: val_loss improved from 0.18932 to 0.17600, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 46s 20ms/step - loss: 0.1902 - val_loss: 0.1760\n",
      "Epoch 5/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1572\n",
      "Epoch 5: val_loss improved from 0.17600 to 0.09618, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 54s 23ms/step - loss: 0.1572 - val_loss: 0.0962\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1003\n",
      "Epoch 6: val_loss improved from 0.09618 to 0.07229, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 54s 23ms/step - loss: 0.1003 - val_loss: 0.0723\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0891\n",
      "Epoch 7: val_loss improved from 0.07229 to 0.06475, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 55s 24ms/step - loss: 0.0890 - val_loss: 0.0648\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0830\n",
      "Epoch 8: val_loss improved from 0.06475 to 0.06002, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 43s 19ms/step - loss: 0.0830 - val_loss: 0.0600\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0794\n",
      "Epoch 9: val_loss improved from 0.06002 to 0.05834, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9.h5\n",
      "2317/2317 [==============================] - 36s 16ms/step - loss: 0.0794 - val_loss: 0.0583\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0767\n",
      "Epoch 10: val_loss did not improve from 0.05834\n",
      "2317/2317 [==============================] - 38s 16ms/step - loss: 0.0767 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 10s 4ms/step\n",
      "2317/2317 [==============================] - 10s 4ms/step\n",
      "623/623 [==============================] - 3s 4ms/step\n",
      "623/623 [==============================] - 3s 4ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "258/258 [==============================] - 1s 4ms/step\n",
      "2576/2576 [==============================] - 11s 4ms/step\n",
      "2576/2576 [==============================] - 11s 4ms/step\n",
      "(None, 1)\n",
      "Epoch 1/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2243\n",
      "Epoch 1: val_loss improved from inf to 0.20366, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 38s 15ms/step - loss: 0.2243 - val_loss: 0.2037\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2015\n",
      "Epoch 2: val_loss improved from 0.20366 to 0.19281, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 31s 13ms/step - loss: 0.2015 - val_loss: 0.1928\n",
      "Epoch 3/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.1946\n",
      "Epoch 3: val_loss improved from 0.19281 to 0.18722, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 38s 16ms/step - loss: 0.1946 - val_loss: 0.1872\n",
      "Epoch 4/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.1878\n",
      "Epoch 4: val_loss improved from 0.18722 to 0.17750, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 37s 16ms/step - loss: 0.1878 - val_loss: 0.1775\n",
      "Epoch 5/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1503\n",
      "Epoch 5: val_loss improved from 0.17750 to 0.09089, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 37s 16ms/step - loss: 0.1503 - val_loss: 0.0909\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.1001\n",
      "Epoch 6: val_loss improved from 0.09089 to 0.07480, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 38s 16ms/step - loss: 0.1001 - val_loss: 0.0748\n",
      "Epoch 7/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.0893\n",
      "Epoch 7: val_loss improved from 0.07480 to 0.06470, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.0893 - val_loss: 0.0647\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.0834\n",
      "Epoch 8: val_loss improved from 0.06470 to 0.06287, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 34s 15ms/step - loss: 0.0834 - val_loss: 0.0629\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.0799\n",
      "Epoch 9: val_loss improved from 0.06287 to 0.05745, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 37s 16ms/step - loss: 0.0799 - val_loss: 0.0575\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.0776\n",
      "Epoch 10: val_loss improved from 0.05745 to 0.05639, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10.h5\n",
      "2317/2317 [==============================] - 36s 15ms/step - loss: 0.0776 - val_loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/1conv_lstm_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 10s 4ms/step\n",
      "2317/2317 [==============================] - 9s 4ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "623/623 [==============================] - 3s 5ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "258/258 [==============================] - 3s 13ms/step\n",
      "258/258 [==============================] - 1s 5ms/step\n",
      "2576/2576 [==============================] - 11s 4ms/step\n",
      "2576/2576 [==============================] - 12s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.8658778925078217 \n",
      "Average MSE on tiling: 0.06062316140517514 \n",
      "Average correlation on random: 0.86431375390494 \n",
      "Average MSE on random: 0.037145893895861044 \n",
      "Average correlation on ChrV: 0.7301933912809401 \n",
      "Average MSE on ChrV: 0.13603220014391731 \n",
      "Average correlation on CN: 0.821566935161993 \n",
      "Average MSE on CN: 0.0716179387530441\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(save_path + model_name + \"_tiling_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 2s 745us/step\n",
      "390/390 [==============================] - 0s 809us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 5s 2ms/step\n",
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Model(inputs = model.input, outputs = model.layers[6].output)\n",
    "lstm_output = lstm_model.predict(X5)\n",
    "pd.DataFrame(lstm_output.reshape(lstm_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_lstm_output\")\n",
    "lstm_output_random = lstm_model.predict(X3)\n",
    "pd.DataFrame(lstm_output_random.reshape(lstm_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_lstm_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
