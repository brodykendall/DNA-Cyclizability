{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 10:40:59.297998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"conv_only_3\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(48, kernel_size=(5,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 24*48))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    # print(outputs.shape)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2713\n",
      "Epoch 1: val_loss improved from inf to 0.23666, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2712 - val_loss: 0.2367\n",
      "Epoch 2/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2118\n",
      "Epoch 2: val_loss improved from 0.23666 to 0.20743, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2118 - val_loss: 0.2074\n",
      "Epoch 3/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2096\n",
      "Epoch 3: val_loss improved from 0.20743 to 0.20267, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2096 - val_loss: 0.2027\n",
      "Epoch 4/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2082\n",
      "Epoch 4: val_loss improved from 0.20267 to 0.20265, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2081 - val_loss: 0.2027\n",
      "Epoch 5/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2075\n",
      "Epoch 5: val_loss did not improve from 0.20265\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2077 - val_loss: 0.2072\n",
      "Epoch 6/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2062\n",
      "Epoch 6: val_loss did not improve from 0.20265\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2062 - val_loss: 0.2046\n",
      "Epoch 7/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2050\n",
      "Epoch 7: val_loss did not improve from 0.20265\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2051 - val_loss: 0.2049\n",
      "Epoch 8/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2058\n",
      "Epoch 8: val_loss improved from 0.20265 to 0.20036, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2058 - val_loss: 0.2004\n",
      "Epoch 9/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2050\n",
      "Epoch 9: val_loss improved from 0.20036 to 0.19888, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2052 - val_loss: 0.1989\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2051\n",
      "Epoch 10: val_loss did not improve from 0.19888\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2051 - val_loss: 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 839us/step\n",
      "2317/2317 [==============================] - 2s 924us/step\n",
      "623/623 [==============================] - 1s 879us/step\n",
      "623/623 [==============================] - 1s 862us/step\n",
      "390/390 [==============================] - 0s 816us/step\n",
      "390/390 [==============================] - 0s 763us/step\n",
      "258/258 [==============================] - 0s 872us/step\n",
      "258/258 [==============================] - 0s 860us/step\n",
      "2576/2576 [==============================] - 2s 819us/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2780\n",
      "Epoch 1: val_loss improved from inf to 0.21918, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2779 - val_loss: 0.2192\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2110\n",
      "Epoch 2: val_loss improved from 0.21918 to 0.21626, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2110 - val_loss: 0.2163\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2093\n",
      "Epoch 3: val_loss improved from 0.21626 to 0.19903, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2093 - val_loss: 0.1990\n",
      "Epoch 4/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2072\n",
      "Epoch 4: val_loss improved from 0.19903 to 0.19759, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2072 - val_loss: 0.1976\n",
      "Epoch 5/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2069\n",
      "Epoch 5: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2068 - val_loss: 0.2055\n",
      "Epoch 6/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2056\n",
      "Epoch 6: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2056 - val_loss: 0.1983\n",
      "Epoch 7/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2057\n",
      "Epoch 7: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2057 - val_loss: 0.1991\n",
      "Epoch 8/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2054\n",
      "Epoch 8: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2054 - val_loss: 0.1995\n",
      "Epoch 9/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2052\n",
      "Epoch 9: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2052 - val_loss: 0.2002\n",
      "Epoch 10/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2049\n",
      "Epoch 10: val_loss did not improve from 0.19759\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2047 - val_loss: 0.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 910us/step\n",
      "2317/2317 [==============================] - 2s 910us/step\n",
      "623/623 [==============================] - 1s 921us/step\n",
      "623/623 [==============================] - 1s 917us/step\n",
      "390/390 [==============================] - 0s 892us/step\n",
      "390/390 [==============================] - 0s 884us/step\n",
      "258/258 [==============================] - 0s 899us/step\n",
      "258/258 [==============================] - 0s 897us/step\n",
      "2576/2576 [==============================] - 2s 925us/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2801\n",
      "Epoch 1: val_loss improved from inf to 0.22442, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3.h5\n",
      "2317/2317 [==============================] - 8s 3ms/step - loss: 0.2801 - val_loss: 0.2244\n",
      "Epoch 2/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2113\n",
      "Epoch 2: val_loss improved from 0.22442 to 0.19449, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2115 - val_loss: 0.1945\n",
      "Epoch 3/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2092\n",
      "Epoch 3: val_loss did not improve from 0.19449\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2091 - val_loss: 0.1945\n",
      "Epoch 4/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2079\n",
      "Epoch 4: val_loss did not improve from 0.19449\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2078 - val_loss: 0.2011\n",
      "Epoch 5/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2071\n",
      "Epoch 5: val_loss did not improve from 0.19449\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2071 - val_loss: 0.1959\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2070\n",
      "Epoch 6: val_loss improved from 0.19449 to 0.19249, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2070 - val_loss: 0.1925\n",
      "Epoch 7/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2054\n",
      "Epoch 7: val_loss did not improve from 0.19249\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2054 - val_loss: 0.1932\n",
      "Epoch 8/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2056\n",
      "Epoch 8: val_loss did not improve from 0.19249\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2056 - val_loss: 0.1938\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2059\n",
      "Epoch 9: val_loss improved from 0.19249 to 0.19199, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2059 - val_loss: 0.1920\n",
      "Epoch 10/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2045\n",
      "Epoch 10: val_loss did not improve from 0.19199\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2048 - val_loss: 0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 1ms/step\n",
      "2317/2317 [==============================] - 3s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "390/390 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 935us/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 2s 933us/step\n",
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2699\n",
      "Epoch 1: val_loss improved from inf to 0.20940, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2699 - val_loss: 0.2094\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2109\n",
      "Epoch 2: val_loss improved from 0.20940 to 0.20667, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2109 - val_loss: 0.2067\n",
      "Epoch 3/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2091\n",
      "Epoch 3: val_loss improved from 0.20667 to 0.20552, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2091 - val_loss: 0.2055\n",
      "Epoch 4/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2084\n",
      "Epoch 4: val_loss did not improve from 0.20552\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2084 - val_loss: 0.2057\n",
      "Epoch 5/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2072\n",
      "Epoch 5: val_loss improved from 0.20552 to 0.20251, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2072 - val_loss: 0.2025\n",
      "Epoch 6/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2063\n",
      "Epoch 6: val_loss did not improve from 0.20251\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2064 - val_loss: 0.2045\n",
      "Epoch 7/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2051\n",
      "Epoch 7: val_loss did not improve from 0.20251\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2050 - val_loss: 0.2110\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2049\n",
      "Epoch 8: val_loss did not improve from 0.20251\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2048 - val_loss: 0.2072\n",
      "Epoch 9/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2044\n",
      "Epoch 9: val_loss improved from 0.20251 to 0.20104, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2045 - val_loss: 0.2010\n",
      "Epoch 10/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2049\n",
      "Epoch 10: val_loss did not improve from 0.20104\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2048 - val_loss: 0.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 918us/step\n",
      "2317/2317 [==============================] - 2s 913us/step\n",
      "623/623 [==============================] - 1s 922us/step\n",
      "623/623 [==============================] - 1s 927us/step\n",
      "390/390 [==============================] - 0s 929us/step\n",
      "390/390 [==============================] - 0s 914us/step\n",
      "258/258 [==============================] - 0s 946us/step\n",
      "258/258 [==============================] - 0s 922us/step\n",
      "2576/2576 [==============================] - 2s 922us/step\n",
      "2576/2576 [==============================] - 2s 922us/step\n",
      "Epoch 1/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2738\n",
      "Epoch 1: val_loss improved from inf to 0.21131, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2738 - val_loss: 0.2113\n",
      "Epoch 2/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2111\n",
      "Epoch 2: val_loss improved from 0.21131 to 0.20513, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2113 - val_loss: 0.2051\n",
      "Epoch 3/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2090\n",
      "Epoch 3: val_loss improved from 0.20513 to 0.20092, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2091 - val_loss: 0.2009\n",
      "Epoch 4/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2066\n",
      "Epoch 4: val_loss improved from 0.20092 to 0.20085, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2066 - val_loss: 0.2008\n",
      "Epoch 5/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2057\n",
      "Epoch 5: val_loss did not improve from 0.20085\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2057 - val_loss: 0.2024\n",
      "Epoch 6/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2047\n",
      "Epoch 6: val_loss improved from 0.20085 to 0.19773, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2047 - val_loss: 0.1977\n",
      "Epoch 7/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2042\n",
      "Epoch 7: val_loss did not improve from 0.19773\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2042 - val_loss: 0.1986\n",
      "Epoch 8/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2041\n",
      "Epoch 8: val_loss did not improve from 0.19773\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2039 - val_loss: 0.2033\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2032\n",
      "Epoch 9: val_loss did not improve from 0.19773\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2033 - val_loss: 0.2060\n",
      "Epoch 10/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2030\n",
      "Epoch 10: val_loss improved from 0.19773 to 0.19711, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2032 - val_loss: 0.1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 886us/step\n",
      "2317/2317 [==============================] - 2s 944us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 966us/step\n",
      "390/390 [==============================] - 0s 936us/step\n",
      "390/390 [==============================] - 0s 950us/step\n",
      "258/258 [==============================] - 0s 947us/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 2s 958us/step\n",
      "2576/2576 [==============================] - 2s 913us/step\n",
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2796\n",
      "Epoch 1: val_loss improved from inf to 0.22674, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2795 - val_loss: 0.2267\n",
      "Epoch 2/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2087\n",
      "Epoch 2: val_loss improved from 0.22674 to 0.22637, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2086 - val_loss: 0.2264\n",
      "Epoch 3/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2071\n",
      "Epoch 3: val_loss improved from 0.22637 to 0.20910, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2071 - val_loss: 0.2091\n",
      "Epoch 4/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2059\n",
      "Epoch 4: val_loss did not improve from 0.20910\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2059 - val_loss: 0.2104\n",
      "Epoch 5/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2057\n",
      "Epoch 5: val_loss improved from 0.20910 to 0.20822, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2056 - val_loss: 0.2082\n",
      "Epoch 6/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2056\n",
      "Epoch 6: val_loss did not improve from 0.20822\n",
      "2317/2317 [==============================] - 8s 3ms/step - loss: 0.2056 - val_loss: 0.2089\n",
      "Epoch 7/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2051\n",
      "Epoch 7: val_loss did not improve from 0.20822\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2050 - val_loss: 0.2170\n",
      "Epoch 8/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2048\n",
      "Epoch 8: val_loss improved from 0.20822 to 0.20779, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2046 - val_loss: 0.2078\n",
      "Epoch 9/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2048\n",
      "Epoch 9: val_loss improved from 0.20779 to 0.20752, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2048 - val_loss: 0.2075\n",
      "Epoch 10/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2041\n",
      "Epoch 10: val_loss did not improve from 0.20752\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2042 - val_loss: 0.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 892us/step\n",
      "2317/2317 [==============================] - 2s 871us/step\n",
      "623/623 [==============================] - 1s 899us/step\n",
      "623/623 [==============================] - 1s 876us/step\n",
      "390/390 [==============================] - 0s 874us/step\n",
      "390/390 [==============================] - 0s 874us/step\n",
      "258/258 [==============================] - 0s 949us/step\n",
      "258/258 [==============================] - 0s 888us/step\n",
      "2576/2576 [==============================] - 2s 872us/step\n",
      "2576/2576 [==============================] - 2s 910us/step\n",
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2811\n",
      "Epoch 1: val_loss improved from inf to 0.20811, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2808 - val_loss: 0.2081\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2132\n",
      "Epoch 2: val_loss improved from 0.20811 to 0.20552, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2131 - val_loss: 0.2055\n",
      "Epoch 3/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2085\n",
      "Epoch 3: val_loss improved from 0.20552 to 0.19569, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2085 - val_loss: 0.1957\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2068\n",
      "Epoch 4: val_loss did not improve from 0.19569\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2069 - val_loss: 0.1998\n",
      "Epoch 5/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2055\n",
      "Epoch 5: val_loss improved from 0.19569 to 0.19367, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 6s 3ms/step - loss: 0.2056 - val_loss: 0.1937\n",
      "Epoch 6/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2050\n",
      "Epoch 6: val_loss improved from 0.19367 to 0.19357, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2051 - val_loss: 0.1936\n",
      "Epoch 7/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2043\n",
      "Epoch 7: val_loss did not improve from 0.19357\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2043 - val_loss: 0.1967\n",
      "Epoch 8/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2044\n",
      "Epoch 8: val_loss improved from 0.19357 to 0.19304, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2046 - val_loss: 0.1930\n",
      "Epoch 9/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2042\n",
      "Epoch 9: val_loss did not improve from 0.19304\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2042 - val_loss: 0.1938\n",
      "Epoch 10/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2040\n",
      "Epoch 10: val_loss did not improve from 0.19304\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2041 - val_loss: 0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 814us/step\n",
      "2317/2317 [==============================] - 2s 770us/step\n",
      "623/623 [==============================] - 0s 759us/step\n",
      "623/623 [==============================] - 0s 708us/step\n",
      "390/390 [==============================] - 0s 711us/step\n",
      "390/390 [==============================] - 0s 704us/step\n",
      "258/258 [==============================] - 0s 707us/step\n",
      "258/258 [==============================] - 0s 709us/step\n",
      "2576/2576 [==============================] - 2s 708us/step\n",
      "2576/2576 [==============================] - 2s 710us/step\n",
      "Epoch 1/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2701\n",
      "Epoch 1: val_loss improved from inf to 0.20380, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 7s 3ms/step - loss: 0.2696 - val_loss: 0.2038\n",
      "Epoch 2/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2121\n",
      "Epoch 2: val_loss improved from 0.20380 to 0.20251, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2120 - val_loss: 0.2025\n",
      "Epoch 3/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2092\n",
      "Epoch 3: val_loss improved from 0.20251 to 0.20080, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2092 - val_loss: 0.2008\n",
      "Epoch 4/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2072\n",
      "Epoch 4: val_loss improved from 0.20080 to 0.19803, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2073 - val_loss: 0.1980\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2065\n",
      "Epoch 5: val_loss did not improve from 0.19803\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2064 - val_loss: 0.2052\n",
      "Epoch 6/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2054\n",
      "Epoch 6: val_loss improved from 0.19803 to 0.19757, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2054 - val_loss: 0.1976\n",
      "Epoch 7/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2052\n",
      "Epoch 7: val_loss improved from 0.19757 to 0.19487, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2052 - val_loss: 0.1949\n",
      "Epoch 8/10\n",
      "2300/2317 [============================>.] - ETA: 0s - loss: 0.2054\n",
      "Epoch 8: val_loss did not improve from 0.19487\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2053 - val_loss: 0.1979\n",
      "Epoch 9/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2045\n",
      "Epoch 9: val_loss did not improve from 0.19487\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2044 - val_loss: 0.1995\n",
      "Epoch 10/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2043\n",
      "Epoch 10: val_loss improved from 0.19487 to 0.19343, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2044 - val_loss: 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 917us/step\n",
      "2317/2317 [==============================] - 2s 991us/step\n",
      "623/623 [==============================] - 1s 793us/step\n",
      "623/623 [==============================] - 1s 802us/step\n",
      "390/390 [==============================] - 0s 789us/step\n",
      "390/390 [==============================] - 0s 876us/step\n",
      "258/258 [==============================] - 0s 779us/step\n",
      "258/258 [==============================] - 0s 768us/step\n",
      "2576/2576 [==============================] - 2s 855us/step\n",
      "2576/2576 [==============================] - 2s 956us/step\n",
      "Epoch 1/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2734\n",
      "Epoch 1: val_loss improved from inf to 0.23277, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2734 - val_loss: 0.2328\n",
      "Epoch 2/10\n",
      "2302/2317 [============================>.] - ETA: 0s - loss: 0.2093\n",
      "Epoch 2: val_loss improved from 0.23277 to 0.21351, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2091 - val_loss: 0.2135\n",
      "Epoch 3/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2064\n",
      "Epoch 3: val_loss did not improve from 0.21351\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2064 - val_loss: 0.2190\n",
      "Epoch 4/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2059\n",
      "Epoch 4: val_loss improved from 0.21351 to 0.21172, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2059 - val_loss: 0.2117\n",
      "Epoch 5/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2040\n",
      "Epoch 5: val_loss improved from 0.21172 to 0.21030, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2042 - val_loss: 0.2103\n",
      "Epoch 6/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2035\n",
      "Epoch 6: val_loss improved from 0.21030 to 0.21001, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2035 - val_loss: 0.2100\n",
      "Epoch 7/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2033\n",
      "Epoch 7: val_loss improved from 0.21001 to 0.20897, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2034 - val_loss: 0.2090\n",
      "Epoch 8/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2031\n",
      "Epoch 8: val_loss did not improve from 0.20897\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2030 - val_loss: 0.2098\n",
      "Epoch 9/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2032\n",
      "Epoch 9: val_loss did not improve from 0.20897\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2032 - val_loss: 0.2108\n",
      "Epoch 10/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2023\n",
      "Epoch 10: val_loss improved from 0.20897 to 0.20881, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2024 - val_loss: 0.2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 836us/step\n",
      "2317/2317 [==============================] - 2s 800us/step\n",
      "623/623 [==============================] - 0s 746us/step\n",
      "623/623 [==============================] - 1s 806us/step\n",
      "390/390 [==============================] - 0s 726us/step\n",
      "390/390 [==============================] - 0s 820us/step\n",
      "258/258 [==============================] - 0s 736us/step\n",
      "258/258 [==============================] - 0s 727us/step\n",
      "2576/2576 [==============================] - 2s 720us/step\n",
      "2576/2576 [==============================] - 2s 792us/step\n",
      "Epoch 1/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2699\n",
      "Epoch 1: val_loss improved from inf to 0.22409, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10.h5\n",
      "2317/2317 [==============================] - 6s 2ms/step - loss: 0.2694 - val_loss: 0.2241\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2109\n",
      "Epoch 2: val_loss improved from 0.22409 to 0.20609, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2109 - val_loss: 0.2061\n",
      "Epoch 3/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2083\n",
      "Epoch 3: val_loss improved from 0.20609 to 0.20078, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2082 - val_loss: 0.2008\n",
      "Epoch 4/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2076\n",
      "Epoch 4: val_loss did not improve from 0.20078\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2075 - val_loss: 0.2009\n",
      "Epoch 5/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2067\n",
      "Epoch 5: val_loss improved from 0.20078 to 0.19853, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2068 - val_loss: 0.1985\n",
      "Epoch 6/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2060\n",
      "Epoch 6: val_loss did not improve from 0.19853\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2062 - val_loss: 0.1996\n",
      "Epoch 7/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2068\n",
      "Epoch 7: val_loss did not improve from 0.19853\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2068 - val_loss: 0.1986\n",
      "Epoch 8/10\n",
      "2309/2317 [============================>.] - ETA: 0s - loss: 0.2059\n",
      "Epoch 8: val_loss improved from 0.19853 to 0.19745, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2059 - val_loss: 0.1975\n",
      "Epoch 9/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2060\n",
      "Epoch 9: val_loss did not improve from 0.19745\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2060 - val_loss: 0.1982\n",
      "Epoch 10/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2060\n",
      "Epoch 10: val_loss did not improve from 0.19745\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2060 - val_loss: 0.1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_3_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 937us/step\n",
      "2317/2317 [==============================] - 2s 751us/step\n",
      "623/623 [==============================] - 0s 741us/step\n",
      "623/623 [==============================] - 0s 738us/step\n",
      "390/390 [==============================] - 0s 787us/step\n",
      "390/390 [==============================] - 0s 730us/step\n",
      "258/258 [==============================] - 0s 778us/step\n",
      "258/258 [==============================] - 0s 848us/step\n",
      "2576/2576 [==============================] - 2s 780us/step\n",
      "2576/2576 [==============================] - 2s 732us/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.4206512082572232 \n",
      "Average MSE on tiling: 0.19939854306854937 \n",
      "Average correlation on random: 0.45227663143031993 \n",
      "Average MSE on random: 0.11474401371743395 \n",
      "Average correlation on ChrV: 0.3269597619694434 \n",
      "Average MSE on ChrV: 0.2600649075903366 \n",
      "Average correlation on CN: 0.35508985050717473 \n",
      "Average MSE on CN: 0.18924649430928234\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(5, 4, 1, 48) dtype=float32, numpy=\n",
       " array([[[[-5.80247343e-02,  1.38385907e-01,  3.27622406e-02,\n",
       "           -3.69063802e-02, -2.99043804e-02, -6.85023842e-03,\n",
       "           -5.30303046e-02, -8.56347308e-02, -3.24559174e-02,\n",
       "           -6.18764423e-02, -6.17932938e-02, -2.33178530e-02,\n",
       "           -3.59188542e-02,  1.50391338e-02, -2.44561955e-02,\n",
       "            4.87169065e-02,  6.26838580e-03,  8.09786543e-02,\n",
       "            1.29743800e-01,  2.25676764e-02, -2.04286203e-02,\n",
       "           -1.90271530e-04, -6.81200624e-02, -8.90013650e-02,\n",
       "           -2.11996660e-02, -7.29471296e-02, -1.92655306e-02,\n",
       "            4.67695408e-02, -1.28149569e-01, -7.79081136e-02,\n",
       "           -5.26460484e-02, -6.97205076e-03, -8.77863765e-02,\n",
       "            3.42829898e-02,  7.53587577e-03, -4.36519347e-02,\n",
       "            2.35479847e-02, -2.70655341e-02, -6.01653606e-02,\n",
       "           -2.35133111e-01, -1.95635352e-02, -2.05048230e-02,\n",
       "           -9.00488533e-03, -4.68188971e-02, -1.74498539e-02,\n",
       "            2.44614072e-02, -2.19712481e-01, -1.65427942e-02]],\n",
       " \n",
       "         [[-1.87978484e-02, -1.01526521e-01,  9.74711254e-02,\n",
       "           -3.61114927e-02,  3.09044253e-02, -4.28849496e-02,\n",
       "            4.57217917e-02, -5.53231649e-02,  1.07940007e-02,\n",
       "            4.01416095e-04, -5.73076271e-02, -1.19352210e-02,\n",
       "            1.10355996e-01,  1.59775503e-02, -3.19469273e-02,\n",
       "           -3.54613453e-01,  1.02442950e-01, -1.43999219e-01,\n",
       "            7.95315653e-02, -6.53159693e-02, -2.14126408e-02,\n",
       "           -4.20263037e-02,  3.32630426e-02, -6.68412298e-02,\n",
       "           -5.32462075e-03, -2.59119511e-01, -4.39807475e-02,\n",
       "            4.37784865e-02,  1.01129919e-01, -3.06762736e-02,\n",
       "           -4.25217934e-02,  3.56742889e-02,  7.73986103e-03,\n",
       "            2.08812719e-03, -9.89568047e-03,  8.39258581e-02,\n",
       "           -7.09945112e-02, -6.91117346e-02,  3.64778424e-03,\n",
       "            1.02090485e-01, -1.02119163e-01, -2.32469998e-02,\n",
       "           -3.39288563e-02, -4.77407053e-02, -3.39087062e-02,\n",
       "            1.64108053e-02,  9.90202054e-02, -9.59237218e-02]],\n",
       " \n",
       "         [[-7.99215659e-02, -4.26156074e-02,  1.10272810e-01,\n",
       "           -8.25165510e-02,  1.82743575e-02, -8.32589269e-02,\n",
       "           -1.58827510e-02, -2.05009840e-02,  4.62068850e-03,\n",
       "           -3.49666290e-02, -2.63575166e-02,  1.84340794e-02,\n",
       "            8.36493075e-02, -1.15913171e-02, -7.46497288e-02,\n",
       "            1.21977255e-01,  1.93264354e-02, -9.00091305e-02,\n",
       "            1.21361047e-01,  1.42586762e-02, -4.99970838e-02,\n",
       "           -5.22417612e-02, -8.87217582e-04, -4.39115167e-02,\n",
       "           -4.60972674e-02, -3.71774107e-01, -2.54872050e-02,\n",
       "           -6.84030503e-02, -2.45648231e-02,  1.20092854e-02,\n",
       "           -3.01115811e-02, -2.72724256e-02, -7.09293559e-02,\n",
       "            4.25603501e-02, -2.12050397e-02,  1.14142753e-01,\n",
       "           -5.24047762e-02,  8.16622190e-03, -1.66026633e-02,\n",
       "            6.60481378e-02, -2.94703767e-02, -2.96869781e-02,\n",
       "           -9.24160182e-02,  1.66316237e-02,  3.84178422e-02,\n",
       "            1.50784384e-02,  1.03514321e-01, -7.24227503e-02]],\n",
       " \n",
       "         [[-3.20930257e-02,  5.53420782e-02,  6.82605850e-03,\n",
       "            3.18494625e-02,  2.50559878e-02, -2.80271135e-02,\n",
       "            1.14722075e-02, -6.00664504e-02, -4.73747216e-02,\n",
       "            2.99459156e-02, -5.92256449e-02, -7.43259713e-02,\n",
       "            6.71269596e-02, -2.26157736e-02,  1.49236461e-02,\n",
       "           -1.82546794e-01,  5.15856519e-02, -1.38704300e-01,\n",
       "           -1.14699900e-01,  2.28929357e-03, -3.33257765e-02,\n",
       "           -3.61133926e-02,  5.88821359e-02, -4.71328050e-02,\n",
       "           -3.56952474e-02,  1.90284610e-01, -2.65509123e-04,\n",
       "            4.25093621e-02, -4.35641855e-02, -1.11903891e-01,\n",
       "           -6.17525950e-02,  3.42461690e-02, -6.43422753e-02,\n",
       "            3.63528579e-02, -3.16219255e-02, -5.66663081e-03,\n",
       "           -6.72131106e-02, -5.99265918e-02,  1.97732588e-04,\n",
       "           -2.32387051e-01, -3.90277468e-02,  1.01167616e-02,\n",
       "           -2.46567838e-02, -7.86191970e-02, -4.55103209e-03,\n",
       "            3.51148732e-02, -2.76857793e-01, -1.01487592e-01]]],\n",
       " \n",
       " \n",
       "        [[[-7.18618631e-02,  1.17373206e-01, -6.01605475e-02,\n",
       "            4.94931042e-02, -4.08775955e-02,  1.04149990e-02,\n",
       "           -6.95123151e-02, -4.20818385e-03, -3.00451405e-02,\n",
       "           -3.16066225e-03,  2.53915023e-02, -1.92640945e-02,\n",
       "           -1.06974505e-01, -2.95149982e-02, -4.41327244e-02,\n",
       "            1.12834796e-02, -1.00074541e-02, -1.67158350e-01,\n",
       "           -2.89425164e-01, -3.10662426e-02, -7.13042542e-02,\n",
       "           -5.66809364e-02, -3.16628665e-02, -4.35456028e-03,\n",
       "           -1.13003269e-01,  2.16754779e-01,  1.56955756e-02,\n",
       "           -4.46470156e-02, -6.58626333e-02, -8.21705982e-02,\n",
       "           -6.03908598e-02, -3.07064801e-02, -7.11236298e-02,\n",
       "           -2.82103773e-02, -3.44874151e-02,  2.21728962e-02,\n",
       "            2.05730945e-02, -5.32991290e-02,  6.42226124e-03,\n",
       "            3.95855568e-02, -4.84763868e-02,  5.51220775e-03,\n",
       "           -1.21311955e-02, -7.43753165e-02, -2.29527894e-02,\n",
       "            6.10575415e-02, -1.94867134e-01, -5.47349919e-03]],\n",
       " \n",
       "         [[-9.67926520e-04,  3.02101541e-02,  6.58165067e-02,\n",
       "           -4.00611339e-03, -2.64065098e-02, -5.65597340e-02,\n",
       "           -5.85224256e-02, -7.39413947e-02, -5.86364381e-02,\n",
       "           -5.89728020e-02,  3.68921906e-02,  1.30910082e-02,\n",
       "            7.62638822e-02, -1.56926066e-02, -2.98564173e-02,\n",
       "           -3.33413780e-01,  8.78326297e-02, -1.42081797e-01,\n",
       "            1.88797921e-01, -3.04276496e-02,  4.44049276e-02,\n",
       "            1.29893180e-02,  1.11768693e-02,  1.02699650e-02,\n",
       "            3.19986045e-02, -2.01875851e-01,  7.60959759e-02,\n",
       "           -6.58700913e-02,  1.08285509e-01,  4.61561903e-02,\n",
       "           -3.78503576e-02, -2.55816523e-02, -1.04558267e-01,\n",
       "           -5.43131493e-02, -7.41042756e-03,  3.84302400e-02,\n",
       "           -6.65846616e-02, -3.62412296e-02, -3.15770064e-03,\n",
       "           -2.16509208e-01,  5.32365404e-02, -7.61601701e-02,\n",
       "           -2.01925868e-05,  1.12643922e-02, -9.13166851e-02,\n",
       "            4.16873619e-02,  1.45420030e-01, -6.20523281e-02]],\n",
       " \n",
       "         [[ 2.92161871e-02,  2.68458519e-02,  9.44370478e-02,\n",
       "           -7.09460080e-02, -6.88898144e-03, -5.10905460e-02,\n",
       "            1.32474285e-02,  4.46087588e-03, -5.37480041e-02,\n",
       "            1.28174219e-02,  2.29262072e-03, -4.44283569e-03,\n",
       "            1.31395506e-03, -4.79876250e-02, -2.62717046e-02,\n",
       "            1.79048106e-01,  1.01380520e-01,  3.42657305e-02,\n",
       "            1.43018007e-01, -1.08684665e-02, -4.23901714e-02,\n",
       "           -5.85741773e-02,  3.86709310e-02,  5.52061945e-03,\n",
       "            1.85098557e-04, -3.54927093e-01,  6.54643252e-02,\n",
       "           -4.06463891e-02, -8.13513547e-02, -9.32962447e-02,\n",
       "           -4.76243580e-03, -2.53491327e-02, -1.89378560e-02,\n",
       "           -3.65447178e-02, -2.81624720e-02,  2.17448827e-02,\n",
       "           -4.12686877e-02, -5.50927855e-02, -2.89397258e-02,\n",
       "            3.27301286e-02,  1.76391937e-02, -1.91454366e-02,\n",
       "           -2.60997638e-02, -3.28349918e-02,  1.33540016e-02,\n",
       "            1.19465441e-01,  1.11131310e-01, -8.66577029e-02]],\n",
       " \n",
       "         [[ 2.40678526e-02,  6.98626786e-02, -6.91872984e-02,\n",
       "           -4.97822985e-02, -6.72188401e-02, -3.93343307e-02,\n",
       "           -5.36661316e-03, -3.90589610e-02,  1.55324806e-02,\n",
       "           -5.89872375e-02, -6.67379498e-02, -4.11936007e-02,\n",
       "            1.65045485e-02,  2.26739570e-02, -2.98856702e-02,\n",
       "           -1.35039091e-01, -8.38194638e-02, -1.90076709e-01,\n",
       "            4.04430777e-02, -5.89111298e-02, -4.38195355e-02,\n",
       "           -3.56885120e-02, -1.31248429e-01, -6.27119541e-02,\n",
       "           -3.65980598e-03, -1.35890797e-01,  5.46645112e-02,\n",
       "           -6.52624965e-02,  3.19795534e-02, -8.25424045e-02,\n",
       "           -3.82923521e-02, -2.72594858e-02, -7.66845718e-02,\n",
       "           -2.07320135e-02,  1.39446314e-02,  5.96887022e-02,\n",
       "           -6.74538389e-02, -7.66653344e-02, -2.73168683e-02,\n",
       "            1.03738837e-01, -3.83481570e-02,  6.11546356e-03,\n",
       "           -3.73828337e-02, -7.33230338e-02, -1.03305787e-01,\n",
       "           -1.83035210e-01, -1.57578588e-01, -6.90259635e-02]]],\n",
       " \n",
       " \n",
       "        [[[-4.69995849e-02, -1.68891232e-02, -7.80646801e-02,\n",
       "            1.07915979e-02, -2.33192742e-03, -7.79488608e-02,\n",
       "           -4.08651754e-02, -8.06493312e-02, -8.48386586e-02,\n",
       "           -2.78558452e-02, -4.27282602e-02,  3.92237678e-02,\n",
       "            1.33883702e-02,  1.49864042e-02, -5.34554347e-02,\n",
       "           -4.01045978e-01,  8.35290030e-02, -3.08230892e-02,\n",
       "           -2.28504967e-02, -2.12029796e-02, -1.32318391e-02,\n",
       "            2.92256027e-02, -4.06443067e-02, -1.43701797e-02,\n",
       "            7.45008653e-03,  6.86132312e-02, -7.08537027e-02,\n",
       "            4.95040556e-03,  1.15517564e-01, -1.11992218e-01,\n",
       "            1.05836876e-02, -5.00375256e-02,  1.34769948e-02,\n",
       "           -8.41541030e-03, -3.25177237e-02, -7.78927356e-02,\n",
       "            3.97719927e-02, -6.58989996e-02, -1.89196225e-03,\n",
       "            3.71730253e-02, -3.84644866e-02,  2.29280423e-02,\n",
       "            2.73162499e-02, -6.29627630e-02, -8.54609236e-02,\n",
       "           -2.91881949e-01, -4.50955033e-01,  3.01614460e-02]],\n",
       " \n",
       "         [[-6.09965958e-02, -2.40172725e-02,  8.94093886e-02,\n",
       "            1.69046521e-02,  1.54117486e-02,  2.30661593e-02,\n",
       "           -2.96176393e-02, -4.49018218e-02,  1.61180701e-02,\n",
       "           -4.88066003e-02, -5.30605465e-02,  1.51297264e-02,\n",
       "           -1.93366989e-01, -5.64731695e-02,  1.19414870e-02,\n",
       "           -4.75971662e-02, -1.30379155e-01, -2.03413561e-01,\n",
       "            1.33217528e-01, -8.53216797e-02, -6.64180815e-02,\n",
       "           -1.44217247e-02, -8.49591941e-03, -4.27780300e-02,\n",
       "           -3.16400453e-02, -2.22945571e-01,  9.39968787e-03,\n",
       "           -3.63027267e-02, -1.24427620e-02,  3.98436328e-04,\n",
       "            3.29248905e-02,  2.71101892e-02, -2.78086755e-02,\n",
       "           -1.13613412e-01, -6.14866987e-02,  1.82569817e-01,\n",
       "            1.77926626e-02,  3.19087654e-02, -3.21319327e-02,\n",
       "            3.98292653e-02, -1.79014727e-02,  1.13291852e-02,\n",
       "            5.80909476e-02, -4.12707590e-02, -7.17880949e-02,\n",
       "            1.33080125e-01, -2.31420007e-02, -3.93268503e-02]],\n",
       " \n",
       "         [[-1.85078122e-02, -1.95520148e-02,  1.80153549e-03,\n",
       "           -4.61243140e-03,  1.74168241e-03, -6.30231425e-02,\n",
       "           -5.58160022e-02,  8.93727131e-03, -2.48312652e-02,\n",
       "            2.37434842e-02, -3.38509381e-02, -1.40932258e-02,\n",
       "            9.58765373e-02, -8.77865553e-02,  4.32357527e-02,\n",
       "            1.34203315e-01,  2.83084512e-02, -4.87840734e-02,\n",
       "            9.76697132e-02, -7.24695027e-02, -3.92037258e-02,\n",
       "            2.96893157e-03, -5.82427084e-02, -2.50852518e-02,\n",
       "           -7.26443902e-02,  2.14018766e-02, -1.53662078e-02,\n",
       "           -5.53085171e-02, -1.27767295e-01, -6.67991862e-02,\n",
       "            4.26099896e-02,  2.25350298e-02, -3.43689695e-02,\n",
       "            4.55631292e-04,  2.79770587e-02, -4.58253026e-02,\n",
       "            4.11878116e-02, -3.38465124e-02, -5.92682846e-02,\n",
       "           -8.99417475e-02, -4.20290232e-02, -1.21104503e-02,\n",
       "           -3.21982033e-03, -1.22623909e-02,  3.73210534e-02,\n",
       "           -1.25483945e-02, -2.77019948e-01,  1.60350581e-03]],\n",
       " \n",
       "         [[-3.19128744e-02,  8.22433159e-02,  6.48294017e-02,\n",
       "            2.32698694e-02, -6.46874160e-02, -6.43964857e-02,\n",
       "           -1.57973263e-02, -5.20819314e-02,  3.26817594e-02,\n",
       "           -6.38056174e-02, -8.50205310e-03,  5.35205975e-02,\n",
       "           -2.09245175e-01, -5.42610232e-03,  5.85328601e-02,\n",
       "           -2.23212644e-01,  9.96253788e-02, -1.88242540e-01,\n",
       "           -5.04486486e-02, -1.22376978e-02, -1.78783499e-02,\n",
       "           -3.57980505e-02,  1.84742790e-02, -5.82251092e-03,\n",
       "           -7.95445442e-02,  6.32455572e-02, -9.85596096e-04,\n",
       "           -5.65800145e-02, -3.40869501e-02, -1.23266913e-02,\n",
       "           -8.95188004e-02, -7.82303978e-03, -4.44488190e-02,\n",
       "           -7.10411593e-02, -1.41767673e-02,  2.07096376e-02,\n",
       "           -1.14733309e-01, -1.89131070e-02, -1.73487067e-02,\n",
       "            1.02033064e-01, -6.64460585e-02, -8.62296391e-03,\n",
       "            1.26756048e-02, -3.24876942e-02, -7.26931840e-02,\n",
       "            8.97153020e-02,  8.29102173e-02, -1.22770034e-01]]],\n",
       " \n",
       " \n",
       "        [[[-2.39827596e-02, -1.33641765e-01,  1.09197401e-01,\n",
       "           -3.62655111e-02, -3.47779170e-02, -6.45992532e-02,\n",
       "           -1.09929973e-02, -1.14660710e-02, -4.57110666e-02,\n",
       "           -7.58282468e-02, -6.59616292e-02, -4.63717356e-02,\n",
       "            1.01757437e-01, -2.86749657e-02, -2.30015926e-02,\n",
       "           -1.68379381e-01,  5.67695647e-02, -1.55755535e-01,\n",
       "           -5.48298704e-05, -1.65873319e-02, -1.83067415e-02,\n",
       "           -8.65032524e-02, -6.67673796e-02, -2.24132352e-02,\n",
       "            3.44572403e-02,  9.23778769e-03, -4.13875878e-02,\n",
       "            4.04303484e-02, -1.20716244e-01, -1.09297052e-01,\n",
       "           -1.04279213e-01, -1.19400667e-02,  7.03205727e-03,\n",
       "           -3.98696885e-02, -2.73015071e-02,  1.10217240e-02,\n",
       "            2.87154336e-02, -3.92345935e-02, -2.53835414e-02,\n",
       "            5.53633831e-02, -2.40250621e-02, -6.08920529e-02,\n",
       "           -3.83172967e-02, -6.08744919e-02, -1.00507304e-01,\n",
       "            1.37730241e-01, -7.17665851e-02,  3.86990942e-02]],\n",
       " \n",
       "         [[ 1.17349559e-02, -3.04222032e-02,  4.23012301e-02,\n",
       "           -1.24132770e-04, -3.20768878e-02, -2.13089474e-02,\n",
       "           -3.46358307e-02,  4.42524180e-02,  1.53798768e-02,\n",
       "           -6.78239092e-02,  4.01677229e-02, -4.45552990e-02,\n",
       "            1.13079539e-02, -2.44897697e-02, -5.03175743e-02,\n",
       "            1.59795195e-01,  3.76145840e-02, -9.46950242e-02,\n",
       "            1.27757385e-01,  2.40033939e-02,  1.11346541e-03,\n",
       "           -6.21477589e-02, -7.49104097e-02,  2.52441247e-03,\n",
       "           -4.17576879e-02, -3.22092697e-02, -7.61009827e-02,\n",
       "           -3.65254208e-02, -2.88006663e-01,  3.06697637e-02,\n",
       "           -2.63904855e-02,  8.37675948e-03,  3.37808430e-02,\n",
       "            3.05476002e-02, -5.00760302e-02, -1.70910239e-01,\n",
       "           -5.33397235e-02,  9.15552210e-03, -4.02538031e-02,\n",
       "           -1.78275574e-02, -6.16391525e-02, -4.06734413e-04,\n",
       "           -9.52452347e-02,  2.85217315e-02, -5.60044218e-03,\n",
       "            5.94467260e-02,  4.66501899e-02, -9.71783027e-02]],\n",
       " \n",
       "         [[-2.85484567e-02, -9.14775059e-02,  2.02593610e-01,\n",
       "            1.89781014e-03, -1.31666390e-02,  1.04386639e-02,\n",
       "           -6.77378997e-02,  1.94728766e-02,  2.49491278e-02,\n",
       "           -4.16589044e-02,  2.89866887e-02, -2.70206016e-02,\n",
       "           -7.68762156e-02, -3.17172483e-02, -4.41476591e-02,\n",
       "            9.82930213e-02, -1.74427360e-01,  2.14709085e-03,\n",
       "            5.60333095e-02,  2.00745054e-02, -3.18879299e-02,\n",
       "           -5.17904498e-02, -3.70223038e-02,  3.58329192e-02,\n",
       "           -5.38514182e-02,  5.28279878e-02, -2.05324814e-02,\n",
       "           -1.88056976e-02, -1.67429969e-01, -7.60369897e-02,\n",
       "           -2.42197905e-02, -3.23639659e-04,  5.22847380e-03,\n",
       "            3.35585326e-02, -7.00974986e-02,  1.57453299e-01,\n",
       "           -1.81357060e-02, -4.75630630e-03, -1.67789422e-02,\n",
       "            6.07492030e-03,  1.32887084e-02,  1.13844676e-02,\n",
       "            5.90042258e-03, -3.73511910e-02, -1.55359576e-03,\n",
       "            8.85852352e-02, -1.38830736e-01, -4.12750579e-02]],\n",
       " \n",
       "         [[-9.49633308e-03,  7.37386942e-02, -3.86423953e-02,\n",
       "            2.41234712e-03, -6.44281879e-02,  2.51183044e-02,\n",
       "           -3.91800702e-02,  3.44020873e-02, -2.85961702e-02,\n",
       "           -5.39983846e-02,  2.45653540e-02, -1.48478243e-02,\n",
       "            6.10072613e-02, -1.08413901e-02, -1.97680984e-02,\n",
       "           -1.17604494e-01,  1.12370074e-01, -2.09041849e-01,\n",
       "           -7.50079602e-02, -6.16116226e-02, -5.83342686e-02,\n",
       "            4.18758951e-02,  1.88914360e-04, -7.69978985e-02,\n",
       "            7.21001346e-03, -3.74963954e-02, -1.05066597e-01,\n",
       "            9.99704283e-03,  2.28650406e-01, -7.58994594e-02,\n",
       "            1.51716918e-02, -3.45126502e-02,  4.60253768e-02,\n",
       "            1.15213841e-02, -5.21923266e-02, -1.76511809e-01,\n",
       "            6.29086122e-02, -5.60905188e-02, -5.62503189e-02,\n",
       "            1.87337995e-02, -7.03960210e-02, -1.87663380e-02,\n",
       "           -7.44814100e-03, -4.98252138e-02, -7.56344423e-02,\n",
       "           -2.15913668e-01,  3.77757959e-02, -3.31924781e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.32381553e-02, -5.27140871e-02, -4.06149536e-01,\n",
       "           -2.49607451e-02,  2.92070545e-02, -7.74288103e-02,\n",
       "           -2.41598289e-04, -5.99725097e-02, -3.59688699e-02,\n",
       "            9.41203814e-03, -4.64069955e-02, -6.62827045e-02,\n",
       "           -4.55304794e-02, -4.79618832e-02, -1.47897506e-03,\n",
       "           -1.43212080e-01, -1.56286269e-01, -1.98226452e-01,\n",
       "           -4.71407473e-02, -7.49133974e-02,  2.39385348e-02,\n",
       "            4.15756293e-02, -6.17997870e-02, -6.10830300e-02,\n",
       "            3.07449494e-02, -1.60357460e-01,  2.12567449e-02,\n",
       "           -6.90362081e-02,  2.40101144e-01, -9.76315439e-02,\n",
       "            3.43324803e-03, -8.02073814e-03, -5.34112658e-03,\n",
       "           -1.75293852e-02, -2.07429770e-02,  8.23032483e-02,\n",
       "           -6.32388890e-02,  7.81860016e-03, -5.32375053e-02,\n",
       "           -1.81719154e-01, -6.20883070e-02, -5.05889170e-02,\n",
       "            1.00657064e-02, -3.30280997e-02, -9.77131277e-02,\n",
       "           -6.81584924e-02, -6.57414496e-02,  4.51779291e-02]],\n",
       " \n",
       "         [[ 3.87961231e-02,  7.33286813e-02,  1.40185967e-01,\n",
       "           -2.99361553e-02, -3.71151641e-02, -4.59322408e-02,\n",
       "           -2.88279750e-03,  1.24430740e-02,  2.53634192e-02,\n",
       "           -2.22875997e-02, -9.21222195e-03, -5.81197329e-02,\n",
       "            1.47081628e-01,  3.36763379e-03, -7.24665374e-02,\n",
       "           -1.40613806e-03,  7.80660883e-02,  2.36266595e-03,\n",
       "            9.34615359e-02,  9.82676260e-03,  2.65425574e-02,\n",
       "           -6.95787445e-02, -3.71330865e-02, -6.83717430e-02,\n",
       "           -1.22645553e-02,  1.18286628e-02, -8.94229263e-02,\n",
       "           -1.93186421e-02, -4.40336674e-01, -1.11674637e-01,\n",
       "           -9.86016691e-02, -4.23080362e-02,  2.50276048e-02,\n",
       "           -2.57788338e-02, -3.58271934e-02,  1.00902826e-01,\n",
       "           -8.08209740e-03,  3.69848087e-02, -7.15992600e-02,\n",
       "            1.13080956e-01, -5.17883280e-04, -7.03384131e-02,\n",
       "           -4.37998325e-02,  3.31587438e-03, -1.70507357e-02,\n",
       "            1.32111505e-01, -3.15961763e-02, -3.73617858e-02]],\n",
       " \n",
       "         [[ 3.92776728e-02,  2.87099089e-03,  9.01860669e-02,\n",
       "           -2.54329033e-02, -1.11259848e-01, -2.01952159e-02,\n",
       "           -6.61024749e-02,  1.01854522e-02,  4.29111570e-02,\n",
       "           -1.65367359e-03, -7.02151880e-02, -3.44833471e-02,\n",
       "            1.46832854e-01, -4.94346134e-02, -1.02578904e-02,\n",
       "           -4.48223278e-02,  1.05415568e-01, -1.30108431e-01,\n",
       "            6.54582381e-02,  4.85654548e-03, -5.89835942e-02,\n",
       "           -3.71677093e-02, -1.35063231e-01,  3.43866758e-02,\n",
       "           -2.92809177e-02,  9.48299617e-02, -8.45905989e-02,\n",
       "           -4.78504077e-02, -3.42621773e-01, -1.35982856e-01,\n",
       "            3.24343704e-02, -3.83475423e-03,  3.72497626e-02,\n",
       "            3.32456152e-03, -6.04580417e-02,  5.94096482e-02,\n",
       "           -7.77897835e-02, -6.11135997e-02,  1.77076403e-02,\n",
       "            1.48203477e-01, -5.00723682e-02, -1.80633012e-02,\n",
       "           -9.64097492e-03,  1.00456635e-02, -7.52193034e-02,\n",
       "            1.41239822e-01, -3.27662587e-01, -4.39117886e-02]],\n",
       " \n",
       "         [[ 1.70919374e-02,  1.14316396e-01,  4.36224230e-02,\n",
       "           -3.71317342e-02, -3.07539795e-02, -7.12018833e-02,\n",
       "           -5.18236794e-02, -6.25904128e-02, -8.06378797e-02,\n",
       "           -5.89811243e-03, -5.01239784e-02, -7.63352439e-02,\n",
       "           -1.36965849e-02, -6.22117147e-03, -1.21623361e-02,\n",
       "           -6.58230409e-02, -1.62739232e-01, -2.05080584e-01,\n",
       "           -4.04901877e-02, -3.13304998e-02,  2.91476753e-02,\n",
       "           -6.19082116e-02,  6.14577346e-02, -7.86657855e-02,\n",
       "            3.95011418e-02, -1.19712524e-01,  2.03072070e-03,\n",
       "           -3.45360972e-02, -4.81461659e-02,  3.38668586e-03,\n",
       "            4.03478853e-02, -9.27676726e-03, -1.68120908e-03,\n",
       "           -3.75737734e-02, -1.30404951e-02, -1.63148995e-02,\n",
       "            2.24777274e-02, -5.24920970e-02, -3.04453485e-02,\n",
       "           -1.64444312e-01, -4.45726141e-02, -3.80645096e-02,\n",
       "            3.26968282e-02,  4.26451564e-02, -3.49810459e-02,\n",
       "            6.65462762e-02,  1.59998417e-01,  6.38985410e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(48,) dtype=float32, numpy=\n",
       " array([-0.04352523, -0.30469504,  0.46394035, -0.08659493, -0.05639281,\n",
       "        -0.03177694, -0.03346823, -0.05704365, -0.13205875, -0.04045991,\n",
       "        -0.03491086, -0.0378111 , -0.23914522, -0.05306875, -0.02595105,\n",
       "        -0.04500474, -0.2516165 , -0.09459574,  0.30032095, -0.03388102,\n",
       "        -0.04222819, -0.1255511 , -0.18880367, -0.03376091, -0.10936197,\n",
       "        -0.11110068, -0.08665928, -0.03252149, -0.12803145, -0.09527595,\n",
       "        -0.06402192, -0.04382389, -0.09109075, -0.05929873, -0.00924136,\n",
       "        -0.27609986, -0.17362876, -0.05237428, -0.00999288, -0.18706207,\n",
       "        -0.03031734, -0.04143571, -0.08906052, -0.09244434, -0.07127666,\n",
       "         0.16943443, -0.03361089, -0.11431061], dtype=float32)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 46, 1, 48) dtype=float32 (created by layer 'conv2d')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 2s 900us/step\n",
      "390/390 [==============================] - 0s 777us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = model.layers[1].weights[0]\n",
    "first_conv_biases = model.layers[1].weights[1]\n",
    "# Format: [Position 0: A, C, G, T, Position 1: A, C, G, T, Position 2: A, C, G, T]\n",
    "pd.DataFrame(array(first_conv_weights).transpose((3,2,0,1)).reshape(first_conv_weights.shape[-1], -1)).to_csv(save_path + model_name+\"_tiling_first_conv_kernels\")\n",
    "pd.DataFrame(first_conv_biases).to_csv(save_path + model_name+\"_tiling_first_conv_biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
