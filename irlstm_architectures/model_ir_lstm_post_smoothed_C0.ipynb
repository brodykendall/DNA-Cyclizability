{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/Brody1/Dropbox/Northwestern/DNA_Cyclizability/benchmarks/\"\n",
    "model_name = \"ir_lstm_post_smoothed_5bp_DNAcycP_chrv\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(48, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # parallel line 1\n",
    "    fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "                   activation='relu',\n",
    "                   padding='same')(x)\n",
    "    fx1 = BatchNormalization()(fx1)\n",
    "    fx1 = Dropout(0.2)(fx1)\n",
    "    fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "                   activation='relu',\n",
    "                   padding='same')(fx1)\n",
    "    fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    fx1 = BatchNormalization()(fx1)\n",
    "    fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # parallel line 2\n",
    "    fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "                   activation='relu',\n",
    "                   padding='same')(x)\n",
    "    fx2 = BatchNormalization()(fx2)\n",
    "    fx2 = Dropout(0.2)(fx2)\n",
    "    fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "                   activation='relu',\n",
    "                   padding='same')(fx2)\n",
    "    fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    fx2 = BatchNormalization()(fx2)\n",
    "    fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # Add\n",
    "    x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    x = Add()([x, x1])\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    x = LSTM(20, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Dropbox/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "Y1_C0 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "m1 = np.mean(Y1_C0)\n",
    "std1 = np.std(Y1_C0)\n",
    "Z1_C0 = (Y1_C0-m1)/std1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Dropbox/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "Y3_C0 = data_random_library[\"C0\"].values.astype(float)\n",
    "m3 = np.mean(Y3_C0)\n",
    "std3 = np.std(Y3_C0)\n",
    "Z3_C0 = (Y3_C0-m3)/std3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Dropbox/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "Y5_C0 = data_tiling[\"C0\"].values.astype(float)\n",
    "m5 = np.mean(Y5_C0)\n",
    "std5 = np.std(Y5_C0)\n",
    "Z5_C0 = (Y5_C0-m5)/std5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82277, 32)\n"
     ]
    }
   ],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Dropbox/Northwestern/DNA_Cyclizability/data/Created/yeast_chrV_ir_lstm_tiling_post_smoothed_matched.csv\")\n",
    "# Remove first row:\n",
    "data_chr5 = data_chr5.iloc[1:(data_chr5.shape[0]-1),]\n",
    "print(data_chr5.shape)\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "Y6 = data_chr5[\"DNAcycP_pred_chrV_post_smooth_5bp\"].values.astype(float)\n",
    "Y6_C0 = data_chr5[\"C0\"].values.astype(float)\n",
    "m6 = np.mean(Y6)\n",
    "std6 = np.std(Y6)\n",
    "Z6 = (Y6-m6)/std6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### chrv\n",
    "\n",
    "# VALIDATION_LOSS = []\n",
    "# fold_var = 1\n",
    "# n = Z6.shape[0]\n",
    "\n",
    "# fits = []\n",
    "# detrend = []\n",
    "# times = []\n",
    "# times2 = []\n",
    "\n",
    "# for train_index, val_index in kf.split(Z6):\n",
    "#     training_X = X6[train_index]\n",
    "#     training_X_reverse = X6_reverse[train_index]\n",
    "#     validation_X = X6[val_index]\n",
    "#     validation_X_reverse = X6_reverse[val_index]\n",
    "#     training_Y = Z6[train_index]\n",
    "#     validation_Y = Z6[val_index]\n",
    "#     # CREATE NEW MODEL\n",
    "#     model = model_cycle()\n",
    "#     # CREATE CALLBACKS\n",
    "#     checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_chrv_\"+str(fold_var)+\".h5\",\n",
    "#                                                     monitor='val_loss', verbose=1,\n",
    "#                                                     save_best_only=True, mode='min')\n",
    "#     time_callback = TimeHistory()\n",
    "\n",
    "#     history = model.fit(training_X, training_Y,\n",
    "#                         epochs=num_epochs,\n",
    "#                         callbacks= [checkpoint, time_callback],\n",
    "#                         validation_data=(validation_X, validation_Y))\n",
    "#     model.load_weights(save_path + model_name+\"_chrv_\"+str(fold_var)+\".h5\")\n",
    "#     model.save(save_path+ model_name+\"_chrv_\"+str(fold_var),save_traces=False)\n",
    "#     times.append(time_callback.times)\n",
    "\n",
    "#     pred_Y = model.predict(training_X)\n",
    "#     pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "#     pred_Y_reverse = model.predict(training_X_reverse)\n",
    "#     pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "#     pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "#     reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "#     detrend_int = reg.intercept_\n",
    "#     detrend_slope = reg.coef_\n",
    "#     detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "    \n",
    "#     start_time = time.process_time()\n",
    "#     fit = model.predict(validation_X)\n",
    "#     fit = fit.reshape(fit.shape[0])\n",
    "#     fit_reverse = model.predict(validation_X_reverse)\n",
    "#     fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "#     reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "#     fit = (fit + fit_reverse)/2\n",
    "#     fit = fit.flatten()\n",
    "#     fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "#     fits.append(fit_tmp)\n",
    "#     fit = detrend_int + fit * detrend_slope\n",
    "#     fit = fit.flatten()\n",
    "#     fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "#     time0 = time.process_time() - start_time\n",
    "#     times2.append([time0])\n",
    "#     fits.append(fit_tmp)\n",
    "    \n",
    "#     K.clear_session()\n",
    "#     fold_var += 1\n",
    "\n",
    "# detrend = array(detrend)\n",
    "# detrend = pd.DataFrame(detrend)\n",
    "# detrend.to_csv(save_path +model_name+\"_detrend_chrv.txt\", index = False)\n",
    "\n",
    "# fits = array(fits)\n",
    "# fits = pd.DataFrame((fits))\n",
    "# fits.to_csv(save_path +model_name+\"_fits_chrv.txt\", index = False)\n",
    "\n",
    "# with open(save_path +model_name+\"_time_chrv.txt\", \"w\") as file:\n",
    "#     for row in times:\n",
    "#         s = \" \".join(map(str, row))\n",
    "#         file.write(s+'\\n')\n",
    "\n",
    "# with open(save_path +model_name+\"_pred_time_chrv.txt\", \"w\") as file:\n",
    "#     for row in times2:\n",
    "#         s = \" \".join(map(str, row))\n",
    "#         file.write(s+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chrv = keras.models.load_model(save_path + model_name + \"_chrv_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "chrv_pred_nuc = model_chrv.predict(X1)*std1 + m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "chrv_pred_random = model_chrv.predict(X3)*std3 + m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "chrv_pred_tiling = model_chrv.predict(X5)*std5 + m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "chrv_pred_chrv = model_chrv.predict(X6)*std6 + m6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between predicted smooth C0 and original C0, nucleosome library: 0.868\n",
      "\t (compared to 0.893)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation between predicted smooth C0 and original C0, nucleosome library: {round(np.corrcoef(array(chrv_pred_nuc).reshape(-1), Y1_C0)[0,1], 3)}\")\n",
    "print(f\"\\t (compared to 0.893)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between predicted smooth C0 and original C0, random library: 0.896\n",
      "\t (compared to 0.930)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation between predicted smooth C0 and original C0, random library: {round(np.corrcoef(array(chrv_pred_random).reshape(-1), Y3_C0)[0,1], 3)}\")\n",
    "print(f\"\\t (compared to 0.930)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between predicted smooth C0 and original C0, tiling library: 0.886\n",
      "\t (compared to 0.916)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation between predicted smooth C0 and original C0, tiling library: {round(np.corrcoef(array(chrv_pred_tiling).reshape(-1), Y5_C0)[0,1], 3)}\")\n",
    "print(f\"\\t (compared to 0.916)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between predicted smooth C0 and original C0, chrV library: 0.747\n",
      "\t (compared to 0.773)\n",
      "Correlation between smooth C0 and original C0, chrV library: 0.751\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation between predicted smooth C0 and original C0, chrV library: {round(np.corrcoef(array(chrv_pred_chrv).reshape(-1), Y6_C0)[0,1], 3)}\")\n",
    "print(f\"\\t (compared to 0.773)\")\n",
    "print(f\"Correlation between smooth C0 and original C0, chrV library: {round(np.corrcoef(Y6, Y6_C0)[0,1], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
