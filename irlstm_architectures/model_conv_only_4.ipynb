{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 10:40:26.700830: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, TimeDistributed, Input, Add, Concatenate\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, LSTM, TimeDistributed, Reshape\n",
    "import keras.backend as K\n",
    "import keras.callbacks as callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/\"\n",
    "model_name = \"conv_only_4\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 10\n",
    "\n",
    "#### define functions ####\n",
    "\n",
    "def model_cycle():\n",
    "    inputs = Input(shape=(50, 4, 1))\n",
    "        \n",
    "    x = Conv2D(4, kernel_size=(3,4),\n",
    "                   activation='relu',\n",
    "                   padding='valid')(inputs)\n",
    "    x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After first convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = Conv1D(48, kernel_size=(11),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After second convolutional layer: x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((24,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # print(f\"After third convolutional layer, x.shape = {x.shape}\")\n",
    "\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    # x = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # x = MaxPooling2D((12,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # # parallel line 1\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    # fx1 = Conv2D(48, kernel_size=(3,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx1)\n",
    "    # fx1 = MaxPooling2D((2,1),padding='same')(fx1)\n",
    "    # fx1 = BatchNormalization()(fx1)\n",
    "    # fx1 = Dropout(0.2)(fx1)\n",
    "    \n",
    "    # # parallel line 2\n",
    "    # fx2 = Conv2D(48, kernel_size=(11,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(x)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    # fx2 = Conv2D(48, kernel_size=(21,1),\n",
    "    #                activation='relu',\n",
    "    #                padding='same')(fx2)\n",
    "    # fx2 = MaxPooling2D((2,1),padding='same')(fx2)\n",
    "    # fx2 = BatchNormalization()(fx2)\n",
    "    # fx2 = Dropout(0.2)(fx2)\n",
    "    \n",
    "    # # # Add\n",
    "    # x1 = Concatenate(axis=-3)([fx1, fx2])\n",
    "    # x = Add()([x, x1])\n",
    "    # x = MaxPooling2D((2,1),padding='same')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    \n",
    "    # x = Reshape((K.int_shape(x)[1], K.int_shape(x)[3]))(x)\n",
    "    # x = LSTM(20, return_sequences=False)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    # x = Reshape((1, 24*48))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    # print(outputs.shape)\n",
    "    network = Model(inputs, outputs)\n",
    "    network.compile(optimizer='rmsprop',\n",
    "                    loss='mean_squared_error')\n",
    "    return network\n",
    "    \n",
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 5])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 3])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 7])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 8) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 8) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], np.transpose(inv_mat)))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.process_time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.process_time() - self.epoch_time_start)\n",
    "        \n",
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append(dnaOneHot(sequence_nt))\n",
    "X1 = array(X1)\n",
    "X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = find_c0new(data_cerevisiae_nucle).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = array(X3)\n",
    "X3 = X3.reshape((X3.shape[0],50,4,1))\n",
    "X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = find_c0new(data_random_library).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = array(X5)\n",
    "X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = find_c0new(data_tiling).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/DNA_Cyclizability/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = array(X6)\n",
    "X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = find_c0new(data_chr5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:08:45.315939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.3297\n",
      "Epoch 1: val_loss improved from inf to 0.22200, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3296 - val_loss: 0.2220\n",
      "Epoch 2/10\n",
      "2281/2317 [============================>.] - ETA: 0s - loss: 0.2253\n",
      "Epoch 2: val_loss improved from 0.22200 to 0.21689, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2252 - val_loss: 0.2169\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 3: val_loss improved from 0.21689 to 0.21616, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2234 - val_loss: 0.2162\n",
      "Epoch 4/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2231\n",
      "Epoch 4: val_loss improved from 0.21616 to 0.21457, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2231 - val_loss: 0.2146\n",
      "Epoch 5/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2230\n",
      "Epoch 5: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2230 - val_loss: 0.2154\n",
      "Epoch 6/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2228\n",
      "Epoch 6: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2229 - val_loss: 0.2151\n",
      "Epoch 7/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2227\n",
      "Epoch 7: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2229 - val_loss: 0.2176\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2230\n",
      "Epoch 8: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2230 - val_loss: 0.2153\n",
      "Epoch 9/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2225\n",
      "Epoch 9: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2225 - val_loss: 0.2177\n",
      "Epoch 10/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2224\n",
      "Epoch 10: val_loss did not improve from 0.21457\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2221 - val_loss: 0.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 709us/step\n",
      "2317/2317 [==============================] - 2s 685us/step\n",
      "623/623 [==============================] - 0s 657us/step\n",
      "623/623 [==============================] - 0s 709us/step\n",
      "390/390 [==============================] - 0s 775us/step\n",
      "390/390 [==============================] - 0s 714us/step\n",
      "258/258 [==============================] - 0s 712us/step\n",
      "258/258 [==============================] - 0s 601us/step\n",
      "2576/2576 [==============================] - 2s 680us/step\n",
      "2576/2576 [==============================] - 2s 670us/step\n",
      "Epoch 1/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2988\n",
      "Epoch 1: val_loss improved from inf to 0.22765, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2984 - val_loss: 0.2276\n",
      "Epoch 2/10\n",
      "2280/2317 [============================>.] - ETA: 0s - loss: 0.2243\n",
      "Epoch 2: val_loss improved from 0.22765 to 0.22616, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2247 - val_loss: 0.2262\n",
      "Epoch 3/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 3: val_loss improved from 0.22616 to 0.22603, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2241 - val_loss: 0.2260\n",
      "Epoch 4/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 4: val_loss improved from 0.22603 to 0.22477, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2238 - val_loss: 0.2248\n",
      "Epoch 5/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.2235\n",
      "Epoch 5: val_loss did not improve from 0.22477\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2238 - val_loss: 0.2260\n",
      "Epoch 6/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2233\n",
      "Epoch 6: val_loss did not improve from 0.22477\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2233 - val_loss: 0.2257\n",
      "Epoch 7/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2230\n",
      "Epoch 7: val_loss did not improve from 0.22477\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2230 - val_loss: 0.2255\n",
      "Epoch 8/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2230\n",
      "Epoch 8: val_loss did not improve from 0.22477\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2232 - val_loss: 0.2272\n",
      "Epoch 9/10\n",
      "2294/2317 [============================>.] - ETA: 0s - loss: 0.2232\n",
      "Epoch 9: val_loss did not improve from 0.22477\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2231 - val_loss: 0.2270\n",
      "Epoch 10/10\n",
      "2283/2317 [============================>.] - ETA: 0s - loss: 0.2235\n",
      "Epoch 10: val_loss improved from 0.22477 to 0.22417, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2.h5\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2233 - val_loss: 0.2242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 776us/step\n",
      "2317/2317 [==============================] - 2s 858us/step\n",
      "623/623 [==============================] - 1s 788us/step\n",
      "623/623 [==============================] - 1s 775us/step\n",
      "390/390 [==============================] - 0s 783us/step\n",
      "390/390 [==============================] - 0s 777us/step\n",
      "258/258 [==============================] - 0s 761us/step\n",
      "258/258 [==============================] - 0s 766us/step\n",
      "2576/2576 [==============================] - 2s 812us/step\n",
      "2576/2576 [==============================] - 2s 812us/step\n",
      "Epoch 1/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.3164\n",
      "Epoch 1: val_loss improved from inf to 0.22276, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3156 - val_loss: 0.2228\n",
      "Epoch 2/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2245\n",
      "Epoch 2: val_loss improved from 0.22276 to 0.22159, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_3.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2245 - val_loss: 0.2216\n",
      "Epoch 3/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 3: val_loss did not improve from 0.22159\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2236 - val_loss: 0.2219\n",
      "Epoch 4/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 4: val_loss improved from 0.22159 to 0.22079, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_3.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2240 - val_loss: 0.2208\n",
      "Epoch 5/10\n",
      "2273/2317 [============================>.] - ETA: 0s - loss: 0.2242\n",
      "Epoch 5: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2239 - val_loss: 0.2214\n",
      "Epoch 6/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2236\n",
      "Epoch 6: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2237 - val_loss: 0.2217\n",
      "Epoch 7/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2239\n",
      "Epoch 7: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2240 - val_loss: 0.2214\n",
      "Epoch 8/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 8: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2240 - val_loss: 0.2211\n",
      "Epoch 9/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2237\n",
      "Epoch 9: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2237 - val_loss: 0.2219\n",
      "Epoch 10/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 10: val_loss did not improve from 0.22079\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.2233 - val_loss: 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 871us/step\n",
      "2317/2317 [==============================] - 2s 795us/step\n",
      "623/623 [==============================] - 1s 809us/step\n",
      "623/623 [==============================] - 1s 801us/step\n",
      "390/390 [==============================] - 0s 782us/step\n",
      "390/390 [==============================] - 0s 796us/step\n",
      "258/258 [==============================] - 0s 791us/step\n",
      "258/258 [==============================] - 0s 811us/step\n",
      "2576/2576 [==============================] - 2s 799us/step\n",
      "2576/2576 [==============================] - 2s 830us/step\n",
      "Epoch 1/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.3165\n",
      "Epoch 1: val_loss improved from inf to 0.21403, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3162 - val_loss: 0.2140\n",
      "Epoch 2/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2237\n",
      "Epoch 2: val_loss improved from 0.21403 to 0.21380, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2238 - val_loss: 0.2138\n",
      "Epoch 3/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2232\n",
      "Epoch 3: val_loss improved from 0.21380 to 0.21346, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2232 - val_loss: 0.2135\n",
      "Epoch 4/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2232\n",
      "Epoch 4: val_loss improved from 0.21346 to 0.21188, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2232 - val_loss: 0.2119\n",
      "Epoch 5/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2232\n",
      "Epoch 5: val_loss improved from 0.21188 to 0.21187, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2231 - val_loss: 0.2119\n",
      "Epoch 6/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2238\n",
      "Epoch 6: val_loss improved from 0.21187 to 0.21174, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2237 - val_loss: 0.2117\n",
      "Epoch 7/10\n",
      "2291/2317 [============================>.] - ETA: 0s - loss: 0.2231\n",
      "Epoch 7: val_loss did not improve from 0.21174\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2231 - val_loss: 0.2119\n",
      "Epoch 8/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2233\n",
      "Epoch 8: val_loss did not improve from 0.21174\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2233 - val_loss: 0.2120\n",
      "Epoch 9/10\n",
      "2305/2317 [============================>.] - ETA: 0s - loss: 0.2226\n",
      "Epoch 9: val_loss did not improve from 0.21174\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2227 - val_loss: 0.2125\n",
      "Epoch 10/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 10: val_loss improved from 0.21174 to 0.21151, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2231 - val_loss: 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 743us/step\n",
      "2317/2317 [==============================] - 2s 741us/step\n",
      "623/623 [==============================] - 1s 864us/step\n",
      "623/623 [==============================] - 1s 807us/step\n",
      "390/390 [==============================] - 0s 768us/step\n",
      "390/390 [==============================] - 0s 792us/step\n",
      "258/258 [==============================] - 0s 748us/step\n",
      "258/258 [==============================] - 0s 799us/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 3s 998us/step\n",
      "Epoch 1/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.3174\n",
      "Epoch 1: val_loss improved from inf to 0.22102, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3174 - val_loss: 0.2210\n",
      "Epoch 2/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2234\n",
      "Epoch 2: val_loss improved from 0.22102 to 0.21757, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2234 - val_loss: 0.2176\n",
      "Epoch 3/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2223\n",
      "Epoch 3: val_loss improved from 0.21757 to 0.21648, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2224 - val_loss: 0.2165\n",
      "Epoch 4/10\n",
      "2295/2317 [============================>.] - ETA: 0s - loss: 0.2221\n",
      "Epoch 4: val_loss improved from 0.21648 to 0.21648, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2219 - val_loss: 0.2165\n",
      "Epoch 5/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2206\n",
      "Epoch 5: val_loss improved from 0.21648 to 0.21478, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2206 - val_loss: 0.2148\n",
      "Epoch 6/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2201\n",
      "Epoch 6: val_loss did not improve from 0.21478\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2202 - val_loss: 0.2150\n",
      "Epoch 7/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2201\n",
      "Epoch 7: val_loss improved from 0.21478 to 0.21475, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2200 - val_loss: 0.2147\n",
      "Epoch 8/10\n",
      "2308/2317 [============================>.] - ETA: 0s - loss: 0.2202\n",
      "Epoch 8: val_loss did not improve from 0.21475\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2202 - val_loss: 0.2154\n",
      "Epoch 9/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2204\n",
      "Epoch 9: val_loss did not improve from 0.21475\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2202 - val_loss: 0.2161\n",
      "Epoch 10/10\n",
      "2289/2317 [============================>.] - ETA: 0s - loss: 0.2200\n",
      "Epoch 10: val_loss did not improve from 0.21475\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2199 - val_loss: 0.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 738us/step\n",
      "2317/2317 [==============================] - 2s 746us/step\n",
      "623/623 [==============================] - 1s 771us/step\n",
      "623/623 [==============================] - 0s 741us/step\n",
      "390/390 [==============================] - 0s 748us/step\n",
      "390/390 [==============================] - 0s 738us/step\n",
      "258/258 [==============================] - 0s 739us/step\n",
      "258/258 [==============================] - 0s 760us/step\n",
      "2576/2576 [==============================] - 2s 754us/step\n",
      "2576/2576 [==============================] - 2s 742us/step\n",
      "Epoch 1/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.3259\n",
      "Epoch 1: val_loss improved from inf to 0.22937, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3252 - val_loss: 0.2294\n",
      "Epoch 2/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 2: val_loss improved from 0.22937 to 0.22387, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2218 - val_loss: 0.2239\n",
      "Epoch 3/10\n",
      "2284/2317 [============================>.] - ETA: 0s - loss: 0.2185\n",
      "Epoch 3: val_loss improved from 0.22387 to 0.22227, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2188 - val_loss: 0.2223\n",
      "Epoch 4/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2183\n",
      "Epoch 4: val_loss did not improve from 0.22227\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2184 - val_loss: 0.2232\n",
      "Epoch 5/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2187\n",
      "Epoch 5: val_loss did not improve from 0.22227\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2187 - val_loss: 0.2226\n",
      "Epoch 6/10\n",
      "2297/2317 [============================>.] - ETA: 0s - loss: 0.2178\n",
      "Epoch 6: val_loss did not improve from 0.22227\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2179 - val_loss: 0.2231\n",
      "Epoch 7/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2181\n",
      "Epoch 7: val_loss did not improve from 0.22227\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2181 - val_loss: 0.2227\n",
      "Epoch 8/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2181\n",
      "Epoch 8: val_loss did not improve from 0.22227\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2181 - val_loss: 0.2230\n",
      "Epoch 9/10\n",
      "2288/2317 [============================>.] - ETA: 0s - loss: 0.2180\n",
      "Epoch 9: val_loss improved from 0.22227 to 0.22225, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2179 - val_loss: 0.2223\n",
      "Epoch 10/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2183\n",
      "Epoch 10: val_loss did not improve from 0.22225\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2184 - val_loss: 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 742us/step\n",
      "2317/2317 [==============================] - 2s 747us/step\n",
      "623/623 [==============================] - 0s 758us/step\n",
      "623/623 [==============================] - 0s 740us/step\n",
      "390/390 [==============================] - 0s 745us/step\n",
      "390/390 [==============================] - 0s 757us/step\n",
      "258/258 [==============================] - 0s 749us/step\n",
      "258/258 [==============================] - 0s 743us/step\n",
      "2576/2576 [==============================] - 2s 740us/step\n",
      "2576/2576 [==============================] - 2s 766us/step\n",
      "Epoch 1/10\n",
      "2290/2317 [============================>.] - ETA: 0s - loss: 0.3614\n",
      "Epoch 1: val_loss improved from inf to 0.22507, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7.h5\n",
      "2317/2317 [==============================] - 4s 1ms/step - loss: 0.3600 - val_loss: 0.2251\n",
      "Epoch 2/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2231\n",
      "Epoch 2: val_loss did not improve from 0.22507\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2232 - val_loss: 0.2257\n",
      "Epoch 3/10\n",
      "2296/2317 [============================>.] - ETA: 0s - loss: 0.2227\n",
      "Epoch 3: val_loss improved from 0.22507 to 0.22454, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2227 - val_loss: 0.2245\n",
      "Epoch 4/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2225\n",
      "Epoch 4: val_loss improved from 0.22454 to 0.22278, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2223 - val_loss: 0.2228\n",
      "Epoch 5/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2215\n",
      "Epoch 5: val_loss did not improve from 0.22278\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2214 - val_loss: 0.2232\n",
      "Epoch 6/10\n",
      "2292/2317 [============================>.] - ETA: 0s - loss: 0.2211\n",
      "Epoch 6: val_loss improved from 0.22278 to 0.22219, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2214 - val_loss: 0.2222\n",
      "Epoch 7/10\n",
      "2284/2317 [============================>.] - ETA: 0s - loss: 0.2215\n",
      "Epoch 7: val_loss did not improve from 0.22219\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2213 - val_loss: 0.2229\n",
      "Epoch 8/10\n",
      "2282/2317 [============================>.] - ETA: 0s - loss: 0.2212\n",
      "Epoch 8: val_loss improved from 0.22219 to 0.22191, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2213 - val_loss: 0.2219\n",
      "Epoch 9/10\n",
      "2311/2317 [============================>.] - ETA: 0s - loss: 0.2208\n",
      "Epoch 9: val_loss did not improve from 0.22191\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2208 - val_loss: 0.2220\n",
      "Epoch 10/10\n",
      "2301/2317 [============================>.] - ETA: 0s - loss: 0.2208\n",
      "Epoch 10: val_loss did not improve from 0.22191\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2207 - val_loss: 0.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 767us/step\n",
      "2317/2317 [==============================] - 2s 760us/step\n",
      "623/623 [==============================] - 1s 779us/step\n",
      "623/623 [==============================] - 1s 778us/step\n",
      "390/390 [==============================] - 0s 757us/step\n",
      "390/390 [==============================] - 0s 787us/step\n",
      "258/258 [==============================] - 0s 761us/step\n",
      "258/258 [==============================] - 0s 766us/step\n",
      "2576/2576 [==============================] - 2s 739us/step\n",
      "2576/2576 [==============================] - 2s 690us/step\n",
      "Epoch 1/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.3291\n",
      "Epoch 1: val_loss improved from inf to 0.21490, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3289 - val_loss: 0.2149\n",
      "Epoch 2/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2240\n",
      "Epoch 2: val_loss improved from 0.21490 to 0.21137, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2239 - val_loss: 0.2114\n",
      "Epoch 3/10\n",
      "2312/2317 [============================>.] - ETA: 0s - loss: 0.2221\n",
      "Epoch 3: val_loss did not improve from 0.21137\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2222 - val_loss: 0.2121\n",
      "Epoch 4/10\n",
      "2287/2317 [============================>.] - ETA: 0s - loss: 0.2215\n",
      "Epoch 4: val_loss improved from 0.21137 to 0.21066, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2215 - val_loss: 0.2107\n",
      "Epoch 5/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2213\n",
      "Epoch 5: val_loss did not improve from 0.21066\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2213 - val_loss: 0.2114\n",
      "Epoch 6/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2207\n",
      "Epoch 6: val_loss did not improve from 0.21066\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2210 - val_loss: 0.2125\n",
      "Epoch 7/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2211\n",
      "Epoch 7: val_loss improved from 0.21066 to 0.21060, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2212 - val_loss: 0.2106\n",
      "Epoch 8/10\n",
      "2303/2317 [============================>.] - ETA: 0s - loss: 0.2212\n",
      "Epoch 8: val_loss improved from 0.21060 to 0.21033, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8.h5\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2212 - val_loss: 0.2103\n",
      "Epoch 9/10\n",
      "2307/2317 [============================>.] - ETA: 0s - loss: 0.2214\n",
      "Epoch 9: val_loss did not improve from 0.21033\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2216 - val_loss: 0.2105\n",
      "Epoch 10/10\n",
      "2304/2317 [============================>.] - ETA: 0s - loss: 0.2217\n",
      "Epoch 10: val_loss did not improve from 0.21033\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2215 - val_loss: 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 744us/step\n",
      "2317/2317 [==============================] - 2s 989us/step\n",
      "623/623 [==============================] - 1s 1ms/step\n",
      "623/623 [==============================] - 1s 940us/step\n",
      "390/390 [==============================] - 0s 939us/step\n",
      "390/390 [==============================] - 1s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "2576/2576 [==============================] - 3s 1ms/step\n",
      "2576/2576 [==============================] - 2s 918us/step\n",
      "Epoch 1/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.3415\n",
      "Epoch 1: val_loss improved from inf to 0.21183, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 5s 2ms/step - loss: 0.3412 - val_loss: 0.2118\n",
      "Epoch 2/10\n",
      "2316/2317 [============================>.] - ETA: 0s - loss: 0.2236\n",
      "Epoch 2: val_loss improved from 0.21183 to 0.20961, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2235 - val_loss: 0.2096\n",
      "Epoch 3/10\n",
      "2293/2317 [============================>.] - ETA: 0s - loss: 0.2224\n",
      "Epoch 3: val_loss improved from 0.20961 to 0.20847, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 2ms/step - loss: 0.2223 - val_loss: 0.2085\n",
      "Epoch 4/10\n",
      "2306/2317 [============================>.] - ETA: 0s - loss: 0.2217\n",
      "Epoch 4: val_loss did not improve from 0.20847\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2217 - val_loss: 0.2091\n",
      "Epoch 5/10\n",
      "2299/2317 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 5: val_loss did not improve from 0.20847\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2217 - val_loss: 0.2086\n",
      "Epoch 6/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2214\n",
      "Epoch 6: val_loss improved from 0.20847 to 0.20814, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2214 - val_loss: 0.2081\n",
      "Epoch 7/10\n",
      "2298/2317 [============================>.] - ETA: 0s - loss: 0.2211\n",
      "Epoch 7: val_loss improved from 0.20814 to 0.20789, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2213 - val_loss: 0.2079\n",
      "Epoch 8/10\n",
      "2314/2317 [============================>.] - ETA: 0s - loss: 0.2209\n",
      "Epoch 8: val_loss did not improve from 0.20789\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2209 - val_loss: 0.2092\n",
      "Epoch 9/10\n",
      "2310/2317 [============================>.] - ETA: 0s - loss: 0.2214\n",
      "Epoch 9: val_loss did not improve from 0.20789\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2214 - val_loss: 0.2099\n",
      "Epoch 10/10\n",
      "2315/2317 [============================>.] - ETA: 0s - loss: 0.2209\n",
      "Epoch 10: val_loss improved from 0.20789 to 0.20773, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2209 - val_loss: 0.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 743us/step\n",
      "2317/2317 [==============================] - 2s 698us/step\n",
      "623/623 [==============================] - 0s 765us/step\n",
      "623/623 [==============================] - 0s 735us/step\n",
      "390/390 [==============================] - 0s 738us/step\n",
      "390/390 [==============================] - 0s 736us/step\n",
      "258/258 [==============================] - 0s 744us/step\n",
      "258/258 [==============================] - 0s 724us/step\n",
      "2576/2576 [==============================] - 2s 715us/step\n",
      "2576/2576 [==============================] - 2s 729us/step\n",
      "Epoch 1/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.3452\n",
      "Epoch 1: val_loss improved from inf to 0.22063, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.3450 - val_loss: 0.2206\n",
      "Epoch 2/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2248\n",
      "Epoch 2: val_loss improved from 0.22063 to 0.21507, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2248 - val_loss: 0.2151\n",
      "Epoch 3/10\n",
      "2280/2317 [============================>.] - ETA: 0s - loss: 0.2225\n",
      "Epoch 3: val_loss improved from 0.21507 to 0.21415, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2227 - val_loss: 0.2142\n",
      "Epoch 4/10\n",
      "2284/2317 [============================>.] - ETA: 0s - loss: 0.2224\n",
      "Epoch 4: val_loss did not improve from 0.21415\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2222 - val_loss: 0.2143\n",
      "Epoch 5/10\n",
      "2284/2317 [============================>.] - ETA: 0s - loss: 0.2217\n",
      "Epoch 5: val_loss improved from 0.21415 to 0.21372, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10.h5\n",
      "2317/2317 [==============================] - 4s 2ms/step - loss: 0.2219 - val_loss: 0.2137\n",
      "Epoch 6/10\n",
      "2279/2317 [============================>.] - ETA: 0s - loss: 0.2220\n",
      "Epoch 6: val_loss did not improve from 0.21372\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2219 - val_loss: 0.2145\n",
      "Epoch 7/10\n",
      "2283/2317 [============================>.] - ETA: 0s - loss: 0.2216\n",
      "Epoch 7: val_loss did not improve from 0.21372\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2218 - val_loss: 0.2140\n",
      "Epoch 8/10\n",
      "2317/2317 [==============================] - ETA: 0s - loss: 0.2217\n",
      "Epoch 8: val_loss did not improve from 0.21372\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2217 - val_loss: 0.2144\n",
      "Epoch 9/10\n",
      "2277/2317 [============================>.] - ETA: 0s - loss: 0.2218\n",
      "Epoch 9: val_loss improved from 0.21372 to 0.21324, saving model to /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10.h5\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2218 - val_loss: 0.2132\n",
      "Epoch 10/10\n",
      "2313/2317 [============================>.] - ETA: 0s - loss: 0.2214\n",
      "Epoch 10: val_loss did not improve from 0.21324\n",
      "2317/2317 [==============================] - 3s 1ms/step - loss: 0.2215 - val_loss: 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/Brody1/Documents/Northwestern/DNA_Cyclizability/benchmarks/deep-learning/conv_only_4_tiling_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/2317 [==============================] - 2s 674us/step\n",
      "2317/2317 [==============================] - 2s 668us/step\n",
      "623/623 [==============================] - 0s 710us/step\n",
      "623/623 [==============================] - 0s 664us/step\n",
      "390/390 [==============================] - 0s 672us/step\n",
      "390/390 [==============================] - 0s 693us/step\n",
      "258/258 [==============================] - 0s 684us/step\n",
      "258/258 [==============================] - 0s 677us/step\n",
      "2576/2576 [==============================] - 2s 672us/step\n",
      "2576/2576 [==============================] - 2s 684us/step\n"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "times2 = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = X5[train_index]\n",
    "    training_X_reverse = X5_reverse[train_index]\n",
    "    validation_X = X5[val_index]\n",
    "    validation_X_reverse = X5_reverse[val_index]\n",
    "    training_Y = Y5[train_index]\n",
    "    validation_Y = Y5[val_index]\n",
    "    # CREATE NEW MODEL\n",
    "    model = model_cycle()\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = callbacks.ModelCheckpoint(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\",\n",
    "                                                    monitor='val_loss', verbose=1,\n",
    "                                                    save_best_only=True, mode='min')\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    history = model.fit(training_X, training_Y,\n",
    "                        epochs=num_epochs,\n",
    "                        callbacks= [checkpoint, time_callback],\n",
    "                        validation_data=(validation_X, validation_Y))\n",
    "    model.load_weights(save_path + model_name+\"_tiling_\"+str(fold_var)+\".h5\")\n",
    "    model.save(save_path+model_name+\"_tiling_\"+str(fold_var),save_traces=False)\n",
    "    times.append(time_callback.times)\n",
    "\n",
    "    pred_Y = model.predict(training_X)\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "    pred_Y_reverse = model.predict(training_X_reverse)\n",
    "    pred_Y_reverse = pred_Y_reverse.reshape(pred_Y_reverse.shape[0])\n",
    "    pred_Y = (pred_Y+pred_Y_reverse)/2\n",
    "    reg =  LinearRegression().fit(array(pred_Y).reshape(-1, 1), array(training_Y).reshape(-1, 1))\n",
    "    \n",
    "    detrend_int = reg.intercept_\n",
    "    detrend_slope = reg.coef_\n",
    "    detrend.append([float(detrend_int), float(detrend_slope)])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X1)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X1_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X3)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X3_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(validation_X)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(validation_X_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model.predict(X6)\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_reverse = model.predict(X6_reverse)\n",
    "    fit_reverse = fit_reverse.reshape(fit_reverse.shape[0])\n",
    "    reverse_corr = np.corrcoef(fit, fit_reverse)[0,1]\n",
    "    fit = (fit + fit_reverse)/2\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    fits.append(fit_tmp)\n",
    "    fit = detrend_int + fit * detrend_slope\n",
    "    fit = fit.flatten()\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit),reverse_corr]\n",
    "    time0 = time.process_time() - start_time\n",
    "    times2.append([time0])\n",
    "    fits.append(fit_tmp)\n",
    "    \n",
    "    K.clear_session()\n",
    "    fold_var += 1\n",
    "    \n",
    "detrend = array(detrend)\n",
    "detrend = pd.DataFrame(detrend)\n",
    "detrend.to_csv(save_path +model_name+\"_detrend_tiling.txt\", index = False)\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+ \"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n",
    "\n",
    "with open(save_path +model_name+\"_pred_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times2:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_csv(save_path +model_name+ \"_fits_tiling.txt\",delimiter = \",\")\n",
    "fits=array(fits.values.tolist())\n",
    "fits = np.transpose(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.3292835516741519 \n",
      "Average MSE on tiling: 0.21597396388814927 \n",
      "Average correlation on random: 0.34785370006707267 \n",
      "Average MSE on random: 0.12647824502056876 \n",
      "Average correlation on ChrV: 0.2630361430070081 \n",
      "Average MSE on ChrV: 0.27086584711475636 \n",
      "Average correlation on CN: 0.2724593879426133 \n",
      "Average MSE on CN: 0.20101999567909004\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574/2574 [==============================] - 1s 555us/step\n",
      "390/390 [==============================] - 0s 758us/step\n"
     ]
    }
   ],
   "source": [
    "first_conv_model = Model(inputs = model.input, outputs = model.layers[1].output)\n",
    "first_conv_output = first_conv_model.predict(X5)\n",
    "pd.DataFrame(first_conv_output.reshape(first_conv_output.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_tiling_first_conv_output\")\n",
    "first_conv_output_random = first_conv_model.predict(X3)\n",
    "pd.DataFrame(first_conv_output_random.reshape(first_conv_output_random.shape[0], -1)).to_csv(save_path + model_name+\"_tiling_random_first_conv_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = model.layers[1].weights[0]\n",
    "first_conv_biases = model.layers[1].weights[1]\n",
    "# Format: [Position 0: A, C, G, T, Position 1: A, C, G, T, Position 2: A, C, G, T]\n",
    "pd.DataFrame(array(first_conv_weights).transpose((3,2,0,1)).reshape(first_conv_weights.shape[-1], -1)).to_csv(save_path + model_name+\"_tiling_first_conv_kernels\")\n",
    "pd.DataFrame(first_conv_biases).to_csv(save_path + model_name+\"_tiling_first_conv_biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
