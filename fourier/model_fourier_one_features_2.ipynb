{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/Brody1/Documents/Northwestern/Jiping/benchmarks/deep-learning/\"\n",
    "model_name = \"fourier_one_features_2\"\n",
    "kf = KFold(n_splits = 10, shuffle =True)\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define functions ####\n",
    "\n",
    "# # Fully connected neural network with one hidden layer\n",
    "# class NeuralNet(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, out_dim):\n",
    "#         super(NeuralNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, out_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.fc1(x)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size_one_hot, input_size_extra, hidden_size_one_hot, hidden_size_extra, out_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size_extra, hidden_size_extra)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size_extra, out_dim)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_size_one_hot, out_channels=hidden_size_one_hot, kernel_size=(3,4))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fits(fits):\n",
    "    print(f\"Average correlation on tiling: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 4) == 2])}\",\n",
    "          f\"\\nAverage MSE on tiling: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 4) == 2])}\",\n",
    "          f\"\\nAverage correlation on random: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 4) == 1])}\",\n",
    "          f\"\\nAverage MSE on random: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 4) == 1])}\",\n",
    "          f\"\\nAverage correlation on ChrV: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 4) == 3])}\",\n",
    "          f\"\\nAverage MSE on ChrV: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 4) == 3])}\",\n",
    "          f\"\\nAverage correlation on CN: {np.mean([fits[0][i] for i in range(fits[0].size) if (i % 4) == 0])}\",\n",
    "          f\"\\nAverage MSE on CN: {np.mean([fits[1][i] for i in range(fits[1].size) if (i % 4) == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct sine and cosine matrices for Fourier features:\n",
    "cos_matrix, sin_matrix = [[] for x in range(50)], [[] for x in range(50)]\n",
    "for n in range(50):\n",
    "    for k in range(50):\n",
    "        cos_matrix[n].append(np.cos(2*np.pi*(n+1)*k/50))\n",
    "        sin_matrix[n].append(np.sin(2*np.pi*(n+1)*k/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnaOneFourier(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [1], \"C\": [0], \"G\": [0], \"T\": [1],\n",
    "            \"a\": [1], \"c\": [0], \"g\": [0], \"t\": [1]}\n",
    "    AT_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        AT_encoded_seq.append(code[char][0])\n",
    "    one_fourier_cos = np.matmul(array(AT_encoded_seq), array(cos_matrix).transpose())\n",
    "    one_fourier_sin = np.matmul(array(AT_encoded_seq), array(sin_matrix).transpose())\n",
    "    return array((one_fourier_cos[5], one_fourier_sin[5]), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnaOneHot(sequence):\n",
    "    seq_array = array(list(sequence))\n",
    "    code = {\"A\": [0], \"C\": [1], \"G\": [2], \"T\": [3], \"N\": [4],\n",
    "            \"a\": [0], \"c\": [1], \"g\": [2], \"t\": [3], \"n\": [4]}\n",
    "    onehot_encoded_seq = []\n",
    "    for char in seq_array:\n",
    "        onehot_encoded = np.zeros(5)\n",
    "        onehot_encoded[code[char]] = 1\n",
    "        onehot_encoded_seq.append(onehot_encoded[0:4])\n",
    "    return onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_c0new(dat):\n",
    "  mat = np.empty((3,3), float)\n",
    "  k = 2*np.pi/10.4\n",
    "  n = array([26, 29, 31])\n",
    "  mat[0:3,0] = 1\n",
    "  mat[0:3, 1] = np.sin(n*k)\n",
    "  mat[0:3, 2] = np.cos(n*k)\n",
    "  inv_mat = np.linalg.inv(mat)\n",
    "  c0A1A2 = array(np.matmul(dat[[\"n=26\", \"n=29\", \"n=31\"]], inv_mat))\n",
    "  c0Aphi = c0A1A2\n",
    "  c0Aphi[:,0] = c0A1A2[:,0]\n",
    "  c0Aphi[:,1] = np.sqrt(c0A1A2[:,1]**2 + c0A1A2[:,2]**2)\n",
    "  c0Aphi[:,2] <- np.sign(c0A1A2[:,2]) * np.arccos(c0A1A2[:,1]/c0Aphi[:,1])\n",
    "  return c0Aphi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### preparing data ####\n",
    "\n",
    "data_cerevisiae_nucle = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/Jiping/cycle1.txt\",delimiter = \",\")\n",
    "X1 = []\n",
    "for sequence_nt in data_cerevisiae_nucle[\"Sequence\"]:\n",
    "    X1.append([dnaOneFourier(sequence_nt), array(dnaOneHot(sequence_nt)).reshape(50, 4, 1)])\n",
    "# X1 = np.float32(array(X1))\n",
    "# X1 = X1.reshape((X1.shape[0],50,4,1))\n",
    "### COMPUTE EIGENVECTORS:\n",
    "\n",
    "# X1_reverse = np.flip(X1,[1,2])\n",
    "# Y1 = data_cerevisiae_nucle[\"C0\"].values.astype(float)\n",
    "Y1 = np.float32(find_c0new(data_cerevisiae_nucle).astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19907, 2)\n",
      "(50, 4, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brody1/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/Brody1/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(array(X1).shape)\n",
    "print(array(X1)[0, 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_library = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/Jiping/cycle3.txt\",delimiter = \",\")\n",
    "X3 = []\n",
    "for sequence_nt in data_random_library[\"Sequence\"]:\n",
    "    X3.append(dnaOneFourier(sequence_nt))\n",
    "    X3.append(dnaOneHot(sequence_nt))\n",
    "X3 = np.float32(array(X3))\n",
    "# X3 = X3.reshape((X3.shape[0],50,2,1))\n",
    "# X3_reverse = np.flip(X3,[1,2])\n",
    "# Y3 = data_random_library[\"C0\"].values.astype(float)\n",
    "Y3 = np.float32(find_c0new(data_random_library).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brody1/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_4/m5twwlnn26b0q41jgwd5jnz80000gq/T/ipykernel_6156/1044120077.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnaOneFourier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_nt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnaOneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_nt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# X5 = X5.reshape((X5.shape[0],50,4,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# X5_reverse = np.flip(X5,[1,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "data_tiling = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/Jiping/cycle5.txt\",delimiter = \",\")\n",
    "X5 = []\n",
    "for sequence_nt in data_tiling[\"Sequence\"]:\n",
    "    X5.append(dnaOneFourier(sequence_nt))\n",
    "    X5.append(dnaOneHot(sequence_nt))\n",
    "X5 = np.float32(array(X5))\n",
    "# X5 = X5.reshape((X5.shape[0],50,4,1))\n",
    "# X5_reverse = np.flip(X5,[1,2])\n",
    "# Y5 = data_tiling[\"C0\"].values.astype(float)\n",
    "Y5 = np.float32(find_c0new(data_tiling).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chr5 = pd.read_csv(\"/Users/Brody1/Documents/Northwestern/Jiping/cycle6.txt\",delimiter = \",\")\n",
    "X6 = []\n",
    "for sequence_nt in data_chr5[\"Sequence\"]:\n",
    "    X6.append(dnaOneFourier(sequence_nt))\n",
    "    X6.append(dnaOneHot(sequence_nt))\n",
    "X6 = np.float32(array(X6))\n",
    "# X6 = X6.reshape((X6.shape[0],50,4,1))\n",
    "# X6_reverse = np.flip(X6,[1,2])\n",
    "# Y6 = data_chr5[\"C0\"].values.astype(float)\n",
    "Y6 = np.float32(find_c0new(data_chr5).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_4/m5twwlnn26b0q41jgwd5jnz80000gq/T/ipykernel_6156/473322355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtraining_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtraining_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "#### tiling\n",
    "\n",
    "VALIDATION_LOSS = []\n",
    "fold_var = 1\n",
    "n = Y5.shape[0]\n",
    "hidden_size = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "fits = []\n",
    "detrend = []\n",
    "times = []\n",
    "\n",
    "for train_index, val_index in kf.split(Y5):\n",
    "    training_X = np.float32(X5[train_index])\n",
    "    validation_X = np.float32(X5[val_index])\n",
    "    training_Y = np.float32(Y5[train_index])\n",
    "    validation_Y = np.float32(Y5[val_index])\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    model = NeuralNet(input_size=202, hidden_size=hidden_size, out_dim=1)\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    # CREATE CALLBACKS\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.from_numpy(training_X)\n",
    "        inputs = inputs.reshape(inputs.shape[0], 202)\n",
    "        targets = torch.from_numpy(training_Y)\n",
    "        targets = targets.reshape(targets.shape[0], 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "    \n",
    "    pred_Y = model(torch.from_numpy(training_X)).detach().numpy()\n",
    "    pred_Y = pred_Y.reshape(pred_Y.shape[0])\n",
    "\n",
    "    start_time = time.process_time()\n",
    "    fit = model(torch.from_numpy(X1)).detach().numpy()\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_tmp =[np.corrcoef(fit, Y1)[0,1],np.mean(np.square(fit-Y1)),np.mean(fit),np.std(fit)]\n",
    "    fits.append(fit_tmp)\n",
    "    time0 = time.process_time() - start_time\n",
    "    times.append([time0])\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model(torch.from_numpy(X3)).detach().numpy()\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_tmp =[np.corrcoef(fit, Y3)[0,1],np.mean(np.square(fit-Y3)),np.mean(fit),np.std(fit)]\n",
    "    fits.append(fit_tmp)\n",
    "    time0 = time.process_time() - start_time\n",
    "    times.append([time0])\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model(torch.from_numpy(validation_X)).detach().numpy()\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_tmp =[np.corrcoef(fit, validation_Y)[0,1],np.mean(np.square(fit-validation_Y)),np.mean(fit),np.std(fit)]\n",
    "    fits.append(fit_tmp)\n",
    "    time0 = time.process_time() - start_time\n",
    "    times.append([time0])\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    fit = model(torch.from_numpy(X6)).detach().numpy()\n",
    "    fit = fit.reshape(fit.shape[0])\n",
    "    fit_tmp =[np.corrcoef(fit, Y6)[0,1],np.mean(np.square(fit-Y6)),np.mean(fit),np.std(fit)]\n",
    "    fits.append(fit_tmp)\n",
    "    time0 = time.process_time() - start_time\n",
    "    times.append([time0])\n",
    "    \n",
    "    fold_var += 1\n",
    "\n",
    "fits = array(fits)\n",
    "fits = pd.DataFrame((fits))\n",
    "fits.to_csv(save_path +model_name+\"_fits_tiling.txt\", index = False)\n",
    "\n",
    "with open(save_path +model_name+\"_time_tiling.txt\", \"w\") as file:\n",
    "    for row in times:\n",
    "        s = \" \".join(map(str, row))\n",
    "        file.write(s+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation on tiling: 0.009142444649559739 \n",
      "Average MSE on tiling: 0.16104955077171326 \n",
      "Average correlation on random: 0.007457088024553468 \n",
      "Average MSE on random: 0.12480362206697464 \n",
      "Average correlation on ChrV: 0.006018485089171445 \n",
      "Average MSE on ChrV: 0.2580263018608093 \n",
      "Average correlation on CN: 0.007645504574162086 \n",
      "Average MSE on CN: 0.2234574779868126\n"
     ]
    }
   ],
   "source": [
    "display_fits(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cd633bf9703d9b8d2b7bb6e04b82983774c32d5f891ed1890ee26b779f7466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
